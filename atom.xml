<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>feng.blog();</title>
  
  
  <link href="https://feng.lu/atom.xml" rel="self"/>
  
  <link href="https://feng.lu/"/>
  <updated>2025-03-28T17:44:14.394Z</updated>
  <id>https://feng.lu/</id>
  
  <author>
    <name>Feng Lu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Building a Tibber MCP Server: Connect Your AI Agent to Energy Consumption Data</title>
    <link href="https://feng.lu/2025/03/28/Building-a-Tibber-MCP-Server-Connect-Your-AI-Agent-to-Energy-Consumption-Data/"/>
    <id>https://feng.lu/2025/03/28/Building-a-Tibber-MCP-Server-Connect-Your-AI-Agent-to-Energy-Consumption-Data/</id>
    <published>2025-03-28T13:25:48.000Z</published>
    <updated>2025-03-28T17:44:14.394Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>In the era of AI, integrating agents with external systems is crucial for expanding their capabilities. Whether accessing local file systems, remote databases, or APIs, external data significantly enhances an AI agent’s ability to assist in daily tasks.</p><p>However, connecting AI agents to external systems can be challenging. Different systems use various interfaces and protocols, making integration complex. Fortunately, Anthropic’s <a href="https://modelcontextprotocol.io/introduction">Model Context Protocol (MCP)</a> simplifies this process, providing a standardized way for AI agents to interact with external resources and tools.</p><p>MCP functions similarly to HTTP on the internet—it defines a standardized approach that enables AI agents to discover and interact with external systems seamlessly.</p><h3 id="Building-an-MCP-Server-for-Tibber"><a href="#Building-an-MCP-Server-for-Tibber" class="headerlink" title="Building an MCP Server for Tibber"></a>Building an MCP Server for Tibber</h3><p>In this blog post, I’ll demonstrate how I built a MCP server for integrating <a href="https://tibber.com/">Tibber</a> with an AI agent.</p><p>Tibber is a Norwegian power supplier that we’ve been using for years. They provide <a href="https://developer.tibber.com/docs">APIs</a> that allow users to retrieve electricity prices and energy consumption data. By integrating Tibber’s API with an AI agent, I can ask natural language questions like:</p><ul><li>“What is the current electricity price?”</li><li>“What was my house’s energy cost yesterday?”</li><li>“List the 3 cheapest hours of tomorrow.”</li></ul><p>This integration enables a more intuitive and efficient way to access real-time energy data without manually querying APIs.</p><h3 id="Demo-video"><a href="#Demo-video" class="headerlink" title="Demo video"></a>Demo video</h3><div class="video-container"><iframe src="https://www.youtube.com/embed/FiqKPa9i6V4" frameborder="0" loading="lazy" allowfullscreen></iframe></div><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><img src="/2025/03/28/Building-a-Tibber-MCP-Server-Connect-Your-AI-Agent-to-Energy-Consumption-Data/tibber-mcp-architecture.png" class="" title="tibber mcp config"><h3 id="Installation-and-Setup-Tibber-MCP-server"><a href="#Installation-and-Setup-Tibber-MCP-server" class="headerlink" title="Installation and Setup Tibber MCP server"></a>Installation and Setup Tibber MCP server</h3><p>You can find the source code for Tibber MCP on my GitHub repository: <a href="https://github.com/linkcd/tibber-mcp">https://github.com/linkcd/tibber-mcp</a>.</p><p>Follow the installation steps in the repository to deploy Tibber MCP on your local machine. Once installed, configure the MCP server settings as follows:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;tibber&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">         <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span><span class="string">&quot;uv&quot;</span><span class="punctuation">,</span></span><br><span class="line">         <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;--directory&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;[PATH-TO-ROOT-OF-THE-CLONED-TIBBER-MCP-FOLDER]&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;run&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;server.py&quot;</span></span><br><span class="line">         <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">         <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;TIBBER_API_TOKEN&quot;</span><span class="punctuation">:</span><span class="string">&quot;[YOUR-TIBBER-TOKEN]&quot;</span></span><br><span class="line">         <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">   <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>Once it is successfully connected to the MCP server, you can see the available tools (and resources) this MCP server provides. This is the screenshot of <a href="https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline">Roo Code</a> MCP servers in VS Code.</p><img src="/2025/03/28/Building-a-Tibber-MCP-Server-Connect-Your-AI-Agent-to-Energy-Consumption-Data/tibber-mcp-config.png" class="" title="tibber mcp config"><h3 id="Sample-questions-and-answers"><a href="#Sample-questions-and-answers" class="headerlink" title="Sample questions and answers"></a>Sample questions and answers</h3><p><strong>Question #1: “What is the current electricity price?”</strong><br><strong>Answer:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">The current electricity price (as of 16:00) is 0.6955 NOK/kWh with a NORMAL price level. </span><br><span class="line">This price consists of:</span><br><span class="line">- Energy cost: 0.5328 NOK/kWh</span><br><span class="line">- Tax: 0.1627 NOK/kWh</span><br><span class="line"></span><br><span class="line">This is a moderate price compared to today&#x27;s range:</span><br><span class="line">- Lowest price today: 0.4924 NOK/kWh (at 23:00)</span><br><span class="line">- Highest price today: 0.732 NOK/kWh (at 18:00)</span><br><span class="line"></span><br><span class="line">Tomorrow&#x27;s prices will be generally lower, with some very cheap periods:</span><br><span class="line">- Lowest price: 0.1673 NOK/kWh (at 01:00)</span><br><span class="line">- Highest price: 0.7472 NOK/kWh (at 18:00)</span><br></pre></td></tr></table></figure><p><strong>Question #2: “What was my house’s energy cost yesterday?”</strong><br><strong>Answer:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Your total electricity cost for yesterday (March 27th) was:</span><br><span class="line">- Total consumption: 63.811 kWh</span><br><span class="line">- Total cost: 45.31 NOK</span><br><span class="line"></span><br><span class="line">The most expensive hours were:</span><br><span class="line">- 08:00-09:00: 0.7795 NOK/kWh</span><br><span class="line">- 07:00-08:00: 0.7736 NOK/kWh</span><br><span class="line">- 06:00-07:00: 0.7424 NOK/kWh</span><br><span class="line"></span><br><span class="line">The cheapest hours were:</span><br><span class="line">- 13:00-14:00: 0.5969 NOK/kWh</span><br><span class="line">- 12:00-13:00: 0.6264 NOK/kWh</span><br><span class="line">- 14:00-15:00: 0.6617 NOK/kWh</span><br></pre></td></tr></table></figure><h3 id="Thoughts-and-improvement-areas"><a href="#Thoughts-and-improvement-areas" class="headerlink" title="Thoughts and improvement areas"></a>Thoughts and improvement areas</h3><p>When reading the source code, you may have noticed how easy it is to build an MCP server using tools like <a href="https://github.com/jlowin/fastmcp">FastMCP</a>. With fewer than 100 lines of code, it efficiently wraps the <a href="https://github.com/Danielhiversen/pyTibber">pyTibber</a> library into an MCP server implementation, enabling the AI agent to interact with it automatically.</p><p>Currently, this MCP server implementation does not support parameters such as date or time when making API calls. For example, when you ask, “What was my energy consumption yesterday?”, it retrieves all consumption data for the past 30 days and relies on the LLM (Large Language Model) to extract the relevant information.</p><p>To improve efficiency and reduce token usage, we could implement parameterized API calls. This would allow the AI agent to pass a specific date (e.g., yesterday) and retrieve only the necessary data, making the interaction more precise and resource-efficient.</p><h3 id="Feedback"><a href="#Feedback" class="headerlink" title="Feedback"></a>Feedback</h3><p>If you have any questions or suggestions, feel free to reach out or create a GitHub issue for the repository: <a href="https://github.com/linkcd/tibber-mcp">https://github.com/linkcd/tibber-mcp</a>.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;p&gt;In the era of AI, integrating </summary>
      
    
    
    
    
    <category term="AI" scheme="https://feng.lu/tags/AI/"/>
    
    <category term="GenAI" scheme="https://feng.lu/tags/GenAI/"/>
    
    <category term="Generative AI" scheme="https://feng.lu/tags/Generative-AI/"/>
    
    <category term="AI Agent" scheme="https://feng.lu/tags/AI-Agent/"/>
    
    <category term="MCP" scheme="https://feng.lu/tags/MCP/"/>
    
    <category term="Model Context Protocol" scheme="https://feng.lu/tags/Model-Context-Protocol/"/>
    
    <category term="Tibber" scheme="https://feng.lu/tags/Tibber/"/>
    
  </entry>
  
  <entry>
    <title>Build a Multi-Agent System to Discover the Top AI Model for Rock-Paper-Scissors Games</title>
    <link href="https://feng.lu/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/"/>
    <id>https://feng.lu/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/</id>
    <published>2024-12-03T15:21:40.000Z</published>
    <updated>2025-03-28T17:44:06.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>Imagine a world where AI agents aren’t working together to achieve a common goal. Instead, each agent is out to win the game of Rock-Paper-Scissors. The mission of each agent is straightforward: defeat the others. </p><p>Can a machine strategize in a game of pure chance? And if it can, which model will emerge victorious? </p><p>In order to answer that very question, I built a multi-agent system to host fully automated Rock-Paper-Scissors tournaments, pitting various AI models against one another to see who comes out on top. From OpenAI’s cutting-edge models to Meta’s Llama and Anthropic’s Claude, each agent brings its own “personality” and decision-making quirks to the table. </p><p>This isn’t just an experiment in gaming; it’s also a showcase of the latest capabilities in multi-agent systems. Using <a href="https://www.crewai.com/">CrewAI</a> and <a href="https://langchain-ai.github.io/langgraph/">LangGraph</a>, it is easy to create AI agents and put them into complicated flows.</p><p>In our games, we will test the following AI:</p><ul><li><a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct">Llama3 8B Instruct</a></li><li><a href="https://www.anthropic.com/news/claude-3-family">Claude 3 Sonnet</a></li><li><a href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">OpenAI GPT 4o Mini</a></li></ul><h2 id="2-Architecture-and-Workflow"><a href="#2-Architecture-and-Workflow" class="headerlink" title="2. Architecture and Workflow"></a>2. Architecture and Workflow</h2><p>This project combines two popular frameworks: <a href="https://langchain-ai.github.io/langgraph/">LangGraph</a> for workflow orchestration and <a href="https://www.crewai.com/">CrewAI</a> for agent definitions:</p><ul><li>The workflow is built as a <a href="https://langchain-ai.github.io/langgraph/concepts/multi_agent/">multi-agent system</a> using LangGraph’s graph structure</li><li>Each AI agent is defined as a <a href="https://docs.crewai.com/concepts/crews">Crew</a>  using CrewAI.</li></ul><p>The graph and crew definition can be found in the <a href="https://github.com/linkcd/rps-agent-game/tree/master/src">src folder</a> in the source code <a href="https://github.com/linkcd/rps-agent-game">github repo</a>.</p><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/generated_graph.png" class="" title="generated graph by langgraph"><p><strong>Workflow</strong>:</p><ul><li>In each round, two player agents make their moves independently and in parallel. They have access to the history of previous rounds, allowing them to analyze patterns and decide on the best move.</li><li>After the players make their moves, a judge agent determines the winner of the round.</li><li>The system checks if the criteria for determining the final winner have been met (e.g., reaching the specified number of rounds, or a player winning 3 out of 5 rounds.).<ul><li><strong>Criteria Not Met</strong>: If the criteria are not met, another round begins.</li><li><strong>If the criteria are met</strong>: The final winner is announced, and a post-game analysis is performed.</li></ul></li></ul><p>After running hundreds of matches, the results were nothing short of interesting – and sometimes hilarious. Let’s look at what we discovered.</p><span id="more"></span><h2 id="3-Memory-Is-Important-For-AI-Agents"><a href="#3-Memory-Is-Important-For-AI-Agents" class="headerlink" title="3. Memory Is Important For AI Agents"></a>3. Memory Is Important For AI Agents</h2><h4 id="Game-1-Doreamen-dummy-agent-vs-Llama3-8B-Instruct-AI-agent-without-memory"><a href="#Game-1-Doreamen-dummy-agent-vs-Llama3-8B-Instruct-AI-agent-without-memory" class="headerlink" title="Game 1. Doreamen (dummy agent) vs Llama3 8B Instruct (AI agent without memory)"></a>Game 1. Doreamen (dummy agent) vs Llama3 8B Instruct (AI agent without memory)</h4><p>Remember the old saying “keep it simple, stupid”? Our first matchup proved this adage true – in the most unexpected way. Enter Doraemon, our delightfully dummy agent with a one-track mind: all rocks, all time. Like a stubborn child who refuses to play anything else, Doraemon faced off against the sophisticated Llama 3 8B Instruct model. </p><p>Doreamen is a dummy agent who can only play Rocks :)</p><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/Doraemon.png" class="" title="doraemon"><p>At this stage, the Llama 3 8B Instruct agent was operating without memory capabilities, meaning it couldn’t learn from previous rounds but relied purely on its instincts. The result? Our rock-obsessed friend dominated with 16 wins out of 20 rounds! It turns out that sometimes, being predictably unpredictable is the winning strategy.</p><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/doraemon%20vs%20llama3-8b-instruct-without-memory.png" class="" title="doraemon vs llama3-8b-instruct-without-memory"><h4 id="Game-2-Doreamen-dummy-agent-vs-Llama3-8B-Instruct-AI-agent-WITH-memory"><a href="#Game-2-Doreamen-dummy-agent-vs-Llama3-8B-Instruct-AI-agent-WITH-memory" class="headerlink" title="Game 2. Doreamen (dummy agent) vs Llama3 8B Instruct (AI agent WITH memory)"></a>Game 2. Doreamen (dummy agent) vs Llama3 8B Instruct (AI agent WITH memory)</h4><p>But here’s where it gets juicy – we now add memory to the AI agent, and the tables turn dramatically. When we enabled Llama 3’s ability to learn from previous rounds, it transformed from a stumbling novice into a strategic mastermind, crushing Doraemon with 18 wins out of 20 rounds. It’s like watching a student become the master in real-time, and also highlighted how important the memory is for AI agents.</p><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/doraemon%20vs%20llama3-8b-instruct.png" class="" title="doraemon vs llama3-8b-instruct-with-memory"><blockquote><p>Noticeable Patterns:<br>  a. Doraemon’s moves:<br>    - Doraemon played “Rock” in all 20 rounds, showing no variation in strategy.</p><p>   b. llama3-8b-instruct’s moves:<br>      - Round 1: Rock (resulting in a tie)<br>      - Round 2: Scissors (losing to Doraemon’s Rock)<br>      - Rounds 3-20: Paper (winning against Doraemon’s Rock)</p><p>   c. Overall pattern:<br>      - After losing in round 2, llama3-8b-instruct seems to have recognized Doraemon’s pattern of always playing Rock and adjusted its strategy to consistently play Paper, which beats Rock.<br>      - This adaptive strategy allowed llama3-8b-instruct to win 17 consecutive rounds from round 3 to round 20.</p><p>  In conclusion, llama3-8b-instruct (agent with memory) demonstrated an ability to adapt its strategy based on the opponent’s behavior, while Doraemon maintained a fixed, predictable strategy throughout the game. This resulted in a decisive victory for llama3-8b-instruct.</p></blockquote><p>This is the same with claude 3 sonnet based agent</p><ul><li><a href="https://github.com/linkcd/rps-agent-game/blob/master/doc/game_history/doraemon%20vs%20claude-3-sonnet-without-memory.png">Doraemon vs claude-3-sonnet without memory</a></li><li><a href="https://github.com/linkcd/rps-agent-game/blob/master/doc/game_history/doraemon%20vs%20claude-3-sonnet.png">Doraemon vs claude-3-sonnet with memory</a></li></ul><h2 id="4-AI-Personalities-Emerge-Through-Gameplay"><a href="#4-AI-Personalities-Emerge-Through-Gameplay" class="headerlink" title="4. AI Personalities Emerge Through Gameplay"></a>4. AI Personalities Emerge Through Gameplay</h2><p>Having memory clearly made a huge difference in how well AI agents performed. But what’s even more interesting is how each AI developed its own unique “personality” during gameplay. </p><p>In our next experiments, we matched two AI agents against each other. Both agent had the same memory capacity and received identical instructions. This setup allowed us to observe how each AI model’s thinking and strategy evolved over multiple rounds, revealing their distinct characteristics.</p><h4 id="Game-3-Llama3-8B-Instruct-vs-Claude-3-Sonnet"><a href="#Game-3-Llama3-8B-Instruct-vs-Claude-3-Sonnet" class="headerlink" title="Game 3: Llama3 8B Instruct vs Claude 3 Sonnet"></a>Game 3: Llama3 8B Instruct vs Claude 3 Sonnet</h4><p>In the battle of <strong>Llama 3 8B Instruct</strong> vs. <strong>Claude 3 Sonnet</strong>, Within 20 rounds, Llama3 8B Instruct initially performed better. However, as more rounds were played, the Claude 3 Sonnet agent adapted its strategy to counter Llama3-8b-instruct’s preference for Paper, ultimately leading to its decisive victory in the game.</p><ul><li><a href="https://github.com/linkcd/rps-agent-game/blob/master/doc/game_history/llama3-8b-instruct%20vs%20claude-3-sonnet%2020%20rounds.txt">20 rounds</a> : llama3-8b-instruct <strong>8:5</strong> claude-3-sonnet, with 6 ties</li></ul><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/llama3-8b-instruct%20vs%20claude-3-sonnet%2020%20rounds.png" class=""><ul><li><a href="https://github.com/linkcd/rps-agent-game/blob/master/doc/game_history/llama3-8b-instruct%20vs%20claude-3-sonnet%2050%20rounds.txt">50 rounds</a> : llama3-8b-instruct <strong>16:20</strong> claude-3-sonnet, with 14 ties</li></ul><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/llama3-8b-instruct%20vs%20claude-3-sonnet%2050%20rounds.png" class=""><ul><li><a href="https://github.com/linkcd/rps-agent-game/blob/master/doc/game_history/llama3-8b-instruct%20vs%20claude-3-sonnet%20100%20rounds.txt">100 rounds</a> : llama3-8b-instruct <strong>29:55</strong> claude-3-sonnet, with 16 ties</li></ul><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/llama3-8b-instruct%20vs%20claude-3-sonnet%20100%20rounds.png" class=""><blockquote><p>Noticeable Patterns:<br>a) llama3-8b-instruct:<br>    - Shows a strong preference for Paper, playing it in 64 out of 100 rounds (64%).<br>    - Rarely plays Scissors, only 11 times throughout the game.<br>    - Tends to stick with Paper for long streaks, especially towards the end of the game.</p><p>b) claude-3-sonnet:<br>    - Demonstrates a clear preference for Scissors, playing it in 58 out of 100 rounds (58%).<br>    - Adapts its strategy over time, increasing its use of Scissors as it recognizes llama3-8b-instruct’s preference for Paper.<br>    - Plays Rock less frequently, only 19 times throughout the game.</p><p>c) Game Progression:<br>    - The game starts with more varied plays from both players.<br>    - As the game progresses, it becomes more predictable with llama3-8b-instruct primarily playing Paper and claude-3-sonnet countering with Scissors.<br>    - The last 30 rounds show an almost complete lock-in of this Paper vs Scissors pattern, heavily favoring claude-3-sonnet.</p></blockquote><p>Llama 3 developed an almost obsessive attachment to “Paper,” playing it 64% of the time. It’s like watching someone convince themselves they’ve found the perfect strategy, only to fall into their own trap. Claude-3-sonnet, meanwhile, showed its adaptive prowess by increasingly choosing Scissors, effectively counter-punching its way to victory.</p><h4 id="Game-4-OpenAI’s-GPT-4o-Mini-vs-Claude-3-Sonnet"><a href="#Game-4-OpenAI’s-GPT-4o-Mini-vs-Claude-3-Sonnet" class="headerlink" title="Game 4: OpenAI’s GPT-4o Mini vs Claude 3 Sonnet"></a>Game 4: OpenAI’s GPT-4o Mini vs Claude 3 Sonnet</h4><p>For our final match, we put <strong>OpenAI’s GPT-4 Mini</strong> against <strong>Claude 3 Sonnet</strong> for 100 rounds. </p><ul><li><a href="https://github.com/linkcd/rps-agent-game/blob/master/doc/game_history/openai-gpt-4o-mini%20vs%20claude-3-sonet.txt">100 rounds</a> : OpenAI-GPT-4o Mini <strong>22:48</strong> claude-3-sonnet, with 30 ties</li></ul><img src="/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/openai-gpt-4o-mini%20vs%20claude-3-sonet.png" class=""><blockquote><p>Noticeable Patterns:<br>a) openai-gpt-4o-mini:<br>    - Showed a strong preference for Rock, especially in the latter half of the game.<br>    - From round 55 onwards, openai-gpt-4o-mini played Rock almost exclusively (45 out of 46 times).<br>    - This predictable pattern was likely exploited by claude-3-sonnet.</p><p>b) claude-3-sonnet:<br>    - Displayed more varied play in the first half of the game.<br>    - Adapted its strategy in the second half, playing Paper much more frequently, likely in response to openai-gpt-4o-mini’s Rock preference.<br>    - From round 55 onwards, claude-3-sonnet alternated mostly between Paper and Scissors, with Paper being more frequent.</p><p>c) Game Dynamics:<br>    - The game was relatively balanced in the first half, with both players winning rounds and several ties.<br>    - In the second half, claude-3-sonnet gained a significant advantage by adapting to openai-gpt-4o-mini’s predictable play.<br>    - There was a streak of 15 consecutive wins for claude-3-sonnet from rounds 55 to 69, all countering openai-gpt-4o-mini’s Rock with Paper.</p><p>In conclusion, claude-3-sonnet demonstrated superior adaptability and strategy, particularly in the latter half of the game, leading to its decisive victory.</p></blockquote><h2 id="5-The-Winner-is-Claude-3-Sonnet"><a href="#5-The-Winner-is-Claude-3-Sonnet" class="headerlink" title="5. The Winner is: Claude 3 Sonnet"></a>5. The Winner is: Claude 3 Sonnet</h2><p>Therefore,  In our 100-round tournament, <strong>Claude 3 Sonnet</strong> proved to be the strongest player among the three AI models.</p><p>Let’s dive into the behavioral patterns that emerged during these AI showdowns. You might think Rock-Paper-Scissors is random, but our AI players showed some surprisingly distinctive quirks.</p><p><strong>Move Preferences and Pattern Recognition:</strong></p><ul><li>Llama 3 developed an almost obsessive fondness for Paper, using it in 64% of its moves</li><li>Claude 3 Sonnet showed a strategic preference for Scissors (58% of moves), but only after recognizing Llama’s Paper-heavy strategy</li><li>GPT-4 Mini began with balanced moves but shifted dramatically, moving from varied patterns early on to playing almost exclusively Rock in later rounds.</li></ul><p><strong>Memorable Streaks and Adaptations:</strong></p><ul><li>Most impressive comeback: Claude’s evolution from losing 8-5 in the 20 rounds game to dominating 55-29 over 100 rounds</li><li>Longest winning streak: Llama 3 (with memory) won 18 consecutive rounds against Doraemon by consistently countering with Paper</li><li>Most dramatic shift: GPT-4 Mini lost 15 consecutive rounds to Claude while stuck in a Rock-only pattern, showing how predictability can be costly</li></ul><p><strong>The “Personality Traits” That Emerged:</strong></p><ol><li>Llama 3 8B Instruct: The Stubborn Specialist</li></ol><ul><li>Tends to find a favorite move and stick with it</li><li>Shows remarkable consistency but poor adaptation</li><li>Like a chess player who’s mastered one opening but refuses to learn others</li></ul><ol start="2"><li>Claude 3 Sonnet: The Adaptive Strategist</li></ol><ul><li>Excels at pattern recognition</li><li>Willing to change strategies mid-game</li><li>Demonstrates superior long-term learning</li><li>Behaves like a poker player who carefully studies their opponent’s tells</li></ul><ol start="3"><li>GPT-4 Mini: The Reluctant Repeater</li></ol><ul><li>Begins with strategic diversity but transitions to fixed patterns</li><li>Shows remarkable shift from adaptable to inflexible play</li><li>Demonstrates how AI agent can devolve into repetitive behavior</li><li>Like a chess player who abandons their opening repertoire for a single, predictable move</li></ul><h2 id="6-Conclusions-Beyond-the-Game"><a href="#6-Conclusions-Beyond-the-Game" class="headerlink" title="6. Conclusions: Beyond the Game"></a>6. Conclusions: Beyond the Game</h2><p>Our AI Rock-Paper-Scissors tournament revealed two crucial insights:</p><p><strong>Memory Makes the Master</strong><br>The impact of memory on AI performance was striking. When given the ability to learn from past rounds, AI agents transformed from predictable players into strategic competitors. This dramatic improvement highlights how crucial historical context is for AI decision-making.</p><p><strong>Unique “Personalities” Emerge</strong><br>Perhaps most fascinating was watching distinct AI “personalities” develop during gameplay:<br>• Claude emerged as the adaptive strategist, constantly evolving its approach<br>• Llama showed stubborn dedication to preferred patterns<br>• GPT-4 demonstrated how even sophisticated AI can fall into rigid behaviors</p><p>These weren’t just random algorithms at work. Each AI model, despite having identical capabilities and instructions, developed its own unique “cognitive style” - much like human players would. This suggests something profound about artificial intelligence: even in simple games, AI systems reveal distinctive problem-solving approaches and decision-making patterns.</p><p>What started as a playful experiment with a children’s game ended up offering valuable insights into how different AI models think, learn, and adapt. These findings have implications far beyond Rock-Paper-Scissors, helping us better understand the unique characteristics and potential of various AI models.</p><p>Ready to explore AI behavior yourself? The code is open source at <a href="https://github.com/linkcd/rps-agent-game">github repo</a> - let the games begin!</p><h6 id="Disclaimer"><a href="#Disclaimer" class="headerlink" title="Disclaimer"></a>Disclaimer</h6><p><em>This article was crafted in collaboration with AI. I’d value your thoughts on how this article reads.</em></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-Introduction&quot;&gt;&lt;a href=&quot;#1-Introduction&quot; class=&quot;headerlink&quot; title=&quot;1. Introduction&quot;&gt;&lt;/a&gt;1. Introduction&lt;/h2&gt;&lt;p&gt;Imagine a world where AI agents aren’t working together to achieve a common goal. Instead, each agent is out to win the game of Rock-Paper-Scissors. The mission of each agent is straightforward: defeat the others. &lt;/p&gt;
&lt;p&gt;Can a machine strategize in a game of pure chance? And if it can, which model will emerge victorious? &lt;/p&gt;
&lt;p&gt;In order to answer that very question, I built a multi-agent system to host fully automated Rock-Paper-Scissors tournaments, pitting various AI models against one another to see who comes out on top. From OpenAI’s cutting-edge models to Meta’s Llama and Anthropic’s Claude, each agent brings its own “personality” and decision-making quirks to the table. &lt;/p&gt;
&lt;p&gt;This isn’t just an experiment in gaming; it’s also a showcase of the latest capabilities in multi-agent systems. Using &lt;a href=&quot;https://www.crewai.com/&quot;&gt;CrewAI&lt;/a&gt; and &lt;a href=&quot;https://langchain-ai.github.io/langgraph/&quot;&gt;LangGraph&lt;/a&gt;, it is easy to create AI agents and put them into complicated flows.&lt;/p&gt;
&lt;p&gt;In our games, we will test the following AI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct&quot;&gt;Llama3 8B Instruct&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.anthropic.com/news/claude-3-family&quot;&gt;Claude 3 Sonnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/&quot;&gt;OpenAI GPT 4o Mini&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;2-Architecture-and-Workflow&quot;&gt;&lt;a href=&quot;#2-Architecture-and-Workflow&quot; class=&quot;headerlink&quot; title=&quot;2. Architecture and Workflow&quot;&gt;&lt;/a&gt;2. Architecture and Workflow&lt;/h2&gt;&lt;p&gt;This project combines two popular frameworks: &lt;a href=&quot;https://langchain-ai.github.io/langgraph/&quot;&gt;LangGraph&lt;/a&gt; for workflow orchestration and &lt;a href=&quot;https://www.crewai.com/&quot;&gt;CrewAI&lt;/a&gt; for agent definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The workflow is built as a &lt;a href=&quot;https://langchain-ai.github.io/langgraph/concepts/multi_agent/&quot;&gt;multi-agent system&lt;/a&gt; using LangGraph’s graph structure&lt;/li&gt;
&lt;li&gt;Each AI agent is defined as a &lt;a href=&quot;https://docs.crewai.com/concepts/crews&quot;&gt;Crew&lt;/a&gt;  using CrewAI.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The graph and crew definition can be found in the &lt;a href=&quot;https://github.com/linkcd/rps-agent-game/tree/master/src&quot;&gt;src folder&lt;/a&gt; in the source code &lt;a href=&quot;https://github.com/linkcd/rps-agent-game&quot;&gt;github repo&lt;/a&gt;.&lt;/p&gt;
&lt;img src=&quot;/2024/12/03/Build-a-Multi-Agent-System-to-Discover-the-Top-AI-Model-for-Rock-Paper-Scissors-Games/generated_graph.png&quot; class=&quot;&quot; title=&quot;generated graph by langgraph&quot;&gt;

&lt;p&gt;&lt;strong&gt;Workflow&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In each round, two player agents make their moves independently and in parallel. They have access to the history of previous rounds, allowing them to analyze patterns and decide on the best move.&lt;/li&gt;
&lt;li&gt;After the players make their moves, a judge agent determines the winner of the round.&lt;/li&gt;
&lt;li&gt;The system checks if the criteria for determining the final winner have been met (e.g., reaching the specified number of rounds, or a player winning 3 out of 5 rounds.).&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Criteria Not Met&lt;/strong&gt;: If the criteria are not met, another round begins.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If the criteria are met&lt;/strong&gt;: The final winner is announced, and a post-game analysis is performed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After running hundreds of matches, the results were nothing short of interesting – and sometimes hilarious. Let’s look at what we discovered.&lt;/p&gt;</summary>
    
    
    
    
    <category term="AI" scheme="https://feng.lu/tags/AI/"/>
    
    <category term="GenAI" scheme="https://feng.lu/tags/GenAI/"/>
    
    <category term="Generative AI" scheme="https://feng.lu/tags/Generative-AI/"/>
    
    <category term="AI Agent" scheme="https://feng.lu/tags/AI-Agent/"/>
    
    <category term="LangGraph" scheme="https://feng.lu/tags/LangGraph/"/>
    
    <category term="CrewAI" scheme="https://feng.lu/tags/CrewAI/"/>
    
    <category term="OpenAI" scheme="https://feng.lu/tags/OpenAI/"/>
    
    <category term="Llama" scheme="https://feng.lu/tags/Llama/"/>
    
    <category term="Claude" scheme="https://feng.lu/tags/Claude/"/>
    
    <category term="LLM" scheme="https://feng.lu/tags/LLM/"/>
    
    <category term="Game" scheme="https://feng.lu/tags/Game/"/>
    
  </entry>
  
  <entry>
    <title>Implementing Secret-less Access to Azure and AWS with Azure Managed Identities and AWS IAM</title>
    <link href="https://feng.lu/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/"/>
    <id>https://feng.lu/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/</id>
    <published>2024-09-18T12:49:21.000Z</published>
    <updated>2025-03-28T09:05:16.791Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-User-case"><a href="#1-User-case" class="headerlink" title="1. User case"></a>1. User case</h2><p>Nowadays, it is common for companies to operate in multi-cloud environments, such as Azure and AWS. They often use Microsoft Entra ID (formerly Azure Active Directory) as their centralized identity provider (IdP), managing identities for both <strong>human users</strong> and <strong>applications</strong>. They would like to use the Entra ID identities to access resources in AWS.</p><p>Establishing human user identity access across Azure and AWS is straightforward. The IT department can use <a href="https://aws.amazon.com/iam/identity-center/">AWS IAM Identity Center</a> to allow users from Microsoft Entra ID to sign-in to the AWS Management Console with Single Sign-On (SSO) via their browser. This integration simplifies authentication, offering a seamless and secure user experience across both Azure and AWS environments. For more information, you can read <a href="https://docs.aws.amazon.com/singlesignon/latest/userguide/idp-microsoft-entra.html">this document</a>.</p><p>However, the browser-based SSO approach for human users does not apply to applications.</p><p>For applications, developers follow security best practices by using cloud-native IAM (Identity and Access Management) mechanisms to manage resource access. In AWS, this mechanism is <a href="https://aws.amazon.com/iam/">AWS IAM</a>, while in Azure, it is typically <a href="https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview">Azure Managed Identity</a>. For example, by leveraging Azure Managed Identity, developers can build applications in Azure without the need to manage secrets or keys.</p><p>This approach is known as <strong>secretless access</strong> to cloud resources. </p><p>AWS IAM and Azure Managed Identity work well within their respective platforms, but there are cross-cloud scenarios where a workload in one cloud needs to access resources in another. For instance, an Azure Function might need to save data to both an Azure Storage account and an AWS S3 bucket for cross-cloud backup. The Azure Function uses Managed Identity to access the Azure Storage account. For accessing S3, the developer could create an IAM user and store the IAM user credentials. However, there is a better way to achieve secretless access to both Azure and AWS resources using the same Azure Managed Identity.</p><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/problem.png" class="" title="The problem of using Azure Managed Identity to access S3"><h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><p>In AWS, there are multiple ways to request temporary, limited-privilege credentials by using <a href="https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html">AWS Security Token Service (AWS STS)</a>, such as <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithSAML.html">AssumeRoleWithSAML</a> and <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html">AssumeRoleWithWebIdentity</a>.</p><p>The post will explain how to use <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html.">AssumeRoleWithWebIdentity</a> and <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-idp_oidc.html">IAM Web Identity Role</a> to extend the permissions of the same Azure Managed Identity to also access AWS resources.  </p><p>We will build an Azure Function with a managed identity, either User-Assigned Managed Identity (UAMI) or System-Assigned Managed Identity (SAMI), to read objects from both an Azure Storage account and an AWS S3 bucket. This same managed identity will work in both Azure and AWS, eliminating the need to manage additional secrets such as AWS IAM user credentials.</p><p>The source code is published at github <a href="https://github.com/linkcd/Secretless-cross-cloud-access">https://github.com/linkcd/Secretless-cross-cloud-access</a></p><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/architecture.png" class="" title="Architecture"><span id="more"></span><h2 id="3-Step-by-step-instruction"><a href="#3-Step-by-step-instruction" class="headerlink" title="3. Step by step instruction"></a>3. Step by step instruction</h2><h3 id="3-1-Create-Azure-functions-and-managed-identities"><a href="#3-1-Create-Azure-functions-and-managed-identities" class="headerlink" title="3.1 Create Azure functions and managed identities"></a>3.1 Create Azure functions and managed identities</h3><ol><li>Create function <strong>CrossCloudAccessFunction-SAMI</strong>: System-Assigned Managed Identity (SAMI)</li></ol><ul><li>In the management panel, enable SAMI</li></ul><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/azure%20function%20sami.png" class=""><ol start="2"><li>Create function <strong>CrossCloudAccessFunction-UAMI</strong>: User-Assigned Managed Identity (UAMI)</li></ol><ul><li>Create a UAMI named <em>UAMI-CrossCloudAccess-Identity</em> </li><li>Assign the identity <em>UAMI-CrossCloudAccess-Identity</em> to Azure function <em>CrossCloudAccessFunction-UAMI</em></li></ul><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/azure%20function%20uami.png" class=""><p>Note: it is possible to have multiple UAMI or mix between UAMI&#x2F;SAMI for one Azure function. Depends on which credential (either SAMI, or one of the UAMIs) you use for calling API, you will have different permission to access different resources, depends on what credential you create in the code.</p><h3 id="3-2-Look-for-the-Object-IDs-of-SAMI-and-UAMI"><a href="#3-2-Look-for-the-Object-IDs-of-SAMI-and-UAMI" class="headerlink" title="3.2 Look for the Object IDs of SAMI and UAMI"></a>3.2 Look for the Object IDs of SAMI and UAMI</h3><p>We need to take note of the Object IDs of the SAMI and UAMI. These IDs will be used when assign access to an Azure application role. We also need to take note of the Entra ID tenant ID.</p><ol><li><strong>SAMI</strong> Object ID</li></ol><ul><li>Go to Azure Portal -&gt; Entra ID -&gt; Enterprise applications</li><li>Remove the filter “Application type &#x3D;&#x3D; Enterprise applications”</li><li>Search for the name of Azure Function with SAMI: <em>CrossCloudAccessFunction-SAMI</em></li><li>Take note of the Object ID. In this case “SAMI-object-id-a43c24bd12f5”</li></ul><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/SAMI%20object%20id.png" class=""><ol start="2"><li><strong>UAMI</strong> Object ID</li></ol><ul><li>Go to Azure Portal -&gt; Managed Identity -&gt; <em>UAMI-CrossCloudAccess-Identity</em></li><li>You can directly get the client ID of UAMI in its own property page. </li><li>In this case, it is “UAMI-object-id-0293fe81ee59”</li></ul><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/UAMI%20object%20id.png" class=""><ol start="3"><li>Get Entra ID tenant</li></ol><ul><li><a href="https://learn.microsoft.com/en-us/entra/fundamentals/how-to-find-tenant">Find your Entra ID tenant ID</a></li></ul><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/tenant%20id.png" class=""><h3 id="3-3-Create-Azure-application-and-assign-managed-identities-to-its-role"><a href="#3-3-Create-Azure-application-and-assign-managed-identities-to-its-role" class="headerlink" title="3.3 Create Azure application and assign managed identities to its role"></a>3.3 Create Azure application and assign managed identities to its role</h3><ol><li>Go to Azure Portal -&gt; Entra Id -&gt; Enterprise applications -&gt; New Application </li><li>Select “Create your own application” and name it as “AWS-Federation-App”</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/create%20new%20entra%20app.png" class=""><ol start="3"><li>(<strong>Important</strong>) Turn on the “User assignment required” to make sure only identities assigned to the application can get a token for the application audience. It means users and other apps or services must first be assigned this application before being able to access it.</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/enable%20assignment%20required.png" class=""><ol start="4"><li>Create an application role “AssumeAWSRole”</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/create%20application%20role.png" class=""><ol start="5"><li>Add an Application ID URI “api:&#x2F;&#x2F;AWS-Federation-App”</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/create%20app%20id%20uri.png" class=""><ol start="6"><li>Finally, assign the managed identities access to the application role<br>Follow the steps in the <a href="https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/how-to-assign-app-role-managed-identity?pivots=identity-mi-app-role-powershell">document</a> to assign the managed identities access to the application role</li></ol><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Your tenant ID (in the Azure portal, under Azure Active Directory &gt; Overview).</span></span><br><span class="line"><span class="variable">$tenantID</span> = <span class="string">&#x27;&lt;tenant-id&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">Connect-MgGraph</span> <span class="literal">-TenantId</span> <span class="variable">$tenantId</span> <span class="literal">-Scopes</span> <span class="string">&#x27;Application.Read.All&#x27;</span>,<span class="string">&#x27;Application.ReadWrite.All&#x27;</span>,<span class="string">&#x27;AppRoleAssignment.ReadWrite.All&#x27;</span>,<span class="string">&#x27;Directory.AccessAsUser.All&#x27;</span>,<span class="string">&#x27;Directory.Read.All&#x27;</span>,<span class="string">&#x27;Directory.ReadWrite.All&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the managed identity object Id of SAMI or UAMI</span></span><br><span class="line"><span class="variable">$managedIdentityObjectId</span> = <span class="string">&quot;SAMI-object-id-a43c24bd12f5&quot;</span> <span class="comment">#SAMI</span></span><br><span class="line"><span class="comment"># $managedIdentityObjectId = &quot;UAMI-object-id-0293fe81ee59&quot; #UAMI</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The name of the server app that exposes the app role.</span></span><br><span class="line"><span class="variable">$serverApplicationName</span> = <span class="string">&quot;AWS-Federation-App&quot;</span> <span class="comment">#Entra ID Enterprise App Name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The name of the app role that the managed identity should be assigned to.</span></span><br><span class="line"><span class="variable">$appRoleName</span> = <span class="string">&#x27;AssumeAWSRole&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Look up the details about the server app&#x27;s service principal and app role.</span></span><br><span class="line"><span class="variable">$serverServicePrincipal</span> = (<span class="built_in">Get-MgServicePrincipal</span> <span class="literal">-Filter</span> <span class="string">&quot;DisplayName eq &#x27;<span class="variable">$serverApplicationName</span>&#x27;&quot;</span>)</span><br><span class="line"><span class="variable">$serverServicePrincipalObjectId</span> = <span class="variable">$serverServicePrincipal</span>.Id</span><br><span class="line"><span class="variable">$appRoleId</span> = (<span class="variable">$serverServicePrincipal</span>.AppRoles | <span class="built_in">Where-Object</span> &#123;<span class="variable">$_</span>.Value <span class="operator">-eq</span> <span class="variable">$appRoleName</span> &#125;).Id</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assign the managed identity access to the app role.</span></span><br><span class="line"><span class="built_in">New-MgServicePrincipalAppRoleAssignment</span> <span class="literal">-ServicePrincipalId</span> <span class="variable">$serverServicePrincipalObjectId</span> <span class="literal">-PrincipalId</span> <span class="variable">$managedIdentityObjectId</span> <span class="literal">-ResourceId</span> <span class="variable">$serverServicePrincipalObjectId</span> <span class="literal">-AppRoleId</span> <span class="variable">$appRoleId</span></span><br></pre></td></tr></table></figure><ol start="7"><li>Verify that the UAMI and SAMI are users of the application</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/entra%20id%20app%20users.png" class=""><h3 id="3-4-Setup-federation-between-the-Azure-application-role-and-AWS-IAM"><a href="#3-4-Setup-federation-between-the-Azure-application-role-and-AWS-IAM" class="headerlink" title="3.4 Setup federation between the Azure application role and AWS IAM"></a>3.4 Setup federation between the Azure application role and AWS IAM</h3><ol><li>Go to AWS console, then head to IAM</li><li>Click “Identity providers” and add an “OpenID Connect” provider</li><li><strong>Provider URL</strong>: <a href="https://sts.windows.net/[your-azure-tenant-id]/">https://sts.windows.net/[your-azure-tenant-id]/</a> (note: make sure you add “&#x2F;“ at the end of the URL) </li><li><strong>Audience</strong>: Application ID URI “api:&#x2F;&#x2F;AWS-Federation-App”</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/add%20idp%20to%20aws.png" class=""><h3 id="3-5-Create-AWS-S3-bucket-and-related-AWS-IAM-Role-for-accessing-S3"><a href="#3-5-Create-AWS-S3-bucket-and-related-AWS-IAM-Role-for-accessing-S3" class="headerlink" title="3.5 Create AWS S3 bucket and related AWS IAM Role for accessing S3"></a>3.5 Create AWS S3 bucket and related AWS IAM Role for accessing S3</h3><ol><li>Create an AWS S3 bucket</li><li>Go to AWS IAM, create new Role for access S3</li><li><strong>Trusted entity</strong>: the OpenID Connect Idp that we just created</li><li><strong>Audience</strong>: “api:&#x2F;&#x2F;AWS-Federation-App”</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/s3%20role%201.png" class=""><ol start="5"><li>Assigning the s3 read-only permission (<strong>NOTE: It grants the read-only permission to ALL s3 buckets. Do NOT use it in your production workload</strong>)</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/s3%20role%202.png" class=""><ol start="6"><li>Name this role as “<strong>S3AccessRoleFromAzure</strong>“</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/s3%20role%203.png" class=""><ol start="7"><li>Take notes of ARN of these AWS IAM Roles. Azure function need it for assuming the role.</li></ol><ul><li>arn:aws:iam::[YOUR_AWS_ACCOUNT_NUMBER]:role&#x2F;S3AccessRoleFromAzure</li></ul>  <img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/sa%20role%20arn.png" class=""><h3 id="3-6-Create-Azure-storage-account-and-setup-permission-for-managed-identities"><a href="#3-6-Create-Azure-storage-account-and-setup-permission-for-managed-identities" class="headerlink" title="3.6 Create Azure storage account and setup permission for managed identities"></a>3.6 Create Azure storage account and setup permission for managed identities</h3><ol><li>Create an Azure storage account and upload some test files into a container named <em>mycontainer</em>.</li><li>In the storage account management panel, grant UAMI and SAMI “Storage Blob Data Contributor&#x2F;Owner” Role<br>(Note, the simple “Owner” role of storage account top level is NOT enough for read&#x2F;write blobs in container), see <a href="https://learn.microsoft.com/en-us/azure/storage/common/storage-auth-aad-app?tabs=dotnet">document</a>)</li></ol><h3 id="3-7-Update-Azure-function-source-code"><a href="#3-7-Update-Azure-function-source-code" class="headerlink" title="3.7 Update Azure function source code"></a>3.7 Update Azure function source code</h3><p>Now we got everything ready, time to work on the source code of Azure functions.</p><p>Both SAMI and UAMI based functions use the <a href="https://github.com/linkcd/Secretless-cross-cloud-access/tree/main/AzureFunction">same code base</a>, as there are only a difference of getting AzureCredential between SAMI and UAMI. If you know for sure which type of managed identity you are using, you can remove the if&#x2F;else condition to optimize the code.</p><p>In addition to the <a href="https://github.com/linkcd/Secretless-cross-cloud-access/blob/main/AzureFunction/run.csx">run.csx</a>, also use <a href="https://github.com/linkcd/Secretless-cross-cloud-access/blob/main/AzureFunction/function.proj">function.proj</a> to include AWS SDK for calling AWS APIs.</p><p>screenshot of run.csx</p><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/azure%20function%20run%20csx.png" class="" title="run.csx"><p>screenshot of function.proj</p><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/azure%20function%20proj.png" class="" title="function.proj"><h3 id="3-8-Test"><a href="#3-8-Test" class="headerlink" title="3.8 Test"></a>3.8 Test</h3><ol><li>Now we have files both in Azure storage account and in AWS S3</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/azure%20files.png" class=""><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/s3%20files.png" class=""><ol start="2"><li>Call the Azure Functions<br>Use the sample input Json for <a href="https://github.com/linkcd/Secretless-cross-cloud-access/blob/main/AzureFunction/sample-request-UAMI.json">UAMI</a> and <a href="https://github.com/linkcd/Secretless-cross-cloud-access/blob/main/AzureFunction/sample-request-SAMI.json">SAMI</a> when you are calling the Azure Functions. (Remember to replace the placeholder parameters with correct values.)</li></ol><p>The azure function prints the JWT in the log, it looks like</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;aud&quot;</span><span class="punctuation">:</span> <span class="string">&quot;api://AWS-Federation-App&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;iss&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://sts.windows.net/&lt;azure-tenant-id&gt;/&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;idp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://sts.windows.net/&lt;azure-tenant-id&gt;/&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;appid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&lt;managed-identity-client-id&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;oid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&lt;managed-identity-object-id&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;roles&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;AssumeAWSRole&quot;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;sub&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&lt;managed-identity-object-id&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  ...</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>Successfully load data from both Azure and S3</li></ol><img src="/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/demo%20screenshot.png" class=""><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By following this post, you can continue using Entra ID as a single IdP, covering both AWS and Azure. This approach not only reduces management overhead but also enhances security in a multi-cloud scenario.</p><h2 id="Also-read"><a href="#Also-read" class="headerlink" title="Also read:"></a>Also read:</h2><ul><li><a href="https://blog.identitydigest.com/azuread-access-aws/">Access AWS resources using Azure AD Managed Identity</a></li><li><a href="https://aws.amazon.com/blogs/apn/automating-openid-connect-based-aws-iam-web-identity-roles-with-microsoft-entra-id/">Automating OpenID Connect-Based AWS IAM Web Identity Roles with Microsoft Entra ID</a></li></ul><h6 id="Disclaimer"><a href="#Disclaimer" class="headerlink" title="Disclaimer"></a>Disclaimer</h6><p><em>This blog is intended solely for educational purposes and reflects the personal views and opinions of the author. The content provided here is not intended to be, nor should it be construed as, official guidelines or professional advice on security matters. Readers are encouraged to seek professional guidance for specific security concerns. The author assumes no responsibility or liability for any errors or omissions in the content of this blog.</em></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-User-case&quot;&gt;&lt;a href=&quot;#1-User-case&quot; class=&quot;headerlink&quot; title=&quot;1. User case&quot;&gt;&lt;/a&gt;1. User case&lt;/h2&gt;&lt;p&gt;Nowadays, it is common for companies to operate in multi-cloud environments, such as Azure and AWS. They often use Microsoft Entra ID (formerly Azure Active Directory) as their centralized identity provider (IdP), managing identities for both &lt;strong&gt;human users&lt;/strong&gt; and &lt;strong&gt;applications&lt;/strong&gt;. They would like to use the Entra ID identities to access resources in AWS.&lt;/p&gt;
&lt;p&gt;Establishing human user identity access across Azure and AWS is straightforward. The IT department can use &lt;a href=&quot;https://aws.amazon.com/iam/identity-center/&quot;&gt;AWS IAM Identity Center&lt;/a&gt; to allow users from Microsoft Entra ID to sign-in to the AWS Management Console with Single Sign-On (SSO) via their browser. This integration simplifies authentication, offering a seamless and secure user experience across both Azure and AWS environments. For more information, you can read &lt;a href=&quot;https://docs.aws.amazon.com/singlesignon/latest/userguide/idp-microsoft-entra.html&quot;&gt;this document&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, the browser-based SSO approach for human users does not apply to applications.&lt;/p&gt;
&lt;p&gt;For applications, developers follow security best practices by using cloud-native IAM (Identity and Access Management) mechanisms to manage resource access. In AWS, this mechanism is &lt;a href=&quot;https://aws.amazon.com/iam/&quot;&gt;AWS IAM&lt;/a&gt;, while in Azure, it is typically &lt;a href=&quot;https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview&quot;&gt;Azure Managed Identity&lt;/a&gt;. For example, by leveraging Azure Managed Identity, developers can build applications in Azure without the need to manage secrets or keys.&lt;/p&gt;
&lt;p&gt;This approach is known as &lt;strong&gt;secretless access&lt;/strong&gt; to cloud resources. &lt;/p&gt;
&lt;p&gt;AWS IAM and Azure Managed Identity work well within their respective platforms, but there are cross-cloud scenarios where a workload in one cloud needs to access resources in another. For instance, an Azure Function might need to save data to both an Azure Storage account and an AWS S3 bucket for cross-cloud backup. The Azure Function uses Managed Identity to access the Azure Storage account. For accessing S3, the developer could create an IAM user and store the IAM user credentials. However, there is a better way to achieve secretless access to both Azure and AWS resources using the same Azure Managed Identity.&lt;/p&gt;
&lt;img src=&quot;/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/problem.png&quot; class=&quot;&quot; title=&quot;The problem of using Azure Managed Identity to access S3&quot;&gt;

&lt;h2 id=&quot;2-Solution&quot;&gt;&lt;a href=&quot;#2-Solution&quot; class=&quot;headerlink&quot; title=&quot;2. Solution&quot;&gt;&lt;/a&gt;2. Solution&lt;/h2&gt;&lt;p&gt;In AWS, there are multiple ways to request temporary, limited-privilege credentials by using &lt;a href=&quot;https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html&quot;&gt;AWS Security Token Service (AWS STS)&lt;/a&gt;, such as &lt;a href=&quot;https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithSAML.html&quot;&gt;AssumeRoleWithSAML&lt;/a&gt; and &lt;a href=&quot;https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html&quot;&gt;AssumeRoleWithWebIdentity&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The post will explain how to use &lt;a href=&quot;https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html.&quot;&gt;AssumeRoleWithWebIdentity&lt;/a&gt; and &lt;a href=&quot;https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-idp_oidc.html&quot;&gt;IAM Web Identity Role&lt;/a&gt; to extend the permissions of the same Azure Managed Identity to also access AWS resources.  &lt;/p&gt;
&lt;p&gt;We will build an Azure Function with a managed identity, either User-Assigned Managed Identity (UAMI) or System-Assigned Managed Identity (SAMI), to read objects from both an Azure Storage account and an AWS S3 bucket. This same managed identity will work in both Azure and AWS, eliminating the need to manage additional secrets such as AWS IAM user credentials.&lt;/p&gt;
&lt;p&gt;The source code is published at github &lt;a href=&quot;https://github.com/linkcd/Secretless-cross-cloud-access&quot;&gt;https://github.com/linkcd/Secretless-cross-cloud-access&lt;/a&gt;&lt;/p&gt;
&lt;img src=&quot;/2024/09/18/How-to-secretless-access-Azure-and-AWS-resources-with-Azure-managed-identity-and-AWS-IAM/architecture.png&quot; class=&quot;&quot; title=&quot;Architecture&quot;&gt;</summary>
    
    
    
    
    <category term="AWS" scheme="https://feng.lu/tags/AWS/"/>
    
    <category term="Azure" scheme="https://feng.lu/tags/Azure/"/>
    
    <category term="Security" scheme="https://feng.lu/tags/Security/"/>
    
    <category term="Idp" scheme="https://feng.lu/tags/Idp/"/>
    
    <category term="IAM" scheme="https://feng.lu/tags/IAM/"/>
    
    <category term="Managed Identity" scheme="https://feng.lu/tags/Managed-Identity/"/>
    
    <category term="Entra ID" scheme="https://feng.lu/tags/Entra-ID/"/>
    
  </entry>
  
  <entry>
    <title>AWS Blog - Build your multilingual personal calendar assistant with Amazon Bedrock and AWS Step Functions</title>
    <link href="https://feng.lu/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/"/>
    <id>https://feng.lu/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/</id>
    <published>2024-07-04T08:50:24.000Z</published>
    <updated>2025-03-28T17:32:40.954Z</updated>
    
    <content type="html"><![CDATA[<p>Check out <a href="https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/">my latest blog post</a> on AWS official AI&#x2F;ML blog channel.</p><p>“Foreigners and expats living outside of their home country deal with a large number of emails in various languages daily. They often find themselves struggling with language barriers when it comes to setting up reminders for events like business gatherings and customer meetings. To solve this problem, this post shows you how to apply AWS services such as Amazon Bedrock, AWS Step Functions, and Amazon Simple Email Service (Amazon SES) to build a fully-automated multilingual calendar artificial intelligence (AI) assistant. It understands the incoming messages, translates them to the preferred language, and automatically sets up calendar reminders.”</p><p>Happy reading!</p><p><a href="https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/"><img src="/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/aws%20blog.png" class=""></a></p><p><strong>Blog address</strong>: <a href="https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/">https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/</a><br><strong>Source code</strong>: <a href="https://github.com/aws-samples/build-multilingual-calendar-assistant-with-amazon-bedrock-and-aws-step-functions">https://github.com/aws-samples/build-multilingual-calendar-assistant-with-amazon-bedrock-and-aws-step-functions</a>  </p><span id="more"></span><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture:"></a>Architecture:</h2><img src="/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/Architecture.png" class=""><h2 id="Example-emails-generated-by-the-solution"><a href="#Example-emails-generated-by-the-solution" class="headerlink" title="Example emails generated by the solution"></a>Example emails generated by the solution</h2><ol><li>Generated calendar reminder from an email in Chinese</li></ol><img src="/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/chinese%20example.png" class=""><ol start="2"><li>Generated calendar reminder from an email in Norwegian</li></ol><img src="/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/norsk%20example.png" class="">]]></content>
    
    
    <summary type="html">&lt;p&gt;Check out &lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/&quot;&gt;my latest blog post&lt;/a&gt; on AWS official AI&amp;#x2F;ML blog channel.&lt;/p&gt;
&lt;p&gt;“Foreigners and expats living outside of their home country deal with a large number of emails in various languages daily. They often find themselves struggling with language barriers when it comes to setting up reminders for events like business gatherings and customer meetings. To solve this problem, this post shows you how to apply AWS services such as Amazon Bedrock, AWS Step Functions, and Amazon Simple Email Service (Amazon SES) to build a fully-automated multilingual calendar artificial intelligence (AI) assistant. It understands the incoming messages, translates them to the preferred language, and automatically sets up calendar reminders.”&lt;/p&gt;
&lt;p&gt;Happy reading!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/&quot;&gt;&lt;img src=&quot;/2024/07/04/AWS-Blog-Build-your-multilingual-personal-calendar-assistant-with-Amazon-Bedrock-and-AWS-Step-Functions/aws%20blog.png&quot; class=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blog address&lt;/strong&gt;: &lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/&quot;&gt;https://aws.amazon.com/blogs/machine-learning/build-your-multilingual-personal-calendar-assistant-with-amazon-bedrock-and-aws-step-functions/&lt;/a&gt;&lt;br&gt;&lt;strong&gt;Source code&lt;/strong&gt;: &lt;a href=&quot;https://github.com/aws-samples/build-multilingual-calendar-assistant-with-amazon-bedrock-and-aws-step-functions&quot;&gt;https://github.com/aws-samples/build-multilingual-calendar-assistant-with-amazon-bedrock-and-aws-step-functions&lt;/a&gt;  &lt;/p&gt;</summary>
    
    
    
    
    <category term="AWS" scheme="https://feng.lu/tags/AWS/"/>
    
    <category term="AI" scheme="https://feng.lu/tags/AI/"/>
    
    <category term="GenAI" scheme="https://feng.lu/tags/GenAI/"/>
    
    <category term="Generative AI" scheme="https://feng.lu/tags/Generative-AI/"/>
    
    <category term="AI Agent" scheme="https://feng.lu/tags/AI-Agent/"/>
    
    <category term="Amazon Bedrock" scheme="https://feng.lu/tags/Amazon-Bedrock/"/>
    
    <category term="AWS Step Functions" scheme="https://feng.lu/tags/AWS-Step-Functions/"/>
    
  </entry>
  
  <entry>
    <title>AWS Blog - Manage IoT device state anywhere using AWS IoT Device Shadow service and AWS IoT Greengrass</title>
    <link href="https://feng.lu/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/"/>
    <id>https://feng.lu/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/</id>
    <published>2023-05-23T08:34:20.000Z</published>
    <updated>2025-03-28T09:05:16.841Z</updated>
    
    <content type="html"><![CDATA[<p>Discover <a href="https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/">my latest blog post</a> on AWS official blog channel, where I delve into managing IoT devices from anywhere! Whether you’re interested in a humble Raspberry Pi application or eager to explore broader applications like home automation or industrial IoT solutions, this post has got you started.</p><p>Happy reading!</p><p><a href="https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/"><img src="/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/AWS%20IoT%20Blog.png" class=""></a></p><p><strong>Blog address</strong>: <a href="https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/">https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/</a><br><strong>Source code</strong>: <a href="https://github.com/aws-samples/manage-IoT-device-using-device-shadow-blog">https://github.com/aws-samples/manage-IoT-device-using-device-shadow-blog</a> </p><span id="more"></span><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture:"></a>Architecture:</h2><img src="/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/Device-shadow-architecture.png" class=""><h2 id="Demo-1-Update-the-device-locally-by-using-joystick"><a href="#Demo-1-Update-the-device-locally-by-using-joystick" class="headerlink" title="Demo 1: Update the device locally by using joystick"></a>Demo 1: Update the device locally by using joystick</h2><img src="/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/use-joystick-to-update-the-number.gif" class=""><h2 id="Demo-2-Update-the-device-remotely-by-updating-device-shadow-document-in-cloud"><a href="#Demo-2-Update-the-device-remotely-by-updating-device-shadow-document-in-cloud" class="headerlink" title="Demo 2: Update the device remotely by updating device shadow document in cloud"></a>Demo 2: Update the device remotely by updating device shadow document in cloud</h2><img src="/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/Update-the-device-remotely-by-updating-device-shadow-document-in-cloud.gif" class="">]]></content>
    
    
    <summary type="html">&lt;p&gt;Discover &lt;a href=&quot;https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/&quot;&gt;my latest blog post&lt;/a&gt; on AWS official blog channel, where I delve into managing IoT devices from anywhere! Whether you’re interested in a humble Raspberry Pi application or eager to explore broader applications like home automation or industrial IoT solutions, this post has got you started.&lt;/p&gt;
&lt;p&gt;Happy reading!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/&quot;&gt;&lt;img src=&quot;/2023/05/23/Manage-IoT-device-state-anywhere-using-AWS-IoT-services/AWS%20IoT%20Blog.png&quot; class=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blog address&lt;/strong&gt;: &lt;a href=&quot;https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/&quot;&gt;https://aws.amazon.com/blogs/iot/manage-iot-device-state-anywhere/&lt;/a&gt;&lt;br&gt;&lt;strong&gt;Source code&lt;/strong&gt;: &lt;a href=&quot;https://github.com/aws-samples/manage-IoT-device-using-device-shadow-blog&quot;&gt;https://github.com/aws-samples/manage-IoT-device-using-device-shadow-blog&lt;/a&gt; &lt;/p&gt;</summary>
    
    
    
    
    <category term="AWS" scheme="https://feng.lu/tags/AWS/"/>
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="Raspberry Pi" scheme="https://feng.lu/tags/Raspberry-Pi/"/>
    
    <category term="AWS IoT Core" scheme="https://feng.lu/tags/AWS-IoT-Core/"/>
    
    <category term="AWS IoT Greengrass" scheme="https://feng.lu/tags/AWS-IoT-Greengrass/"/>
    
    <category term="Device Shadow" scheme="https://feng.lu/tags/Device-Shadow/"/>
    
  </entry>
  
  <entry>
    <title>AWS Step Functions with ECS Anywhere on NanoPi Sample</title>
    <link href="https://feng.lu/2022/02/02/AWS-Step-Function-with-ECS-Anywhere-on-NanoPi-Sample/"/>
    <id>https://feng.lu/2022/02/02/AWS-Step-Function-with-ECS-Anywhere-on-NanoPi-Sample/</id>
    <published>2022-02-02T13:31:24.000Z</published>
    <updated>2025-03-28T09:05:16.459Z</updated>
    
    <content type="html"><![CDATA[<p>This is a demo solution that is using <a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a> and <a href="https://aws.amazon.com/ecs/Anywhere/">ECS Anywhere</a> to complete a simple data processing task by using cloud orchestration (Step Functions) and local computing resources (a NanoPi). </p><h2 id="Data-flow"><a href="#Data-flow" class="headerlink" title="Data flow"></a>Data flow</h2><ol><li>User upload a file to a s3 bucket</li><li>S3 triggers step functions via cloudtrail and event bridge</li><li>Event bridge triggers a step function state machine</li><li>State machine triggers a ECS Anywhere task to download the file from s3 to local (to do some processing), if file name matches condition</li></ol><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><img src="/2022/02/02/AWS-Step-Function-with-ECS-Anywhere-on-NanoPi-Sample/architecture.png" class="" title="architecture"><h2 id="NanoPi-that-runs-ECS-Anywhere"><a href="#NanoPi-that-runs-ECS-Anywhere" class="headerlink" title="NanoPi that runs ECS Anywhere"></a>NanoPi that runs ECS Anywhere</h2><img src="/2022/02/02/AWS-Step-Function-with-ECS-Anywhere-on-NanoPi-Sample/nanopi.jpg" class="" title="nano pi"><p><a href="https://wiki.friendlyarm.com/wiki/index.php/NanoPi_NEO2">NanoPi Neo2</a> with LED hat in my home office, running AWS ECS Anywhere.</p><span id="more"></span><h2 id="Source-code"><a href="#Source-code" class="headerlink" title="Source code"></a>Source code</h2><p>All source code can be found at <a href="https://github.com/linkcd/step-function-with-ecs-Anywhere-example">https://github.com/linkcd/step-function-with-ecs-Anywhere-example</a></p><h2 id="1-Build-a-docker-image-as-the-ECS-Anywhere-task"><a href="#1-Build-a-docker-image-as-the-ECS-Anywhere-task" class="headerlink" title="1. Build a docker image as the ECS Anywhere task"></a>1. Build a docker image as the ECS Anywhere task</h2><p>As in this demo, the ecs Anywhere is running on a Nanopi, it should be build on the Pi as it is ARM architecture</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In nano pi ssh</span></span><br><span class="line"><span class="built_in">cd</span> ./container-for-ecs-task</span><br><span class="line">docker build -t linkcd/s3downloader:arm .</span><br><span class="line">docker login</span><br><span class="line">docker push linkcd/s3downloader:arm </span><br></pre></td></tr></table></figure><p>Then push to public repository so ECS cluster can download (public docker hub or private ECR)</p><h2 id="2-Setup-ECS-Anywhere-and-tasks"><a href="#2-Setup-ECS-Anywhere-and-tasks" class="headerlink" title="2. Setup ECS Anywhere and tasks"></a>2. Setup ECS Anywhere and tasks</h2><ul><li>Setup ECS Anywhere cluster on Nanopi</li><li>Create an ECS execution role that has permission to download file from s3</li><li>Create an ECS task (see <a href="https://github.com/linkcd/step-function-with-ecs-Anywhere-example/blob/master/ecs-task-definition.json">ecs-task-definition.json</a>) that refers to linkcd&#x2F;s3downloader:arm image</li></ul><h2 id="3-Create-a-step-function-state-machine"><a href="#3-Create-a-step-function-state-machine" class="headerlink" title="3. Create a step function state machine"></a>3. Create a step function state machine</h2><ul><li>Create a state machine (see <a href="https://github.com/linkcd/step-function-with-ecs-Anywhere-example/blob/master/state-machine-definition.json">state-machine-definition.json</a>)</li><li>As we need to wait for ecs task finish, step function requires permission as in <a href="https://docs.aws.amazon.com/step-functions/latest/dg/ecs-iam.html">here</a></li><li>Follow <a href="https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html">the steps</a> for setting up s3 triggers step functions via cloudtrail and event bridge</li></ul><h3 id="3-1-ECS-task-details"><a href="#3-1-ECS-task-details" class="headerlink" title="3.1 ECS task details:"></a>3.1 ECS task details:</h3><h4 id="1-Start"><a href="#1-Start" class="headerlink" title="(1). Start:"></a>(1). Start:</h4><p>The s3 upload event is captured by cloudtrail, which triggers and pass the event data to step function. </p><h4 id="2-Extract-S3-event"><a href="#2-Extract-S3-event" class="headerlink" title="(2). Extract S3 event"></a>(2). Extract S3 event</h4><p>This PASS step extract the needed info (bucket name and file key). Output is</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;bucketName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;the_bucket_name_from_event&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fileKey&quot;</span><span class="punctuation">:</span> <span class="string">&quot;the_file_key_from_event&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h4 id="3-Choice"><a href="#3-Choice" class="headerlink" title="(3). Choice"></a>(3). Choice</h4><p>The CHOICE step check the file key and trigger the ECS task ONLY IF the file key matches “demo*.txt”</p><h4 id="4-ECS-RunTask"><a href="#4-ECS-RunTask" class="headerlink" title="(4). ECS RunTask"></a>(4). ECS RunTask</h4><p>This ECS RunTask update the input paramater (adding s3:&#x2F;&#x2F; prefix to bucket name), then pass the parameters to ecs Anywhere task via environment variables.</p><h4 id="5-End"><a href="#5-End" class="headerlink" title="(5). End"></a>(5). End</h4><p>Once the ecs Anywhere task is finished, the downloaded file can be found in the ecs Anywhere local file system (in this case, the file is in &#x2F;data)</p><h2 id="4-Side-notes"><a href="#4-Side-notes" class="headerlink" title="4. Side notes"></a>4. Side notes</h2><p>In ECS RunTask in Step Functions, override command cannot pass multiple parameters. In our case we would like to use aws cli docker for simple aws cli s3 download. However if we override the command to “s3 cp x y” in ECS RunTask step in State Machine, these 4 parts will NOT be passed as individual 4 parameters but ONE parameter that contains all. AWS cli cannot accept that. </p><p>Incorrect value that passed via override command </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;s3 cp x y&quot;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>Correct call if we directly use aws cli docker from terminal</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;s3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;cp&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;x&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;y&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>Therefore we use environment variables to make sure we can pass parameters to ecs container task separately (it means we have to use <a href="https://github.com/linkcd/step-function-with-ecs-Anywhere-example/blob/master/container-for-ecs-task/Dockerfile">our own container</a>)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;This is a demo solution that is using &lt;a href=&quot;https://aws.amazon.com/step-functions/&quot;&gt;AWS Step Functions&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/ecs/Anywhere/&quot;&gt;ECS Anywhere&lt;/a&gt; to complete a simple data processing task by using cloud orchestration (Step Functions) and local computing resources (a NanoPi). &lt;/p&gt;
&lt;h2 id=&quot;Data-flow&quot;&gt;&lt;a href=&quot;#Data-flow&quot; class=&quot;headerlink&quot; title=&quot;Data flow&quot;&gt;&lt;/a&gt;Data flow&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;User upload a file to a s3 bucket&lt;/li&gt;
&lt;li&gt;S3 triggers step functions via cloudtrail and event bridge&lt;/li&gt;
&lt;li&gt;Event bridge triggers a step function state machine&lt;/li&gt;
&lt;li&gt;State machine triggers a ECS Anywhere task to download the file from s3 to local (to do some processing), if file name matches condition&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Architecture&quot;&gt;&lt;a href=&quot;#Architecture&quot; class=&quot;headerlink&quot; title=&quot;Architecture&quot;&gt;&lt;/a&gt;Architecture&lt;/h2&gt;&lt;img src=&quot;/2022/02/02/AWS-Step-Function-with-ECS-Anywhere-on-NanoPi-Sample/architecture.png&quot; class=&quot;&quot; title=&quot;architecture&quot;&gt;

&lt;h2 id=&quot;NanoPi-that-runs-ECS-Anywhere&quot;&gt;&lt;a href=&quot;#NanoPi-that-runs-ECS-Anywhere&quot; class=&quot;headerlink&quot; title=&quot;NanoPi that runs ECS Anywhere&quot;&gt;&lt;/a&gt;NanoPi that runs ECS Anywhere&lt;/h2&gt;&lt;img src=&quot;/2022/02/02/AWS-Step-Function-with-ECS-Anywhere-on-NanoPi-Sample/nanopi.jpg&quot; class=&quot;&quot; title=&quot;nano pi&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://wiki.friendlyarm.com/wiki/index.php/NanoPi_NEO2&quot;&gt;NanoPi Neo2&lt;/a&gt; with LED hat in my home office, running AWS ECS Anywhere.&lt;/p&gt;</summary>
    
    
    
    
    <category term="AWS" scheme="https://feng.lu/tags/AWS/"/>
    
    <category term="Step Functions" scheme="https://feng.lu/tags/Step-Functions/"/>
    
    <category term="ECS Anywhere" scheme="https://feng.lu/tags/ECS-Anywhere/"/>
    
    <category term="Nano Pi" scheme="https://feng.lu/tags/Nano-Pi/"/>
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>Using SSM to access EC2 instances</title>
    <link href="https://feng.lu/2021/12/17/Using-SSM-to-access-EC2-instances/"/>
    <id>https://feng.lu/2021/12/17/Using-SSM-to-access-EC2-instances/</id>
    <published>2021-12-17T08:34:22.000Z</published>
    <updated>2025-03-28T09:05:16.902Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Benefits-of-using-for-connecting-EC2-instances"><a href="#1-Benefits-of-using-for-connecting-EC2-instances" class="headerlink" title="1. Benefits of using for connecting EC2 instances"></a>1. Benefits of using for connecting EC2 instances</h2><p><a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html">AWS Systems Manager (SSM)</a> is an AWS service that you can use to view and control your infrastructure on AWS. It can securely connect to a managed node. The SSM Agent is installed in EC2 OS. It is <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-install-ssm-agent.html">pre-installed</a> on many amazon Machine Images (AMIs).</p><p>With SSM:</p><ul><li>No need to open SSH port in security group for EC2</li><li>No need to create and manage SSH keys</li></ul><p>And SSM works regardless if the EC2 instance is in public or private (NAT or Endpoint) subnet.</p><p>Requirements for SSM working:</p><ul><li><strong>AWS instances</strong>:<ul><li>SSM agent installed in instance (pre-installed in many AMIs already)</li><li>Connectivity to the AWS public zone endpoint of SSM (IGW, NAT or VPCE)</li><li>IAM role providing permissions</li></ul></li><li><strong>On-Prem instances:</strong><ul><li>SSM agent installed in instance</li><li>Connectivity to the AWS public zone endpoint of SSM (Access to public internet)</li><li>Activation (Activation Code and Actuation ID)</li><li>IAM role providing permissions</li></ul></li></ul><h2 id="2-EC2-Instance-in-public-subnet"><a href="#2-EC2-Instance-in-public-subnet" class="headerlink" title="2. EC2 Instance in public subnet"></a>2. EC2 Instance in public subnet</h2><ul><li>2.1. Make sure the EC2 instance has a public IP. It could be the public IP assigned during creation, or an Elastic IP.</li><li>2.2. EC2 instance should have Internet access (for calling SSM endpoint). In public subnet it is done via <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html">Internet Gateways</a>. See details from <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-prerequisites.html">Session Manager prerequisites</a>, in “Connectivity to endpoints” section.</li><li>2.3. You can use <a href="https://docs.aws.amazon.com/vpc/latest/reachability/what-is-reachability-analyzer.html">VPC Reachability Analyzer</a> to troubleshoot the connectivity between your EC2 and Internet gateway.</li><li>2.4. Create an EC2 Instance profile has IAM policy <strong>AmazonSSMManagedInstanceCore</strong>. Read the details from <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html">Step 4: Create an IAM instance profile for Systems Manager</a></li><li>2.5  Attach the EC2 Instance profile to your instance.</li><li>2.6  Reboot the EC2 instances.</li></ul><h2 id="3-EC2-instance-in-private-subnet-with-NAT-connectivity"><a href="#3-EC2-instance-in-private-subnet-with-NAT-connectivity" class="headerlink" title="3. EC2 instance in private subnet, with NAT connectivity"></a>3. EC2 instance in private subnet, with NAT connectivity</h2><p>In this case, EC2 instances have no public IP, but they can still talk to internet via NAT.</p><ul><li>3.1. Make sure EC2 instances in private subnet can access internet, via a <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html">NAT Gateway</a> or <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html">NAT instance</a>.</li><li>3.2. The rest will be the same as EC2 instances in public subnet, starting from 2.2</li></ul><h2 id="4-EC2-instance-in-private-subnet-without-NAT-connectivity-but-VPC-endpoints"><a href="#4-EC2-instance-in-private-subnet-without-NAT-connectivity-but-VPC-endpoints" class="headerlink" title="4. EC2 instance in private subnet, without NAT connectivity but VPC endpoints"></a>4. EC2 instance in private subnet, without NAT connectivity but VPC endpoints</h2><p>In this case, the EC2 instance (no public IP) won´t have access internet via NAT but VPC endpoints, some extra works are required</p><ul><li>4.1 <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-create-vpc.html#sysman-setting-up-vpc-create">Create VPC endpoints for System Manager</a>. Remember to allow HTTPS (port 443) outbound traffic in security group for your endpoint (ssm, ssmmessages and ec2messages)</li><li>4.2. Create an IAM Role as EC2 profile that contains <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html#instance-profile-policies-overview">at least the following 2 policies</a></li><li>aws managed policy <strong>AmazonSSMManagedInstanceCore</strong> </li><li><a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html#instance-profile-custom-s3-policy">a custom policy</a> for accessing an AWS owned S3 buckets.</li><li>4.3 Attach this instance profile to your EC2 instance</li><li>4.4 Make sure enable “DNS resolution” and “DNS hostnames” for you VPC</li><li>4.5 In addition, if your EC2 instance need to access other AWS services such as S3, remember to create needed endpoints for them as well. (For S3 you can choose either Gateway or Endpoint. At this moment Gateway is free.) <strong>Note</strong> that you need to add the endpoint into the private subnet route table. The following screenshot shows the route table entity of a S3 Gateway endpoint, which is using <a href="https://docs.aws.amazon.com/vpc/latest/userguide/managed-prefix-lists.html">prefix lists</a>.</li></ul><img src="/2021/12/17/Using-SSM-to-access-EC2-instances/s3%20endpoint%20in%20route%20table.png" class="" title="s3 endpoint in route table"><h2 id="5-Verification"><a href="#5-Verification" class="headerlink" title="5. Verification"></a>5. Verification</h2><p>Once the SSM is fully up-and-running, the EC2 instance (either in public&#x2F;private subnet) will appear in Fleet Manager in SSM web console. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-Benefits-of-using-for-connecting-EC2-instances&quot;&gt;&lt;a href=&quot;#1-Benefits-of-using-for-connecting-EC2-instances&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    
    <category term="AWS" scheme="https://feng.lu/tags/AWS/"/>
    
    <category term="IAM" scheme="https://feng.lu/tags/IAM/"/>
    
    <category term="AWS Systems Manager" scheme="https://feng.lu/tags/AWS-Systems-Manager/"/>
    
    <category term="SSM" scheme="https://feng.lu/tags/SSM/"/>
    
    <category term="EC2" scheme="https://feng.lu/tags/EC2/"/>
    
    <category term="VPC" scheme="https://feng.lu/tags/VPC/"/>
    
    <category term="VPC Endpoint" scheme="https://feng.lu/tags/VPC-Endpoint/"/>
    
    <category term="SSH" scheme="https://feng.lu/tags/SSH/"/>
    
  </entry>
  
  <entry>
    <title>Building a Very Slow Movie Player</title>
    <link href="https://feng.lu/2021/12/04/Building-a-Very-Slow-Movie-Player/"/>
    <id>https://feng.lu/2021/12/04/Building-a-Very-Slow-Movie-Player/</id>
    <published>2021-12-04T10:23:19.000Z</published>
    <updated>2025-03-28T10:26:55.649Z</updated>
    
    <content type="html"><![CDATA[<p>Inspired by <a href="https://medium.com/s/story/very-slow-movie-player-499f76c48b62">Bryan Boyer</a> and <a href="https://debugger.medium.com/how-to-build-a-very-slow-movie-player-in-2020-c5745052e4e4">Tom Whitwell</a>, I am building a Very Slow Movie Player (VSMP).</p><img src="/2021/12/04/Building-a-Very-Slow-Movie-Player/vsmp-demo.gif" class="" title="vsmp demo"><p>With VSMP, </p><ul><li>Kiki’s Delivery Service (running time 1h42m): takes 7 days to play (with 1 frame per 20 seconds, as in above demo)</li><li>Laputa: Castle in the Sky (running time 2h4m): takes 2 months to play (with 1 frame per 120 seconds, as default setting)</li></ul><span id="more"></span><h1 id="1-Hardware"><a href="#1-Hardware" class="headerlink" title="1. Hardware"></a>1. Hardware</h1><ul><li>Raspberry Pi Zero WH (Zero W with Headers)</li><li><a href="https://www.waveshare.net/wiki/7.5inch_e-Paper_HAT">Waveshare e-paper 7.5 inch with Hat</a></li><li>IKEA Photo Frame</li></ul><p>All can be assembled together easily.</p><p>Front view</p><img src="/2021/12/04/Building-a-Very-Slow-Movie-Player/front.png" class="" title="the front"><p>Zoom in details</p><img src="/2021/12/04/Building-a-Very-Slow-Movie-Player/detail.png" class="" title="the detail"><p>The back</p><img src="/2021/12/04/Building-a-Very-Slow-Movie-Player/back.png" class="" title="the back"><h1 id="2-Installation"><a href="#2-Installation" class="headerlink" title="2. Installation"></a>2. Installation</h1><h2 id="2-1-Raspberry-Pi-Zero"><a href="#2-1-Raspberry-Pi-Zero" class="headerlink" title="2.1 Raspberry Pi Zero"></a>2.1 Raspberry Pi Zero</h2><p>Install standard Raspberry OS. I am using the 32bit bulleyes with desktop version, but someone suggested to use lite version for Raspberry Pi Zero. Read more <a href="https://github.com/TomWhitwell/SlowMovie/wiki/Hardware">here</a>.</p><p>For install pi with headless wifi, read how-to <a href="https://desertbot.io/blog/headless-raspberry-pi-zero-w-2-ssh-wifi-setup-mac-windows-10-steps">here</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> /Volumes/boot/ssh</span><br><span class="line"><span class="built_in">touch</span> /Volumes/boot/wpa_supplicant.conf</span><br></pre></td></tr></table></figure><p>Content of wpa_supplicant.conf</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">country=US</span><br><span class="line">ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev</span><br><span class="line">update_config=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">network=<span class="punctuation">&#123;</span></span><br><span class="line">scan_ssid=<span class="number">1</span></span><br><span class="line">ssid=<span class="string">&quot;your_wifi_ssid&quot;</span></span><br><span class="line">psk=<span class="string">&quot;your_wifi_password&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>Note:</strong> It is a good practice to disable the default user “Pi”, but <a href="https://github.com/TomWhitwell/SlowMovie">VSMP installation script</a> from Tom Whitwell is using hard-coded “Pi” home path, so to keep it simple, keep “Pi” user but DEFINITELY update the default password. I also run it in a guest wifi that it has no access to rest of my network devices. </p><h2 id="2-2-Install-VSMP-files"><a href="#2-2-Install-VSMP-files" class="headerlink" title="2.2 Install VSMP files"></a>2.2 Install VSMP files</h2><p>There are many implementations of VSMP:</p><ul><li><a href="https://github.com/TomWhitwell/SlowMovie">https://github.com/TomWhitwell/SlowMovie</a> (I am using this one, works with my e-paper by default)</li><li><a href="https://github.com/robweber/vsmp-plus">https://github.com/robweber/vsmp-plus</a> (This one provides nice web interface for controlling, but it crashes all the time in my setup)</li><li><a href="https://github.com/rec0de/vsmp-zero">https://github.com/rec0de/vsmp-zero</a> (For e-paper 7.8inch, 1872×1404 resolution, with embedded controller IT8951, communicating via USB&#x2F;SPI&#x2F;I80 interface)</li></ul><p><strong>Note:</strong> You can test your e-ink by running omni-epd-test. In my case, I do the following</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">omni-epd-test -e waveshare_epd.epd7in5_V2</span><br></pre></td></tr></table></figure><p>The <a href="https://github.com/robweber/omni-epd#displays-implemented">omni-epd</a> is a part of the installation.</p><h1 id="3-Prepare-the-movie"><a href="#3-Prepare-the-movie" class="headerlink" title="3. Prepare the movie"></a>3. Prepare the movie</h1><h2 id="3-1-If-you-need-convert-mkv-to-mp4"><a href="#3-1-If-you-need-convert-mkv-to-mp4" class="headerlink" title="3.1 If you need convert mkv to mp4"></a>3.1 If you need convert mkv to mp4</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># assume you have ffmpeg installed on your mac</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> *.mkv; <span class="keyword">do</span> ffmpeg -i <span class="string">&quot;<span class="variable">$f</span>&quot;</span> -c copy <span class="string">&quot;<span class="variable">$&#123;f%.mkv&#125;</span>.mp4&quot;</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>Read more examples at <a href="https://gist.github.com/jamesmacwhite/58aebfe4a82bb8d645a797a1ba975132">here</a>.</p><h2 id="3-2-Remove-sound-track-for-reducing-the-file-size"><a href="#3-2-Remove-sound-track-for-reducing-the-file-size" class="headerlink" title="3.2 Remove sound track for reducing the file size"></a>3.2 Remove sound track for reducing the file size</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># assume you have ffmpeg installed on your mac</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> *.mp4; <span class="keyword">do</span> ffmpeg -i <span class="string">&quot;<span class="variable">$f</span>&quot;</span> -c copy -an <span class="string">&quot;<span class="variable">$&#123;f%.mp4&#125;</span>-nosound.mp4&quot;</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>Read more about “-an” parameter at <a href="https://superuser.com/questions/268985/remove-audio-from-video-file-with-ffmpeg">here</a>.</p><h2 id="3-3-Copy-files-to-Pi"><a href="#3-3-Copy-files-to-Pi" class="headerlink" title="3.3 Copy files to Pi"></a>3.3 Copy files to Pi</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from movie folder</span></span><br><span class="line">scp *.mp4 pi@YOUR_PI_HOST_NAME:/home/pi/SlowMovie/Videos/</span><br></pre></td></tr></table></figure><h1 id="4-Play"><a href="#4-Play" class="headerlink" title="4. Play"></a>4. Play</h1><h2 id="4-1-VSMP-as-a-service"><a href="#4-1-VSMP-as-a-service" class="headerlink" title="4.1 VSMP as a service"></a>4.1 VSMP as a service</h2><p>By default <a href="https://github.com/TomWhitwell/SlowMovie/wiki/Content-reviews:-What-makes-a-good-slow-movie%3F">VSMP</a> is enabled as a service. </p><p>Edit the slowmovie.conf file to specify parameters such as video locations and start frame</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Edit the config file</span></span><br><span class="line">vi slowmovie.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">## Content of slowmovie.conf ##</span></span><br><span class="line">random-frames = False</span><br><span class="line">delay = 120</span><br><span class="line">increment = 4</span><br><span class="line">contrast = 2.0</span><br><span class="line">epd = waveshare_epd.epd7in5_V2</span><br><span class="line">directory = /home/pi/SlowMovie/Videos</span><br><span class="line">timecode = False</span><br><span class="line"><span class="comment">## End of content ##</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Restart the service</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl restart slowmovie</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> slowmovie</span><br></pre></td></tr></table></figure><h2 id="4-2-Manually-run"><a href="#4-2-Manually-run" class="headerlink" title="4.2 Manually run"></a>4.2 Manually run</h2><p>If you want to <a href="https://github.com/TomWhitwell/SlowMovie#running-from-the-shell">manually run command</a>, REMEMBER to disable the service.</p><p>If you run it manually, considering use <a href="https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/">tmux</a> to ensure the session continues after you log off.</p><p>Example:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stop services</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl stop slowmovie</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">disable</span> slowmovie</span><br><span class="line"></span><br><span class="line"><span class="comment"># enter tmux session</span></span><br><span class="line">tmux</span><br><span class="line"></span><br><span class="line"><span class="comment"># Manual run in tmux session window</span></span><br><span class="line"><span class="built_in">cd</span> SlowMovie</span><br><span class="line">python3 slowmovie.py -f ./Videos/Kiki.mp4 -d 20 -s 19970 <span class="comment">#delay 20 sec, start from 19970 frame</span></span><br></pre></td></tr></table></figure><h1 id="5-Bonus-content"><a href="#5-Bonus-content" class="headerlink" title="5. Bonus content"></a>5. Bonus content</h1><h2 id="5-1-What-to-play"><a href="#5-1-What-to-play" class="headerlink" title="5.1 What to play"></a>5.1 What to play</h2><p>Wondering what to play? Read <a href="https://github.com/TomWhitwell/SlowMovie/wiki/Content-reviews:-What-makes-a-good-slow-movie%3F">Content reviews: What makes a good slow movie</a>. I am a big fan of <a href="https://www.ghibli.jp/">Studio Ghibli</a> so that is my choice. </p><p>Also you might want to re-encode the videos as <a href="https://github.com/TomWhitwell/SlowMovie/wiki/Preparing-Video-Files">here</a>.</p><h2 id="5-2-Shoot-a-video-for-your-VSMP"><a href="#5-2-Shoot-a-video-for-your-VSMP" class="headerlink" title="5.2 Shoot a video for your VSMP"></a>5.2 Shoot a video for your VSMP</h2><p>You can use iphone time-lapse to record your VSMP to see how it works. However, iphone time-lapse will sometimes capture some e-paper refresh, when the screen is all white or black. To remove these bad frames from your video, do following (ref <a href="https://gist.github.com/loretoparisi/a9277b2eb4425809066c380fed395ab3">#1</a>, <a href="https://stackoverflow.com/questions/10225403/how-can-i-extract-a-good-quality-jpeg-image-from-a-video-file-with-ffmpeg">#2</a>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># extract all frames from iphone time-lapse video</span></span><br><span class="line"><span class="built_in">mkdir</span> img</span><br><span class="line">ffmpeg -i time-lapse.MOV -qscale:v 2 -r 30/1 img/img%03d.jpg <span class="comment">#iphone time-lapse video is 30 fps, second best output img quality</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># remove bad frames</span></span><br><span class="line"><span class="comment"># manual or using ML such as Amazon Lookout For Vision</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># regenerate the video from frames</span></span><br><span class="line">ffmpeg -framerate 30 -pattern_type glob -i <span class="string">&#x27;img/*.jpg&#x27;</span>  output.mov</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow it down if needed</span></span><br><span class="line">ffmpeg -i output.mov -filter:v <span class="string">&quot;setpts=1.3*PTS&quot;</span> output_slow.mov</span><br></pre></td></tr></table></figure><p>Example of using <a href="https://aws.amazon.com/lookout-for-vision/">Amazon Lookout for Vision</a> for detecting bad frames, but that is another story.</p><img src="/2021/12/04/Building-a-Very-Slow-Movie-Player/Lookout%20for%20vision.png" class="" title="the back"><h1 id="6-Slightly-longer-demo"><a href="#6-Slightly-longer-demo" class="headerlink" title="6. Slightly longer demo"></a>6. Slightly longer demo</h1><div class="video-container"><iframe src="https://www.youtube.com/embed/VIQjtaqm8Ps" frameborder="0" loading="lazy" allowfullscreen></iframe></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;Inspired by &lt;a href=&quot;https://medium.com/s/story/very-slow-movie-player-499f76c48b62&quot;&gt;Bryan Boyer&lt;/a&gt; and &lt;a href=&quot;https://debugger.medium.com/how-to-build-a-very-slow-movie-player-in-2020-c5745052e4e4&quot;&gt;Tom Whitwell&lt;/a&gt;, I am building a Very Slow Movie Player (VSMP).&lt;/p&gt;
&lt;img src=&quot;/2021/12/04/Building-a-Very-Slow-Movie-Player/vsmp-demo.gif&quot; class=&quot;&quot; title=&quot;vsmp demo&quot;&gt;

&lt;p&gt;With VSMP, &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kiki’s Delivery Service (running time 1h42m): takes 7 days to play (with 1 frame per 20 seconds, as in above demo)&lt;/li&gt;
&lt;li&gt;Laputa: Castle in the Sky (running time 2h4m): takes 2 months to play (with 1 frame per 120 seconds, as default setting)&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="Raspberry Pi" scheme="https://feng.lu/tags/Raspberry-Pi/"/>
    
    <category term="e-paper" scheme="https://feng.lu/tags/e-paper/"/>
    
    <category term="DIY" scheme="https://feng.lu/tags/DIY/"/>
    
    <category term="SVMP" scheme="https://feng.lu/tags/SVMP/"/>
    
    <category term="Amazon Lookout for Vision" scheme="https://feng.lu/tags/Amazon-Lookout-for-Vision/"/>
    
    <category term="Movie" scheme="https://feng.lu/tags/Movie/"/>
    
  </entry>
  
  <entry>
    <title>Okta and AWS Control Tower - a happy path demo</title>
    <link href="https://feng.lu/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/"/>
    <id>https://feng.lu/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/</id>
    <published>2021-11-17T19:17:08.000Z</published>
    <updated>2025-03-28T09:05:16.881Z</updated>
    
    <content type="html"><![CDATA[<p>This is a <a href="https://en.wikipedia.org/wiki/Happy_path">happy path</a> demo of setting up <a href="https://www.okta.com/">Okta</a> as the Idp for <a href="https://aws.amazon.com/controltower/">AWS Control Tower</a> (via <a href="https://aws.amazon.com/single-sign-on/">AWS SSO</a>). <br><strong>Goal</strong>: To utilize users and groups in Okta to manage AWS control tower.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/title.jpg" class="" title><h1 id="1-Create-a-brand-new-Control-Tower-instance"><a href="#1-Create-a-brand-new-Control-Tower-instance" class="headerlink" title="1. Create a brand new Control Tower instance"></a>1. Create a brand new Control Tower instance</h1><p>In this demo, we create the AWS Control Tower instance in a brand new AWS account. During this process, control tower creates several services&#x2F;components, such as AWS Organizations, AWS SSO, default organizations unit (OU) “Security” and 2 AWS accounts “Log Archive” and “Audit”. </p><p>In the AWS SSO, some default SSO user groups are created for managing Control Tower:</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20SSO%20user%20groups.jpg" class="" title="default SSO user groups"><p>The default admin user for organization management account is “AWS Control Tower Admin”.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20master%20user1.jpg" class="" title="default master user1"><p>Detailed user info</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20master%20user2.jpg" class="" title="default master user2"><p>And it belongs to 2 groups: <strong>AWSAccountFactory</strong> and <strong>AWSControlTowerAdmins</strong></p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20master%20user3.jpg" class="" title="default master user3"><span id="more"></span><h1 id="2-Setup-Okta-and-use-it-as-the-idp-of-AWS-SSO"><a href="#2-Setup-Okta-and-use-it-as-the-idp-of-AWS-SSO" class="headerlink" title="2. Setup Okta and use it as the idp of AWS SSO"></a>2. Setup Okta and use it as the idp of AWS SSO</h1><h2 id="2-1-Create-an-environment-of-Okta"><a href="#2-1-Create-an-environment-of-Okta" class="headerlink" title="2.1 Create an environment of Okta]"></a>2.1 Create an environment of Okta]</h2><p>For this demo, we are using a <a href="https://developer.okta.com/signup/">free developer plan of Okta</a>.</p><h2 id="2-2-Setup-Okta-as-the-idp-of-AWS-SSO"><a href="#2-2-Setup-Okta-as-the-idp-of-AWS-SSO" class="headerlink" title="2.2 Setup Okta as the idp of AWS SSO"></a>2.2 Setup Okta as the idp of AWS SSO</h2><p>Follow the steps in the following document, to use Okta as the idp of AWS SSO.<br><strong>Note that you need to check steps from <em>both</em> documentation to make sure the integration and user provisioning works.</strong></p><h3 id="2-2-1-Basic-hand-shake-import-metadata-file-from-Okta-to-AWS-SSO"><a href="#2-2-1-Basic-hand-shake-import-metadata-file-from-Okta-to-AWS-SSO" class="headerlink" title="2.2.1 Basic hand-shake, import metadata file from Okta to AWS SSO"></a>2.2.1 Basic hand-shake, import metadata file from Okta to AWS SSO</h3><p><strong>Steps</strong>: <a href="https://saml-doc.okta.com/SAML_Docs/How-to-Configure-SAML-2.0-for-AWS-Single-Sign-on.html">How to Configure SAML 2.0 for AWS Single Sign-on</a></p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/config%20saml2%20for%20aws%20sso.jpg" class="" title="config saml2 for aws sso"><h3 id="2-2-2-Config-provisioning-and-other-settings-in-AWS-SSO"><a href="#2-2-2-Config-provisioning-and-other-settings-in-AWS-SSO" class="headerlink" title="2.2.2 Config provisioning and other settings in AWS SSO"></a>2.2.2 Config provisioning and other settings in AWS SSO</h3><p><strong>Steps</strong>: <a href="https://docs.aws.amazon.com/singlesignon/latest/userguide/okta-idp.html">Configure provisioning for Okta in AWS SSO</a>        </p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/Config%20provisioning%20and%20other%20settings%20in%20AWS%20SSO.jpg" class="" title="Config provisioning and other settings in AWS SSO"><h2 id="2-3-The-basic-setup-is-ready-but-not-for-users-and-groups-yet"><a href="#2-3-The-basic-setup-is-ready-but-not-for-users-and-groups-yet" class="headerlink" title="2.3 The basic setup is ready, but not for users and groups yet"></a>2.3 The basic setup is ready, but not for users and groups yet</h2><p>After the basic hand-shake between AWS SSO and Okta, the AWS SSO is now using Okta.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/AWS%20SSO%20is%20now%20using%20Okta.jpg" class="" title="AWS SSO is now using Okta"><p>In Okta groups UI, you can see identical groups as in AWS SSO are created in Okta. The <strong>Everyone</strong> is a default Okta user group.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/identical%20groups%20as%20in%20AWS%20SSO%20are%20created%20in%20Okta.jpg" class="" title="identical groups as in AWS SSO are created in Okta"><p><strong>Note</strong>: you <strong>cannot</strong> add&#x2F;remove users to it, as it says “This group is managed automatically by Okta, so you cannot edit it or modify its membership.”</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/readonly%20user%20groups.jpg" class="" title="readonly user groups"><h1 id="3-Setup-Okta-users-and-groups-push-them-to-AWS-SSO"><a href="#3-Setup-Okta-users-and-groups-push-them-to-AWS-SSO" class="headerlink" title="3. Setup Okta users and groups, push them to AWS SSO"></a>3. Setup Okta users and groups, push them to AWS SSO</h1><h2 id="3-1-Create-user-and-groups-in-Okta"><a href="#3-1-Create-user-and-groups-in-Okta" class="headerlink" title="3.1 Create user and groups in Okta"></a>3.1 Create user and groups in Okta</h2><p>Lets create some test users:</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/test%20users.jpg" class="" title="test users"><p>We also create user groups in Okta</p><ul><li><strong>AWS-CT-Admin-Okta-Group</strong>, has 1 user: <strong>Feng</strong> </li><li><strong>AWS-CT-Developers-Okta-Group</strong> has 2 users: <strong>Alice</strong> and <strong>Bob</strong></li></ul><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/user%20groups%20in%20okta.jpg" class="" title="user groups in okta"><p>However, they are not appearing in AWS SSO user list. There is still no Okta user nor Okta group.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/no%20okta%20users%20yet.jpg" class="" title="no okta users yet"><p>In order to user the users from Okta, these users need to be assigned to <strong>AWS SSO Application</strong> in Okta.</p><h2 id="3-2-Assign-users-and-or-groups-in-Okta"><a href="#3-2-Assign-users-and-or-groups-in-Okta" class="headerlink" title="3.2 Assign users and&#x2F;or groups in Okta"></a>3.2 Assign users and&#x2F;or groups in Okta</h2><p>Go to Okta -&gt; Application -&gt; AWS SSO, in <strong>Assignments</strong> tab, you can either assign individual users or user groups. In this screenshot, all users are assigned to AWS SSO via Group (see the <strong>Type</strong> column).</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/assign%20okta%20users%20to%20sso%20app.jpg" class="" title="assign okta users to sso app"><p>Soon, you can see these 3 users appear in AWS SSO interface.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/okta%20users%20now%20in%20sso.jpg" class="" title="okta users now in sso"><p>The detailed info. Note that it was created and updated by <strong>SCIM</strong>.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/okta%20user%20detailed%20info.jpg" class="" title="okta user detailed info"><p>Now you can assign them into AWS account, so the user can login to AWS console via login to Okta.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/grant%20permission%20to%20okta%20user.jpg" class="" title="grant permission to okta user"><h2 id="3-3-Push-groups-from-Okta-to-AWS-SSO"><a href="#3-3-Push-groups-from-Okta-to-AWS-SSO" class="headerlink" title="3.3 Push groups from Okta to AWS SSO"></a>3.3 Push groups from Okta to AWS SSO</h2><p>Now we can grant permission for individual Okta users. But how about Okta group? These new okta groups are not available in AWS SSO yet. And the groups with identical names from AWS SSO is not helping, as we cannot add users into it.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/missing%20okta%20group.jpg" class="" title="missing okta group"><p>To solve this, we need to push the Okta groups to AWS SSO by setting up the “<strong>Push Groups</strong>”.</p><p>Go Okta &gt; Application &gt; AWS SSO, in tab “<strong>Push Groups</strong>”, here you can push group by name, or setup roles for batch pushing.</p><p>In this demo, we setup a rule named “Pust-AWS-Related-Groups” for pushing any group that starts with “<strong>AWS-</strong>”</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/push%20group%20rule.jpg" class="" title="push group rule"><p>Soon, these groups were pushed to AWS SSO:</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/group%20push%20logs.jpg" class="" title="group push logs"><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/okta%20groups%20available%20now.jpg" class="" title="okta groups available now"><p>Now you can also grant permission to groups, such as every Okta user in <strong>AWS-CT-Admin-Okta-Group</strong> now have permission as AWS control tower admin.</p><img src="/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/grant%20permission%20to%20groups.jpg" class="" title="grant permission to groups"><p>EoF.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;This is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Happy_path&quot;&gt;happy path&lt;/a&gt; demo of setting up &lt;a href=&quot;https://www.okta.com/&quot;&gt;Okta&lt;/a&gt; as the Idp for &lt;a href=&quot;https://aws.amazon.com/controltower/&quot;&gt;AWS Control Tower&lt;/a&gt; (via &lt;a href=&quot;https://aws.amazon.com/single-sign-on/&quot;&gt;AWS SSO&lt;/a&gt;). &lt;br&gt;&lt;strong&gt;Goal&lt;/strong&gt;: To utilize users and groups in Okta to manage AWS control tower.&lt;/p&gt;
&lt;img src=&quot;/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/title.jpg&quot; class=&quot;&quot; title&gt;

&lt;h1 id=&quot;1-Create-a-brand-new-Control-Tower-instance&quot;&gt;&lt;a href=&quot;#1-Create-a-brand-new-Control-Tower-instance&quot; class=&quot;headerlink&quot; title=&quot;1. Create a brand new Control Tower instance&quot;&gt;&lt;/a&gt;1. Create a brand new Control Tower instance&lt;/h1&gt;&lt;p&gt;In this demo, we create the AWS Control Tower instance in a brand new AWS account. During this process, control tower creates several services&amp;#x2F;components, such as AWS Organizations, AWS SSO, default organizations unit (OU) “Security” and 2 AWS accounts “Log Archive” and “Audit”. &lt;/p&gt;
&lt;p&gt;In the AWS SSO, some default SSO user groups are created for managing Control Tower:&lt;/p&gt;
&lt;img src=&quot;/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20SSO%20user%20groups.jpg&quot; class=&quot;&quot; title=&quot;default SSO user groups&quot;&gt;

&lt;p&gt;The default admin user for organization management account is “AWS Control Tower Admin”.&lt;/p&gt;
&lt;img src=&quot;/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20master%20user1.jpg&quot; class=&quot;&quot; title=&quot;default master user1&quot;&gt;

&lt;p&gt;Detailed user info&lt;/p&gt;
&lt;img src=&quot;/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20master%20user2.jpg&quot; class=&quot;&quot; title=&quot;default master user2&quot;&gt;

&lt;p&gt;And it belongs to 2 groups: &lt;strong&gt;AWSAccountFactory&lt;/strong&gt; and &lt;strong&gt;AWSControlTowerAdmins&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;/2021/11/17/Okta-and-AWS-Control-Tower-a-happy-path-demo/default%20master%20user3.jpg&quot; class=&quot;&quot; title=&quot;default master user3&quot;&gt;</summary>
    
    
    
    
    <category term="AWS" scheme="https://feng.lu/tags/AWS/"/>
    
    <category term="Okta" scheme="https://feng.lu/tags/Okta/"/>
    
    <category term="AWS Control Tower" scheme="https://feng.lu/tags/AWS-Control-Tower/"/>
    
    <category term="AWS SSO" scheme="https://feng.lu/tags/AWS-SSO/"/>
    
    <category term="SSO" scheme="https://feng.lu/tags/SSO/"/>
    
  </entry>
  
  <entry>
    <title>How to build an IoT connected car - Part 2: Data Analytics in the Cloud</title>
    <link href="https://feng.lu/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/"/>
    <id>https://feng.lu/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/</id>
    <published>2020-09-22T08:00:13.000Z</published>
    <updated>2025-03-28T09:05:16.670Z</updated>
    
    <content type="html"><![CDATA[<p>In <a href="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/" title="How to build an IoT connected car - Part 1: On the Edge">Part 1</a>, we have talked about the hardware&#x2F;software running on the edge (the car) for collecting data.</p><p>Now we have the data, and how to gain some insights by doing data analytics? I have been using the following products, and would like to share my quick thoughts</p><ul><li>Azure Time Series Insight (TSI)</li><li>Azure Databricks</li><li>Azure Data Explorer (ADX)</li><li>PowerBI</li><li>Grafana</li></ul><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/Thumbnail.png" class="" title="Thumbnail"> <span id="more"></span><p><em>Please note that I tested these products back to Feb&#x2F;March of 2019 and all the feedback were from that time point. I am sure all products were significate upgraded and improved since then, so you might wanna check them again with the lastest features.</em>  </p><h2 id="1-Azure-Time-Series-Insight-TSI"><a href="#1-Azure-Time-Series-Insight-TSI" class="headerlink" title="1. Azure Time Series Insight (TSI)"></a>1. Azure Time Series Insight (TSI)</h2><p><a href="https://azure.microsoft.com/en-us/services/time-series-insights/">Azure Time Series Insight (TSI)</a> is an IoT analytics platform monitor, analyze, and visualize your industrial IoT data at scale. With native integration with Azure IoTHub or EventHub, it is easy to visualize and explore the IoT data such as from our connected car.</p><h3 id="1-1-Simple-data-exploring"><a href="#1-1-Simple-data-exploring" class="headerlink" title="1.1 Simple data exploring"></a>1.1 Simple data exploring</h3><p>You can easily explore data by putting time series data into one screen:</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/TSI%20analytics.png" class="" title="TSI analytics"><p>(click to enlarge)<br>For example, you can identify the relationship between engine RPM and speed, and the increasing temperature of engine coolant. </p><h3 id="1-2-Metadata-Model-management"><a href="#1-2-Metadata-Model-management" class="headerlink" title="1.2 Metadata&#x2F;Model management"></a>1.2 Metadata&#x2F;Model management</h3><p>As TSI is built for handling IoT data, it has built-in functionality for managing metadata&#x2F;models of IoT data stream. This is a unique feature that only TSI offers, compares to other general-purpose analytics products that I tried. </p><p>In another word, in order to use TSI, you will have to setup the <a href="https://docs.microsoft.com/en-us/azure/time-series-insights/concepts-model-overview">following models</a>:</p><ul><li>Time Series Model instances</li><li>Time Series Model hierarchies</li><li>Time Series Model types</li></ul><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/TSI%20models.png" class="" title="TSI models"><p>(source: Microsoft)</p><p>For our case, we can setup the models for representing the </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">Assets - ABC Taxi Company Carpool</span><br><span class="line">    ├── Car 1: Feng Toyota Auris</span><br><span class="line">    │   ├── GPS</span><br><span class="line">    │   │   └── FengsDevice_GPS</span><br><span class="line">    │   │       ├── GPS Speed</span><br><span class="line">    │   │       ├── Altitude</span><br><span class="line">    │   │       └── ...</span><br><span class="line">    │   └── OBD</span><br><span class="line">    │       └── FengsDevice_OBD</span><br><span class="line">    │           ├── RPM</span><br><span class="line">    │           ├── SPEED</span><br><span class="line">    │           ├── MAF</span><br><span class="line">    │           ├── ENGINE_LOAD</span><br><span class="line">    │           └── ...</span><br><span class="line">    │ </span><br><span class="line">    ├── Car 2: Thomas Two Engines Monster Truck</span><br><span class="line">    │   ├── GPS</span><br><span class="line">    │   │   └── TomsDevice_GPS</span><br><span class="line">    │   │       ├── GPS Speed</span><br><span class="line">    │   │       ├── Altitude</span><br><span class="line">    │   │       └── ...</span><br><span class="line">    │   └── OBD</span><br><span class="line">    │       ├── TomsDevice_OBD_Engine_1</span><br><span class="line">    │       │   ├── RPM</span><br><span class="line">    │       │   ├── SPEED</span><br><span class="line">    │       │   ├── MAF</span><br><span class="line">    │       │   ├── ENGINE_LOAD</span><br><span class="line">    │       │   └── ...</span><br><span class="line">    │       └── TomsDevice_OBD_Engine_2</span><br><span class="line">    │           ├── RPM</span><br><span class="line">    │           ├── SPEED</span><br><span class="line">    │           ├── MAF</span><br><span class="line">    │           ├── ENGINE_LOAD</span><br><span class="line">    │           └── ...</span><br><span class="line">    │ </span><br><span class="line">    └── Car 3: ...</span><br><span class="line">        └── ...</span><br></pre></td></tr></table></figure><p>For our case, these model definitions can be found at <a href="https://github.com/linkcd/IoTCar/tree/master/modules/OBDModule/TSI%20config">here</a>.</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/TSI%20models%20in%20demo.png" class="" title="TSI models in demo"><h3 id="1-3-Summary-of-TSI-experience"><a href="#1-3-Summary-of-TSI-experience" class="headerlink" title="1.3 Summary of TSI experience"></a>1.3 Summary of TSI experience</h3><p><strong>Pro:</strong></p><ul><li>Very nice user interface with animation, smoothly zoom in&#x2F;out</li><li>Built-in support of data module&#x2F;metadata</li><li>Supporting IoT data in scale (although I only tested with a small dataset)</li><li>Data can be exported to parquet files, which is optimized for time-series data</li></ul><p><strong>Con:</strong></p><ul><li>Limited analytic possibility, cannot run customized query in UI</li><li>Does not support map</li><li>Data model contextualization is done only via TSI API, not in parquet file (which is raw data) </li><li>Exported parquet file is somewhat messy (see more details in DataBricks section)</li></ul><h2 id="2-Azure-Databricks"><a href="#2-Azure-Databricks" class="headerlink" title="2. Azure Databricks"></a>2. Azure Databricks</h2><p>It was nice to visualize the time series data in TSI, but I would like to play more with the dataset, such as calculating the fuel consumption vs. speed for example. I would like to use python and jupyter notebook. Therefore I continue the work with <a href="https://azure.microsoft.com/en-us/services/databricks/">Azure Databrick</a>.</p><h3 id="2-1-Simple-plot-of-Speed-vs-RPM"><a href="#2-1-Simple-plot-of-Speed-vs-RPM" class="headerlink" title="2.1 Simple plot of Speed vs RPM"></a>2.1 Simple plot of Speed vs RPM</h3><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/speed%20vs%20rpm.png" class="" title="Speed vs RPM"><h3 id="2-2-Calculate-the-fuel-consumption-and-eco-driving-zone"><a href="#2-2-Calculate-the-fuel-consumption-and-eco-driving-zone" class="headerlink" title="2.2 Calculate the fuel consumption and eco-driving zone"></a>2.2 Calculate the fuel consumption and eco-driving zone</h3><p>By using MFA and speed, it is possible to calculate the fuel consumption, as explained in <a href="https://www.windmill.co.uk/fuel.html">https://www.windmill.co.uk/fuel.html</a> and <a href="https://www.wikihow.com/Convert-MPG-to-Liters-per-100km">https://www.wikihow.com/Convert-MPG-to-Liters-per-100km</a>. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Adding MPG column</span></span><br><span class="line"><span class="comment"># MPG=Speed(Km/h)*7.718/MAF</span></span><br><span class="line">dfwithMPG = df.withColumn(<span class="string">&quot;MPG&quot;</span>,df.series_SPEED_double/df.series_MAF_double*<span class="number">7.718</span>).select(<span class="string">&quot;timestamp&quot;</span>, <span class="string">&quot;series_SPEED_double&quot;</span>, <span class="string">&quot;series_RPM_double&quot;</span>, <span class="string">&quot;MPG&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Then convert from MPG to L/100km, adding Consumption column, using US galoons</span></span><br><span class="line">l/100km = <span class="number">282.48</span>/MPG (imperial gallons) <span class="keyword">or</span>  l/100km = <span class="number">235.21</span>/MPG (US gallons)</span><br><span class="line">dfwithConsumption = dfwithMPG.withColumn(<span class="string">&quot;Consumption&quot;</span>,<span class="number">235.21</span>/dfwithMPG.MPG).select(<span class="string">&quot;timestamp&quot;</span>, <span class="string">&quot;series_SPEED_double&quot;</span>, <span class="string">&quot;series_RPM_double&quot;</span>, <span class="string">&quot;MPG&quot;</span>, <span class="string">&quot;Consumption&quot;</span>)</span><br></pre></td></tr></table></figure><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/fuel%20consumption.jpg" class="" title="Fuel Consumption"><p>(Picture: Oversimplified calculation of eco-driving zone)</p><h3 id="2-3-Issue-of-TSI-generated-parquet-files"><a href="#2-3-Issue-of-TSI-generated-parquet-files" class="headerlink" title="2.3 Issue of TSI generated parquet files"></a>2.3 Issue of TSI generated parquet files</h3><p>If we directly use the TSI parquet files as input for the databricks, we will encounter an error message <strong>“Found duplicate column(s) in data schema: “series_speed_double”</strong>.</p><p>This is because both GPS and OBD modules are reporting speed, but with different case <strong>“Speed”</strong> and <strong>“SPEED”</strong>.</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/duplicate%20columns.png" class="" title="Duplicate columns for speed"><p>TSI is fine with it, as the asset model&#x2F;metadata helps, but in Databrick there is no data contextualization - all data fields are flattened out, therefore it is quite often encountering this type of issue.</p><p>As a workaround, we can set spark.sql.caseSensitive as true </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.sql(<span class="string">&quot;set spark.sql.caseSensitive=true&quot;</span>)</span><br><span class="line">df = sqlContext.read.parquet(file_path).select(<span class="string">&quot;column1&quot;</span>, <span class="string">&quot;column2&quot;</span> )</span><br></pre></td></tr></table></figure><h3 id="2-4-Summary-of-Databricks-experience"><a href="#2-4-Summary-of-Databricks-experience" class="headerlink" title="2.4 Summary of Databricks experience"></a>2.4 Summary of Databricks experience</h3><p><strong>Pro:</strong></p><ul><li>The standard tool&#x2F;eco-system for data analytics, can do almost anything</li><li>Rich and powerful libraries</li></ul><p><strong>Con:</strong></p><ul><li>Not for ordinary business users who do not work with python&#x2F;programming</li><li>Some visualization such as map and animation requires extra work</li><li>Tried PowerBI to databricks (spark), did not manage to make it work at that time (beta version) </li><li>No builtin data contextualization support, take the input as it is, which is an issue with TSI parquet files</li></ul><h2 id="3-Azure-Data-Explorer-ADX"><a href="#3-Azure-Data-Explorer-ADX" class="headerlink" title="3. Azure Data Explorer (ADX)"></a>3. Azure Data Explorer (ADX)</h2><p>After tried the a-bit-too-simple TSI and a-bit-too-hardcore Databrick, I was looking for a better-balanced product between them. Therefore I started exploring <a href="https://azure.microsoft.com/en-us/services/data-explorer/">Azure Data Explorer (ADX)</a>.</p><h3 id="3-1-Setup-database-and-ingestion-mapping"><a href="#3-1-Setup-database-and-ingestion-mapping" class="headerlink" title="3.1 Setup database and ingestion mapping"></a>3.1 Setup database and ingestion mapping</h3><p>Long story short, I created an ADX cluster and a database for IoT Car data, created 2 tables:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.create table OBDTable (timestamp: datetime, deviceId: string, speed: real, rpm: real, run_time: real, absolute_load: real, short_fuel_trim_1: real, long_fuel_trim_1: real, timing_advance: real, intake_pressure: real, intake_temp: real, throttle_pos: real, relative_throttle_pos: real, oil_temp: real, maf: real, coolant_temp: real, engine_load: real) </span><br><span class="line"></span><br><span class="line">.create table GPSTable (timestamp: datetime, deviceId: string, gps_speed: real, altitude: real, longitude: string, latitude: string) </span><br></pre></td></tr></table></figure><p>And create mappings as below:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;Name&quot;</span><span class="punctuation">:</span> GPSMapping<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Kind&quot;</span><span class="punctuation">:</span> Json<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Mapping&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;timestamp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.timestamp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;datetime&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;deviceId&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.deviceId&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;string&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;gps_speed&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].gps_speed&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;altitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].altitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;longitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].longitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;string&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;latitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].latitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;string&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;LastUpdatedOn&quot;</span><span class="punctuation">:</span> <span class="number">2019</span><span class="number">-02</span><span class="number">-27</span>T19<span class="punctuation">:</span><span class="number">25</span><span class="punctuation">:</span><span class="number">47.889932</span>Z<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Database&quot;</span><span class="punctuation">:</span> iotcardb<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Table&quot;</span><span class="punctuation">:</span> GPSTable<span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;Name&quot;</span><span class="punctuation">:</span> OBDMapping<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Kind&quot;</span><span class="punctuation">:</span> Json<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Mapping&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;timestamp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.timestamp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;datetime&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;deviceId&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.deviceId&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;string&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;speed&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].SPEED&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;rpm&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].RPM&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;run_time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].RUN_TIME&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;absolute_load&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].ABSOLUTE_LOAD&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;short_fuel_trim_1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].SHORT_FUEL_TRIM_1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;long_fuel_trim_1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].LONG_FUEL_TRIM_1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;timing_advance&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].TIMING_ADVANCE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;intake_pressure&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].INTAKE_PRESSURE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;intake_temp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].INTAKE_TEMP&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;throttle_pos&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].THROTTLE_POS&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;relative_throttle_pos&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].RELATIVE_THROTTLE_POS&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;oil_temp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].OIL_TEMP&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;maf&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].MAF&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;coolant_temp&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].COOLANT_TEMP&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;column&quot;</span><span class="punctuation">:</span><span class="string">&quot;engine_load&quot;</span><span class="punctuation">,</span><span class="attr">&quot;path&quot;</span><span class="punctuation">:</span><span class="string">&quot;$.series[0].ENGINE_LOAD&quot;</span><span class="punctuation">,</span><span class="attr">&quot;datatype&quot;</span><span class="punctuation">:</span><span class="string">&quot;double&quot;</span><span class="punctuation">,</span><span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span><span class="string">&quot;None&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;LastUpdatedOn&quot;</span><span class="punctuation">:</span> <span class="number">2019</span><span class="number">-02</span><span class="number">-27</span>T19<span class="punctuation">:</span><span class="number">17</span><span class="punctuation">:</span><span class="number">24.3220181</span>Z<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Database&quot;</span><span class="punctuation">:</span> iotcardb<span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;Table&quot;</span><span class="punctuation">:</span> OBDTable<span class="punctuation">,</span></span><br></pre></td></tr></table></figure><h3 id="3-2-Data-analytics-by-using-kusto-query-language"><a href="#3-2-Data-analytics-by-using-kusto-query-language" class="headerlink" title="3.2 Data analytics by using kusto query language"></a>3.2 Data analytics by using kusto query language</h3><p>Now we are ready to query by using powerful <a href="https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/">kusto query language</a>, especially the <a href="https://docs.microsoft.com/en-us/azure/data-explorer/time-series-analysis">timeseries related analytics</a>.</p><h4 id="3-2-1-Average-GPS-speed-aggregated-by-every-20-seconds"><a href="#3-2-1-Average-GPS-speed-aggregated-by-every-20-seconds" class="headerlink" title="3.2.1 Average GPS speed aggregated by every 20 seconds"></a>3.2.1 Average GPS speed aggregated by every 20 seconds</h4><p>Simple data aggregation</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//avg gps speed every 20s</span><br><span class="line"><span class="built_in">let</span> min_t = datetime(2019-03-06 12:30:00); //UTC</span><br><span class="line"><span class="built_in">let</span> max_t = datetime(2019-03-06 13:00:00); //UTC</span><br><span class="line">GPSTable</span><br><span class="line">| <span class="built_in">where</span> timestamp between (min_t .. max_t)</span><br><span class="line">| summarize avg(gps_speed) by bin(timestamp, 20s)</span><br><span class="line">| render timechart </span><br></pre></td></tr></table></figure><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/adx%20average%20gps%20speed.png" class="" title="ADX average GPS speed"><h4 id="3-2-2-Join-2-tables-Show-obd-speed-gps-speed-and-avg-MAF"><a href="#3-2-2-Join-2-tables-Show-obd-speed-gps-speed-and-avg-MAF" class="headerlink" title="3.2.2 Join 2 tables, Show obd speed, gps speed and avg MAF"></a>3.2.2 Join 2 tables, Show obd speed, gps speed and avg MAF</h4><p>Inner join two tables and apply aggregation</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//join 2 tables, show obd speed, gps speed and avg maf </span><br><span class="line"><span class="built_in">let</span> min_t = datetime(2019-03-06 12:30:00); //UTC</span><br><span class="line"><span class="built_in">let</span> max_t = datetime(2019-03-06 13:00:00); //UTC</span><br><span class="line">GPSTable</span><br><span class="line">| <span class="built_in">where</span> timestamp between (min_t .. max_t)</span><br><span class="line">| summarize avg(gps_speed) by bin(timestamp, 20s)</span><br><span class="line">| <span class="built_in">join</span> kind=inner</span><br><span class="line">(OBDTable </span><br><span class="line">| <span class="built_in">where</span> timestamp between (min_t .. max_t)</span><br><span class="line">| summarize avg(speed), avg(maf) by bin(timestamp, 20s))</span><br><span class="line">on timestamp </span><br><span class="line">| project timestamp, avg_gps_speed, avg_speed, avg_maf </span><br><span class="line">| render timechart</span><br></pre></td></tr></table></figure><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/ADX%20join%202%20tables.png" class="" title="ADX join 2 tables"><h4 id="3-2-3-Applies-two-segments-linear-regression-on-engine-load"><a href="#3-2-3-Applies-two-segments-linear-regression-on-engine-load" class="headerlink" title="3.2.3 Applies two segments linear regression on engine_load"></a>3.2.3 Applies two segments linear regression on engine_load</h4><p>Apply two segments linear regression on engine load, see the document <a href="https://docs.microsoft.com/en-us/azure/kusto/query/series-fit-2lines-dynamicfunction">here</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//Applies two segments linear regression on engine_load. </span><br><span class="line"><span class="built_in">let</span> min_t = datetime(2019-03-06 12:40:55); //UTC</span><br><span class="line"><span class="built_in">let</span> max_t = datetime(2019-03-06 12:57:20); //UTC</span><br><span class="line">OBDTable</span><br><span class="line">| <span class="built_in">where</span> coolant_temp &gt; 0</span><br><span class="line">| make-series engine_load_targetAvg = avg(engine_load) default = 0 on timestamp <span class="keyword">in</span> range(min_t, max_t, 5s)</span><br><span class="line">| extend LineFit=series_fit_line_dynamic(engine_load_targetAvg).line_fit, LineFit2=series_fit_2lines_dynamic(engine_load_targetAvg).line_fit</span><br><span class="line">| project timestamp, engine_load_targetAvg, LineFit, LineFit2 </span><br><span class="line">| render timechart</span><br></pre></td></tr></table></figure><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/adx%20two%20segments%20linear%20regression%20on%20engine%20load.png" class="" title="Applies two segments linear regression on engine_load"><h3 id="3-3-Summary-of-ADX-experience"><a href="#3-3-Summary-of-ADX-experience" class="headerlink" title="3.3 Summary of ADX experience"></a>3.3 Summary of ADX experience</h3><p>Pro:</p><ul><li>Easy and powerful <a href="https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/">kusto query language</a>, good balance between capacity and user-friendly query.</li><li>Powerful and proven data computing capacity (the same technology that powers Azure log) </li><li>Contextualization in storage (table and columns)</li><li>Works well with PowerBI (see PowerBI section)</li></ul><p>Con:</p><ul><li>Cannot replace the “real” big data products </li><li>It has its own <a href="https://docs.microsoft.com/en-us/azure/kusto/concepts/querylimits">query limits</a></li><li>Missing some visualization such as map and animation</li></ul><h2 id="4-PowerBI"><a href="#4-PowerBI" class="headerlink" title="4. PowerBI"></a>4. PowerBI</h2><p>So far I have tried several products for analytics, but none of them have great built-in visualization features, especially on map support.</p><p>PowerBI is a popular tool for data visualization, but it does not support big data analytics. However, by combining PowerBI and ADX, the job is easier.</p><h3 id="4-1-Let-ADX-to-handle-the-computing-part"><a href="#4-1-Let-ADX-to-handle-the-computing-part" class="headerlink" title="4.1 Let ADX to handle the computing part"></a>4.1 Let ADX to handle the computing part</h3><p>Instead of doing the visualization in ADX, now we use a query to generate a dataset (two dimensional table)</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="keyword">for</span> powerbi map, CANNOT have comments<span class="operator">!</span></span><br><span class="line"></span><br><span class="line">let min_t <span class="operator">=</span> datetime(<span class="number">2019</span><span class="number">-03</span><span class="number">-06</span> <span class="number">12</span>:<span class="number">40</span>:<span class="number">55</span>);</span><br><span class="line">let max_t <span class="operator">=</span> datetime(<span class="number">2019</span><span class="number">-03</span><span class="number">-06</span> <span class="number">12</span>:<span class="number">57</span>:<span class="number">20</span>);</span><br><span class="line">GPSTable</span><br><span class="line"><span class="operator">|</span> <span class="keyword">where</span> <span class="type">timestamp</span> <span class="keyword">between</span> (min_t .. max_t)</span><br><span class="line"><span class="operator">|</span> summarize <span class="keyword">any</span>(longitude), <span class="keyword">any</span>(latitude) <span class="keyword">by</span> bin(<span class="type">timestamp</span>, <span class="number">20</span>s)</span><br><span class="line"><span class="operator">|</span> <span class="keyword">join</span> kind<span class="operator">=</span><span class="keyword">inner</span></span><br><span class="line">(OBDTable </span><br><span class="line"><span class="operator">|</span> <span class="keyword">where</span> <span class="type">timestamp</span> <span class="keyword">between</span> (min_t .. max_t)</span><br><span class="line"><span class="operator">|</span> summarize <span class="built_in">avg</span>(speed), <span class="built_in">avg</span>(maf), <span class="built_in">avg</span>(rpm) <span class="keyword">by</span> bin(<span class="type">timestamp</span>, <span class="number">20</span>s))</span><br><span class="line"><span class="keyword">on</span> <span class="type">timestamp</span> </span><br><span class="line"><span class="operator">|</span> project <span class="type">timestamp</span>, any_latitude, any_longitude, avg_speed, avg_maf, avg_rpm </span><br></pre></td></tr></table></figure><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/ADX%20for%20PowerBI.png" class="" title="ADX for PowerBI"><p>Then use “Query to PowerBI” on the dropdown list. </p><p>NOTE: When I was testing this, there was an issue that the Kusto query can NOT have inline comments, otherwise these inline comments will be mixed into the generated powerBI query, which ruined the syntax. Keep all the comments out of the kusto query block.</p><h3 id="4-2-In-PowerBI-create-good-looking-visualization-dashboard"><a href="#4-2-In-PowerBI-create-good-looking-visualization-dashboard" class="headerlink" title="4.2 In PowerBI, create good-looking visualization dashboard"></a>4.2 In PowerBI, create good-looking visualization dashboard</h3><p>By using the generated PowerBI query from above, I can easily create differnt visualization dashboard in PowerBI. For example the map:</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/PowerBI%20map.png" class="" title="Map in PowerBI, with speed group"><p>It shows one of the trips on the map, as well as the speed: greener is faster, and reder means slower.</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/PowerBI%20map%20zoom%20in.jpg" class="" title="PowerBI map zoom in"><h3 id="4-3-Replay-a-trip"><a href="#4-3-Replay-a-trip" class="headerlink" title="4.3 Replay a trip"></a>4.3 Replay a trip</h3><p>Using PowerBI addon such as <a href="https://appsource.microsoft.com/en-us/product/office/WA104380981">Play Axis (Dynamic Slicer)</a>, it is easy to replay a trip.</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/PowerBI%20replay%20a%20trip.gif" class="" title="PowerBI replay a trip"><p>Picture: Play a trip in PowerBI, with map and engine RPM.</p><ul><li>X-axis: time</li><li>Y-axis: speed (from GPS)</li><li>Size of the bubble: Engine RPM (from OBD)</li></ul><p>It clearly shows where was the traffic jam (drops of speed), and where had a good traffic condition (peak of speed and RPM).</p><h3 id="4-4-Summary-of-PowerBI-experience"><a href="#4-4-Summary-of-PowerBI-experience" class="headerlink" title="4.4 Summary of PowerBI experience"></a>4.4 Summary of PowerBI experience</h3><p><strong>Pro:</strong></p><ul><li>Easy to use</li><li>Rich visualization (e.g. map)</li><li>Easy to share (e.g. PowerBI Online)</li></ul><p><strong>Con:</strong></p><ul><li>Not for big data computing, but good for visualization</li><li>Need a “big data computing” back end (in our case it is ADX)</li></ul><h2 id="5-Grafana"><a href="#5-Grafana" class="headerlink" title="5. Grafana"></a>5. Grafana</h2><p>PowerBI is a good visualization tool, but it is not easy to directly create&#x2F;update kusto query in PowerBI. Most likely you will have to run and test the query in ADX, then export to PowerBI. We hope to overcome this issue with Grafana.</p><p><a href="https://grafana.com/">Grafana</a> is an open source tool mainly used for monitoring and data visualization.  With the <a href="https://grafana.com/grafana/plugins/grafana-azure-data-explorer-datasource">Azure Data Explorer Datasource For Grafana</a> plugin, we can integrate the ADX and Kusto power with fancy and powerful Grafana visualization. </p><h3 id="5-1-Run-Grafana-as-docker-with-preinstalled-ADX-data-source-plugin"><a href="#5-1-Run-Grafana-as-docker-with-preinstalled-ADX-data-source-plugin" class="headerlink" title="5.1 Run Grafana as docker, with preinstalled ADX data source plugin"></a>5.1 Run Grafana as docker, with preinstalled ADX data source plugin</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 3000:3000 -e <span class="string">&quot;GF_INSTALL_PLUGINS=grafana-azure-data-explorer-datasource&quot;</span> grafana/grafana:latest</span><br></pre></td></tr></table></figure><p>Then follow the <a href="https://grafana.com/grafana/plugins/grafana-azure-data-explorer-datasource">plugin documenation</a> to config access.</p><p>Now you can directly create Kusto-enabled dashboard, including map.</p><img src="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/grafana%20dashboard.jpg" class="" title="Grafana dashboard"><h3 id="5-2-Summary-of-Grafana-experience"><a href="#5-2-Summary-of-Grafana-experience" class="headerlink" title="5.2  Summary of Grafana experience"></a>5.2  Summary of Grafana experience</h3><p><strong>Pro:</strong></p><ul><li>Very rich and powerful visualization</li><li>Self-service Kusto enabled queries and build dashboard</li><li>Built-in access control and notification support</li><li>Big support by the community</li></ul><p><strong>Con:</strong></p><ul><li>(cannot find one…for now)</li></ul><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Now we have tried several products, and my favorite setup is ADX (as backend data storage and query) and Grafana (as front end self-service visualization). I believe it meet the most common needs of ordinary users. But of course other products have different focus areas and can&#x2F;should be used for different scenarios. </p><p>After all, the old saying is always correct: “It depends.”</p><p>Thanks for the reading.</p><p>(Read <a href="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/" title="How to build an IoT connected car - Part 1: On the Edge">Part 1</a> of this article series)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;In &lt;a href=&quot;/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/&quot; title=&quot;How to build an IoT connected car - Part 1: On the Edge&quot;&gt;Part 1&lt;/a&gt;, we have talked about the hardware&amp;#x2F;software running on the edge (the car) for collecting data.&lt;/p&gt;
&lt;p&gt;Now we have the data, and how to gain some insights by doing data analytics? I have been using the following products, and would like to share my quick thoughts&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Azure Time Series Insight (TSI)&lt;/li&gt;
&lt;li&gt;Azure Databricks&lt;/li&gt;
&lt;li&gt;Azure Data Explorer (ADX)&lt;/li&gt;
&lt;li&gt;PowerBI&lt;/li&gt;
&lt;li&gt;Grafana&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&quot;/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/Thumbnail.png&quot; class=&quot;&quot; title=&quot;Thumbnail&quot;&gt;</summary>
    
    
    
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="Azure" scheme="https://feng.lu/tags/Azure/"/>
    
    <category term="PowerBI" scheme="https://feng.lu/tags/PowerBI/"/>
    
    <category term="Data Analytics" scheme="https://feng.lu/tags/Data-Analytics/"/>
    
    <category term="Car" scheme="https://feng.lu/tags/Car/"/>
    
    <category term="Python" scheme="https://feng.lu/tags/Python/"/>
    
    <category term="Jupyter Notebook" scheme="https://feng.lu/tags/Jupyter-Notebook/"/>
    
    <category term="Visualization" scheme="https://feng.lu/tags/Visualization/"/>
    
    <category term="Databricks" scheme="https://feng.lu/tags/Databricks/"/>
    
    <category term="Time Series Insight (TSI)" scheme="https://feng.lu/tags/Time-Series-Insight-TSI/"/>
    
    <category term="Azure Data Explorer (ADX)" scheme="https://feng.lu/tags/Azure-Data-Explorer-ADX/"/>
    
    <category term="Grafana" scheme="https://feng.lu/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>How to build an IoT connected car - Part 1: On the Edge</title>
    <link href="https://feng.lu/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/"/>
    <id>https://feng.lu/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/</id>
    <published>2020-09-15T08:38:12.000Z</published>
    <updated>2025-03-28T09:05:16.640Z</updated>
    
    <content type="html"><![CDATA[<p>Previously I wrote a blog about how to <a href="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/" title="How to measure your Hamster&#39;s running with wireless IoT">measure hamster via IoT wheel</a>. This reminds me another personal project I did back to the winter of 2018&#x2F;2019, for measuring car performance. </p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/Thumbnail.png" class="" title="Thumbnail"> <span id="more"></span><h1 id="Other-articles-in-this-series"><a href="#Other-articles-in-this-series" class="headerlink" title="Other articles in this series:"></a>Other articles in this series:</h1><ul><li>Part 1 (this article):<br>Talk about the hardware&#x2F;software running on the edge (the car) for collecting data.</li><li><a href="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/" title="How to build an IoT connected car - Part 2: Data Analytics in the Cloud">Part 2</a>:Talk about how to get insight from the data with different analytic tools.</li></ul><h1 id="1-Overview-on-the-edge"><a href="#1-Overview-on-the-edge" class="headerlink" title="1. Overview on the edge"></a>1. Overview on the edge</h1><h2 id="1-1-Hardware"><a href="#1-1-Hardware" class="headerlink" title="1.1 Hardware"></a>1.1 Hardware</h2><ul><li>OBD2 USB connector<br><a href="https://en.wikipedia.org/wiki/On-board_diagnostics">OBD2</a> is an interface&#x2F;protocol that is available for 1996 and newer vehicles. It reports <a href="https://en.wikipedia.org/wiki/OBD-II_PIDs">various telemetries</a> of the vehicle.</li><li>USB GPS dongle<br>For collecting location information</li><li>Raspberry Pi<br>Running Linux, Azure IoT Edge runtime and hosting 2 modules (OBD and GPS location)</li><li>USB Wifi dongle<br>For connecting mobile phone hotspot</li><li>Mobile phone<br>For realtime data uploading to the cloud via 4G</li><li>Power bank (optional)<br>For powering up raspberry pi. Alternatively, you can use a 12V-&gt;5V adapter to use the car battery.</li></ul><h2 id="1-2-Software"><a href="#1-2-Software" class="headerlink" title="1.2 Software"></a>1.2 Software</h2><ul><li>Azure IoT Edge</li><li>Docker</li><li>Python</li></ul><h2 id="1-3-Dataflow-and-Architecture"><a href="#1-3-Dataflow-and-Architecture" class="headerlink" title="1.3 Dataflow and Architecture"></a>1.3 Dataflow and Architecture</h2><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/hardware%20architecture.png" class="" title="Hardware architecture"><h1 id="2-Developing-IoT-Edge-modules"><a href="#2-Developing-IoT-Edge-modules" class="headerlink" title="2. Developing IoT Edge modules"></a>2. Developing IoT Edge modules</h1><h2 id="2-1-Introduction"><a href="#2-1-Introduction" class="headerlink" title="2.1 Introduction"></a>2.1 Introduction</h2><h3 id="2-1-1-Design-Principles"><a href="#2-1-1-Design-Principles" class="headerlink" title="2.1.1 Design Principles"></a>2.1.1 Design Principles</h3><p>As there are many possible situations can happen on the edge, such as disconnection from OBD2 connector, or loss of GPS signal (when going through an underground tunnel), the modules are built with the following principles:</p><ul><li>Design for failure </li><li>Auto healing</li></ul><p>In addition, the modules are built into docker containers, together with Azure IoT Edge runtime, which makes it easier to deploy.</p><h3 id="2-1-2-Source-code"><a href="#2-1-2-Source-code" class="headerlink" title="2.1.2 Source code"></a>2.1.2 Source code</h3><p>All source code can be found at <a href="https://github.com/linkcd/IoTCar">https://github.com/linkcd/IoTCar</a></p><h3 id="2-1-3-Sample-data"><a href="#2-1-3-Sample-data" class="headerlink" title="2.1.3 Sample data"></a>2.1.3 Sample data</h3><p>This edge device (raspberry pi + OBD connector + GPS dongle) reports the following data per second:</p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/sample-data.png" class="" title="sample data"><h2 id="2-2-GPS-location-module-details"><a href="#2-2-GPS-location-module-details" class="headerlink" title="2.2 GPS location module - details"></a>2.2 GPS location module - details</h2><p><a href="https://github.com/linkcd/IoTCar/tree/master/modules/LocatorModule">Source code</a></p><p>With a USB GPS dongle, it is quite easy to get the location information by using tools such as <a href="https://gpsd.gitlab.io/gpsd/index.html">GPSD</a>.</p><h3 id="2-2-1-You-have-to-dev-test-in-the-field-not-only-in-the-office"><a href="#2-2-1-You-have-to-dev-test-in-the-field-not-only-in-the-office" class="headerlink" title="2.2.1 You have to dev&#x2F;test in the field, not only in the office"></a>2.2.1 You have to dev&#x2F;test in the field, not only in the office</h3><p>I immediately met the first challenge: The USB GPS dongle requires a good open sky view to work well. The one that I used does not have an antenna, so I need to put the whole thing (raspberry pi + GPS dongle) outside of the building (or at least outside of the window).</p><p>Remind you that it was winter in Norway during that time, and I was not a fan of typing keyboard in the snow with -5 degrees. </p><p>Firstly, I have tried do this in my car: parked the car in an outdoor parking slot, put the raspberry pi on the dashboard and remote desktop to it. Well, it worked, GSP signal was strong, but it was quite difficult to type any keys behind the steering wheel :)</p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/GPS-in-car-small.png" class="" title="Testing GPS in the car"><p>But soon I figured out a better solution on my balcony (see below picture), and that worked perfectly (as far as the wifi signal is good and the power bank battery did not die from the low temperature)</p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/gps-programming-in-winter.png" class="" title="programming GPS in winter"><p>Now I can work from a warm cozy place and deal with the GPS data that is collected from the “cold box”. </p><h3 id="2-2-2-Working-with-GPS-data-with-python"><a href="#2-2-2-Working-with-GPS-data-with-python" class="headerlink" title="2.2.2 Working with GPS data with python"></a>2.2.2 Working with GPS data with python</h3><p>The GPS receiver reports data as <a href="https://www.gpsinformation.org/dale/nmea.htm#nmea">NMEA sentences</a>, and we are combining <a href="https://www.gpsinformation.org/dale/nmea.htm#GGA">GGA</a> and <a href="https://www.gpsinformation.org/dale/nmea.htm#RMC">RMC</a>. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GGA </span></span><br><span class="line"><span class="variable">$GPGGA</span>,123519,4807.038,N,01131.000,E,1,08,0.9,545.4,M,46.9,M,,*47</span><br><span class="line"><span class="comment"># RMC</span></span><br><span class="line"><span class="variable">$GPRMC</span>,123519,A,4807.038,N,01131.000,E,022.4,084.4,230394,003.1,W*6A</span><br></pre></td></tr></table></figure><p>Here we are using a python lib <a href="https://github.com/Knio/pynmea2">pynmea2</a> for handling the NMEA sentences, the detailed logic can be found at <a href="https://github.com/linkcd/IoTCar/blob/master/modules/LocatorModule/gpsreader.py#L66">source code here</a>.</p><p>In addition, we need to do some <a href="https://github.com/linkcd/IoTCar/blob/master/modules/LocatorModule/gpsreader.py#L27">small math</a> for calculating the correct latitude and longitude, otherwise you will find your car was driving in the ocean :)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The latitude is formatted as DDMM.ffff and longitude is DDDMM.ffff where D is the degrees and M is minutes plus the fractional minutes. </span></span><br><span class="line"><span class="comment"># So, 1300.8067,N is 13 degrees 00.8067 minutes North and the longitude of 07733.0003,E is read as 77 degrees 33.0003 minutes East.</span></span><br><span class="line"><span class="comment"># Converting to degrees you would have to do this: 13 + 00.8067/60 for latitude and 77 + 33.0003/60 for the longitude.</span></span><br><span class="line"><span class="comment"># ##NMEA outputs in a human readable DDDMM.mmmm format NOT DECIMAL DEGREES</span></span><br><span class="line"><span class="comment"># 3746.03837</span></span><br><span class="line"><span class="comment"># 37 46.03837</span></span><br><span class="line"><span class="comment"># 37 + (46.03837 / 60)</span></span><br><span class="line"><span class="comment"># result = 37 + 0.7673062</span></span><br><span class="line"></span><br><span class="line">segments = value.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(segments[<span class="number">0</span>]) == <span class="number">4</span>:</span><br><span class="line">    <span class="comment">#lanitude</span></span><br><span class="line">    degree = segments[<span class="number">0</span>][:<span class="number">2</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment">#longtitude</span></span><br><span class="line">    degree = segments[<span class="number">0</span>][:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">minute = <span class="built_in">round</span>(Decimal(segments[<span class="number">0</span>][-<span class="number">2</span>:] + <span class="string">&quot;.&quot;</span> + segments[<span class="number">1</span>])/<span class="number">60</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure><p>Finally, this module reports the following data per second</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;series&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;mag_variation&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;geo_sep&quot;</span><span class="punctuation">:</span> <span class="string">&quot;39.1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;num_sats&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fixed_time&quot;</span><span class="punctuation">:</span> <span class="string">&quot;20:33:21&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;geo_sep_units&quot;</span><span class="punctuation">:</span> <span class="string">&quot;M&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;horizontal_dil&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2.21&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;longitude_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;E&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;mag_var_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;gps_speed&quot;</span><span class="punctuation">:</span> <span class="number">0.242</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;altitude_units&quot;</span><span class="punctuation">:</span> <span class="string">&quot;M&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;true_course&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;latitude&quot;</span><span class="punctuation">:</span> <span class="string">&quot;11.111111&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fixed_full_timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-02-26 20:33:21&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;latitude_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;N&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fixed_date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-02-26&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;gps_quality&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;longitude&quot;</span><span class="punctuation">:</span> <span class="string">&quot;22.222222&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;altitude&quot;</span><span class="punctuation">:</span> <span class="number">93.4</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;deviceId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;FengsDevice_GPS&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-02-26 20:33:21&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="2-3-OBD2-module-details"><a href="#2-3-OBD2-module-details" class="headerlink" title="2.3 OBD2 module - details"></a>2.3 OBD2 module - details</h2><p><a href="https://github.com/linkcd/IoTCar/tree/master/modules/OBDModule">Source code</a></p><h3 id="2-3-1-You-cannot-do-it-in-the-field-do-it-on-an-emulator-instead"><a href="#2-3-1-You-cannot-do-it-in-the-field-do-it-on-an-emulator-instead" class="headerlink" title="2.3.1 You cannot do it in the field, do it on an emulator instead"></a>2.3.1 You cannot do it in the field, do it on an emulator instead</h3><p>Programming&#x2F;debugging OBD2 can be difficult - after all I do not want to be programming while driving. Instead of hiring a driver and typing the keyboard on the passenger seat, it is better to use an ODB emulator to emulate all telemetries (and error codes) of the car.</p><h4 id="OBD2-Emulator"><a href="#OBD2-Emulator" class="headerlink" title="OBD2 Emulator"></a>OBD2 Emulator</h4><p>Lucky I am not alone who has the same problem during OBD development. There are professional and affordable emulators on <a href="https://www.alibaba.com/product-detail/Professional-OBD2-Emulator-Tool-for-OBD_62315028570.html">Aliexpress</a> and <a href="https://item.taobao.com/item.htm?spm=a230r.1.14.37.532d3fe1POSTRH&id=613000775363&ns=1&abbucket=12#detail">Taobao</a> (BTW The price on Taobao is 1&#x2F;3 as Aliexpress!).  The detailed features can be found at [here](OBD emulator features.jpg). My respects to the designers of this emulator - you are life savers!</p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/OBD%20emulator%203.png" class="" title="OBD emulator"><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/OBD%20emulator1.jpg" class="" title="OBD emulator"><h3 id="2-3-2-Design-for-failure-and-auto-healing"><a href="#2-3-2-Design-for-failure-and-auto-healing" class="headerlink" title="2.3.2 Design for failure and auto healing"></a>2.3.2 Design for failure and auto healing</h3><p>Now, with the emulator and python <a href="https://pypi.org/project/obd/">obd lib</a>, it is easy to collect the telemetries of the car.</p><p>However, the library does not take care of failures and auto-healing, which we need to do it ourselves, otherwise the code just throw exceptions and stop working.</p><p>Thanks to the emulator, it is easy to test all corner scenarios, such as disconnect the ODB and reconnect while “the engine” is still running, in a safe environment. That is impossible to test&#x2F;debug with real car.</p><p>The following code snippet ensures the modules works with different scenarios and self-healing:</p><ul><li>Car is powered off</li><li>Car is powered on but engine is not started yet</li><li>Engine starts</li><li>Engine is stopped but car is still powered on</li><li>OBD receiver is disconnected (e.g lost bluetooth signal)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getVehicleTelemtries</span>(<span class="params">deviceId</span>):</span><br><span class="line">    <span class="keyword">global</span> connection</span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">not</span> connection.is_connected()):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No connecting to the car, reconnecting...&quot;</span>)</span><br><span class="line">        connection = obd.OBD(fast=<span class="literal">True</span>) </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># Use library to get readings...</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(telemtryDic[<span class="string">&quot;RPM&quot;</span>] == <span class="number">0</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Cannot read RPM, reconnecting...&quot;</span>)</span><br><span class="line">            connection = obd.OBD(fast=<span class="literal">True</span>) </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> buildJsonPayload(deviceId, telemtryDic)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Error with OBDII, error: &quot;</span> + <span class="built_in">str</span>(e) + <span class="string">&quot;. Reconnecting...&quot;</span>)</span><br><span class="line">        connection = obd.OBD(fast=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/ODB%20connection%20in%20car.jpg" class="" title="obd connection in car"><p>Finally, this module reports the following data per second:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;series&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;SPEED&quot;</span>: <span class="number">56</span>,</span><br><span class="line">      <span class="string">&quot;RPM&quot;</span>: <span class="number">2830.75</span>,</span><br><span class="line">      <span class="string">&quot;RUN_TIME&quot;</span>: <span class="number">639</span>,</span><br><span class="line">      <span class="string">&quot;ABSOLUTE_LOAD&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">      <span class="string">&quot;SHORT_FUEL_TRIM_1&quot;</span>: -<span class="number">21.09375</span>,</span><br><span class="line">      <span class="string">&quot;TIMING_ADVANCE&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">      <span class="string">&quot;INTAKE_PRESSURE&quot;</span>: <span class="number">0</span>,</span><br><span class="line">      <span class="string">&quot;LONG_FUEL_TRIM_1&quot;</span>: <span class="number">18.75</span>,</span><br><span class="line">      <span class="string">&quot;INTAKE_TEMP&quot;</span>: <span class="number">0</span>,</span><br><span class="line">      <span class="string">&quot;THROTTLE_POS&quot;</span>: <span class="number">37.64705882352941</span>,</span><br><span class="line">      <span class="string">&quot;OIL_TEMP&quot;</span>: <span class="number">16</span>,</span><br><span class="line">      <span class="string">&quot;MAF&quot;</span>: <span class="number">655.35</span>,</span><br><span class="line">      <span class="string">&quot;RELATIVE_THROTTLE_POS&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">      <span class="string">&quot;COOLANT_TEMP&quot;</span>: <span class="number">0</span>,</span><br><span class="line">      <span class="string">&quot;ENGINE_LOAD&quot;</span>: <span class="number">45.490196078431374</span></span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;timestamp&quot;</span>: <span class="string">&quot;2019-02-20 19:27:11.705387&quot;</span>,</span><br><span class="line">  <span class="string">&quot;deviceId&quot;</span>: <span class="string">&quot;FengsDevice_OBD&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-3-Tips-Considering-use-‘Real-Time-Clock’-or-RTC-board-for-your-Pi"><a href="#2-3-3-Tips-Considering-use-‘Real-Time-Clock’-or-RTC-board-for-your-Pi" class="headerlink" title="2.3.3 Tips: Considering use ‘Real Time Clock’ or RTC board for your Pi"></a>2.3.3 Tips: Considering use ‘Real Time Clock’ or RTC board for your Pi</h3><p>As Raspberry PI does not have an RTC, the system clock was reset after each power-on. If it has an internet connection, it will fetch the correct date-time from internet, with some delay.</p><p>In the current logic, both GPS and OBD modules are using the system clock as the event timestamp. Therefore, if the Pi failed to have internet connection (happened often with mobile hotspot) or sending data before system clock is updated due to delay, the event timestamp will be incorrect.</p><p>To overcome this issue, you can install a RTC (Real Time Clock) to the Raspberry Pi, such as <a href="https://learn.adafruit.com/adding-a-real-time-clock-to-raspberry-pi">this</a> and <a href="https://thepihut.com/blogs/raspberry-pi-tutorials/17209332-adding-a-real-time-clock-to-your-raspberry-pi">this</a>.</p><p>I end up with a <a href="https://www.tindie.com/products/rachel/ups-18650-for-raspberry-pi/">UPS-18650 Raspberry pi UPS Power Expansion Board With RTC</a>. It comes with a power bank AND a built-in RTC. It is design and built by <a href="https://www.tindie.com/stores/rachel/">ACE design studio</a> in China, and I am very happy about it. Definitely buy more from them next time.</p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/Pi%20with%20RTC.png" class="" title="Raspberry Pi with UPS power expansion board and LoRa&#x2F;GPS Hat"><p>(Picture: My to-be-tested Raspberry Pi with UPS power expansion board and LoRa&#x2F;GPS Hat.Hopefully it can use LoRa network connections to replace 4G)</p><h1 id="3-Put-things-together-and-send-to-Azure"><a href="#3-Put-things-together-and-send-to-Azure" class="headerlink" title="3. Put things together and send to Azure"></a>3. Put things together and send to Azure</h1><h2 id="3-1-Config-on-the-edge"><a href="#3-1-Config-on-the-edge" class="headerlink" title="3.1 Config on the edge"></a>3.1 Config on the edge</h2><p>Now we have 2 modules and we have built them into 2 docker images (in variables ${MODULES.OBDModule.arm32v7} and ${MODULES.LocatorModule.arm32v7}). I was hosting them in the dockerhub but it can also be hosted in any private registration.</p><p>For now we did not do any computing on the edge but simply forward them to Azure Iot Hub (see <a href="https://github.com/linkcd/IoTCar/blob/96501440601ced4e2e4d18f3e37d24905591c718/deployment.template.json#L96">here</a>)</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;$edgeHub&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;properties.desired&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;schemaVersion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;routes&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;OBDModuleToIoTHub&quot;</span><span class="punctuation">:</span> <span class="string">&quot;FROM /messages/modules/OBDModule/outputs/* INTO $upstream&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;LocatorModuleToIoTHub&quot;</span><span class="punctuation">:</span> <span class="string">&quot;FROM /messages/modules/LocatorModule/outputs/* INTO $upstream&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;storeAndForwardConfiguration&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;timeToLiveSecs&quot;</span><span class="punctuation">:</span> <span class="number">7200</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>More info can be found in the <a href="https://github.com/linkcd/IoTCar/blob/master/deployment.template.json">deployment.template.json</a>.</p><h2 id="3-2-Visualization-in-the-cloud"><a href="#3-2-Visualization-in-the-cloud" class="headerlink" title="3.2  Visualization in the cloud"></a>3.2  Visualization in the cloud</h2><p>Now we 2 module docker images running on the Raspberry Pi and sending data to Azure IoT Edge runtime. The Raspberry Pi has wifi connection to mobile phone 4G hotspot and forwarding the data to Azure IoT Hub in realtime. </p><p>With Azure IoT Hub and <a href="https://azure.microsoft.com/en-us/services/time-series-insights/">Azure Time Series Insights(TSI)</a>, we can now visualize the data:</p><img src="/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/TSI%20sample.png" class="" title="Azure Time Series Insight sample"><p>This is a quick example of data analytics for the IoT car. In the <a href="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/" title="How to build an IoT connected car - Part 2: Data Analytics in the Cloud">second part</a> of the series, I will talk more about the data analytics part (including TSI, DataBrick ++) in the cloud.</p><a href="/2020/09/22/How-to-build-an-IoT-connected-car-Part-2-Data-Analytics-in-the-Cloud/" title="How to build an IoT connected car - Part 2: Data Analytics in the Cloud">Continue reading part 2</a>]]></content>
    
    
    <summary type="html">&lt;p&gt;Previously I wrote a blog about how to &lt;a href=&quot;/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/&quot; title=&quot;How to measure your Hamster&amp;#39;s running with wireless IoT&quot;&gt;measure hamster via IoT wheel&lt;/a&gt;. This reminds me another personal project I did back to the winter of 2018&amp;#x2F;2019, for measuring car performance. &lt;/p&gt;
&lt;img src=&quot;/2020/09/15/How-to-build-an-IoT-connected-car-Part-1-On-the-Edge/Thumbnail.png&quot; class=&quot;&quot; title=&quot;Thumbnail&quot;&gt;</summary>
    
    
    
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="Raspberry Pi" scheme="https://feng.lu/tags/Raspberry-Pi/"/>
    
    <category term="Data Analytics" scheme="https://feng.lu/tags/Data-Analytics/"/>
    
    <category term="Azure IoT Hub" scheme="https://feng.lu/tags/Azure-IoT-Hub/"/>
    
    <category term="Azure IoT Edge" scheme="https://feng.lu/tags/Azure-IoT-Edge/"/>
    
    <category term="Car" scheme="https://feng.lu/tags/Car/"/>
    
    <category term="GPS" scheme="https://feng.lu/tags/GPS/"/>
    
    <category term="OBD2" scheme="https://feng.lu/tags/OBD2/"/>
    
  </entry>
  
  <entry>
    <title>How to measure your Hamster&#39;s running with wireless IoT</title>
    <link href="https://feng.lu/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/"/>
    <id>https://feng.lu/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/</id>
    <published>2020-08-05T17:30:43.000Z</published>
    <updated>2025-03-28T09:05:16.741Z</updated>
    
    <content type="html"><![CDATA[<p>We recently welcomed our new family member Qiuqiu (球球) (a girl <a href="https://en.wikipedia.org/wiki/Golden_hamster">Syrian&#x2F;Golden hamster)</a> home. She seems to enjoy the new environment  fairly well, but she is a quiet girl - does not show much activities during the day time.</p><p>Of course we understand hamsters are nocturnal animals, which means they are sleeping in day time and become more active at night. But I started wondering how she was doing during the nights, especially how much she ran on the hamster wheel. </p><p>Let’s do something about it.</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/Qiuqiu.jpg" class="" title="This is Qiuqiu with her wheel"><p>Picture: Qiuqiu with her wheel</p><span id="more"></span><h1 id="1-Hardware"><a href="#1-Hardware" class="headerlink" title="1. Hardware"></a>1. Hardware</h1><p>There are many possible ways to track the hamster wheel. </p><ol><li><strong>Wired solution, attach wire and switch to the wheel</strong><br>It should work pretty straight forward, but I am not a fan of having wires going through the cage for connecting to the computer. Also Qiuqiu will definitely chew on the wires. </li><li><strong>Wireless solution, with computer vision</strong><br>This can be a pretty cool idea: Draw a mark (e.g. a red X) on the wheel, then place a camera (ie. <a href="https://aws.amazon.com/deeplens/">AWS DeepLens</a>) to run some computer vision tasks, for counting the wheel cycle.<br>I like this idea because it requires minimal work on the wheel and no dangerous for the hamster at all. But there also are some challenges such as how to ensure the image quality if there is no light in the room, or the wheel is running too fast to get a stable high quality image.</li><li><strong>Wireless solution, with wireless sensor</strong><br>This is what I did - need to attach a sensor on the wheel, but the sensor is so small that can be well protected in a shell. I decided to use zigbee protocol as I already have a smart home system that is well integrated.</li></ol><h2 id="1-1-Needed-hardware"><a href="#1-1-Needed-hardware" class="headerlink" title="1.1 Needed hardware"></a>1.1 Needed hardware</h2><ol><li>Sensor: <a href="https://www.aqara.com/us/door_and_window_sensor.html">Aqara Door and Window Sensor</a></li><li>Zigbee gateway: <a href="https://www.phoscon.de/en/conbee2">Conbee II</a></li><li>PC&#x2F;Laptop&#x2F;Raspberry Pi</li></ol><h2 id="1-2-Installation"><a href="#1-2-Installation" class="headerlink" title="1.2 Installation"></a>1.2 Installation</h2><h3 id="1-2-1-Place-the-sensor"><a href="#1-2-1-Place-the-sensor" class="headerlink" title="1.2.1 Place the sensor"></a>1.2.1 Place the sensor</h3><p>Carefully place the sensor on the wheel and the body, make sure when wheel spins, the magnet on the wheel has a small but close enough gap with the sensor body. Used lego part for some adjustments.   </p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/installing_sensor.jpg" class="" title="Installing sensor"><h3 id="1-2-2-Test-with-realtime-sensor-reading"><a href="#1-2-2-Test-with-realtime-sensor-reading" class="headerlink" title="1.2.2 Test with realtime sensor reading"></a>1.2.2 Test with realtime sensor reading</h3><p>Before we continue, I would like to test in action, to make sure the gap is OK. It is possible monitor realtime reading of the sensor, by using the Conbee API.<br>I wrote a simple web app (<a href="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/hamsterwheel_realtime.html.txt">source code</a>) with javascript and WebSocket, to visualize the realtime reading. The WebSocket API is provided by the Conbee application, see the document <a href="https://dresden-elektronik.github.io/deconz-rest-doc/websocket/">here</a>.</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/realtime_reading1.gif" class=""><p>Under the hood:</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/realtime_reading2.gif" class=""><h3 id="1-2-3-Mount-the-protective-shell"><a href="#1-2-3-Mount-the-protective-shell" class="headerlink" title="1.2.3 Mount the protective shell"></a>1.2.3 Mount the protective shell</h3><p>I made a protective shell from a spare plastic box, and mounted on the wheel. Therefore Qiuqiu cannot chew on the sensor. I even made a small hole on the shell to easily use a stick for pressing the sensor reset button, without remove the whole thing.</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/mount_shell.jpg" class="" title="Mount the shell"><h1 id="2-Software"><a href="#2-Software" class="headerlink" title="2. Software"></a>2. Software</h1><h2 id="2-1-Manual-data-export"><a href="#2-1-Manual-data-export" class="headerlink" title="2.1 Manual data export"></a>2.1 Manual data export</h2><p>The BeeCon 2 is a USB-based zigbee gateway that can be attached to a PC or raspberry pi. It talks to the zigbee mesh network and receives signals from sensors. For example, the sensor on the wheel send the following json payload, one for “close” event (magnet and sensor are closed) and another one for “open” event (magnet and sensor are parted). Logically one open-close event pair indicates a finished cycle:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;e&quot;</span><span class="punctuation">:</span> <span class="string">&quot;changed&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;3&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;r&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sensors&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;state&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;lastupdated&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2020-08-05T17:32:37.102&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;open&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;t&quot;</span><span class="punctuation">:</span> <span class="string">&quot;event&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;uniqueid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;00:15:8d:00:04:5c:d8:d3-01-0006&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span> </span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;e&quot;</span><span class="punctuation">:</span> <span class="string">&quot;changed&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;3&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;r&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sensors&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;state&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;lastupdated&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2020-08-05T17:32:37.227&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;open&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;t&quot;</span><span class="punctuation">:</span> <span class="string">&quot;event&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;uniqueid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;00:15:8d:00:04:5c:d8:d3-01-0006&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>By connecting Conbee gateway with <a href="https://www.home-assistant.io/">Home Assistant</a> via <a href="https://www.home-assistant.io/integrations/deconz/">deCONZ integration</a>, it is fairly easy to export the data as a CSV file. (I plan to build a data pipeline with time series database in the later stage, but for now let’s stay with manual data export.)</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/exported_csv.png" class="" title="Exported CSV"><pre><code>Picture: exported csv, with 4 columns</code></pre><h2 id="2-2-Data-analytics"><a href="#2-2-Data-analytics" class="headerlink" title="2.2 Data analytics"></a>2.2 Data analytics</h2><h3 id="2-2-1-Data-loading-and-transformation"><a href="#2-2-1-Data-loading-and-transformation" class="headerlink" title="2.2.1 Data loading and transformation"></a>2.2.1 Data loading and transformation</h3><p>Now it is time for having some python&#x2F;jupyter notebook fun. Here we are going to use <a href="https://www.kaggle.com/">https://www.kaggle.com/</a>. You can read more comparison of online jupyter notebook hosting at <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">here</a>.</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/Data%20load%20and%20transformation.png" class=""><p>The above code snippet does:</p><ol><li>Load CSV file into pandas DataFrame, with needed 2 columns <em>‘last_changed’ and ‘state’</em></li><li>During loading, parse datetime and also set <em>last_changed</em> as index</li><li>Convert fixed string value “on”&#x2F;“off” in <em>‘state’</em> to digital 0&#x2F;1 in <em>‘finshedOneRound’</em> that can be used for plot</li></ol><h3 id="2-2-2-Check-the-raw-data-and-noises"><a href="#2-2-2-Check-the-raw-data-and-noises" class="headerlink" title="2.2.2 Check the raw data and noises"></a>2.2.2 Check the raw data and noises</h3><p>Let’s take a look at the raw data. The first thing I noticed is the “noise” of each cycle. As the door-window close sensor is not designed for tracking a spin, whenever a cycle finished, instead of report simple 2 events: on and off, it actually generates a sequence of events: <strong>on-off-on-off-on-off</strong>. This is a “noise” that we need to take care of.  </p><p>it is worth noting that not all cycles follow the same pattern. For example, the 3rd red circle on the screenshot shows an exception: it only has one “on-off” event pair. </p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/Raw%20data%20visualization.png" class="" title="Raw data visualization"><h3 id="2-3-Noise-reduction-by-rolling-window-calculations"><a href="#2-3-Noise-reduction-by-rolling-window-calculations" class="headerlink" title="2.3 Noise reduction by rolling window calculations"></a>2.3 Noise reduction by rolling window calculations</h3><p>We need a way to “group” the multiple events (“on-off-on-off-on-off”) into one event that indicates a cycle, but we cannot group by a fixed pattern as there are exceptions (as we mentioned above). </p><p>After some quick research and testing, without diving into hard-core data science part, I found the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html">rolling window calculation</a> can be a solution for our case.</p><p>Lets set the rolling windows to 150 ms - it is “magic number” that  works good with the raw data. It purely depends on how fast the hamster runs. </p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/rolling_window.png" class=""><p>Lets visualize the rolling calculation results.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"></span><br><span class="line">fig = go.Figure()</span><br><span class="line"></span><br><span class="line">fig.add_trace(go.Scatter(x=df.index, y=df[<span class="string">&#x27;finshedOneRound&#x27;</span>], name=<span class="string">&#x27;raw&#x27;</span>))</span><br><span class="line">fig.add_trace(go.Scatter(x=df.index, y=df[<span class="string">&#x27;finshedOneRound_rolled&#x27;</span>], mode=<span class="string">&#x27;lines+markers&#x27;</span>, name=<span class="string">&#x27;rolling&#x27;</span>))</span><br><span class="line"></span><br><span class="line">fig.update_xaxes(rangeslider_visible=<span class="literal">True</span>)</span><br><span class="line">fig.update_yaxes(tick0=<span class="number">0</span>, dtick=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><p>Now you can see that the result of rolling calculation does generate unique markers for each cycle (the green circles), and it works for different patterns in the raw data!</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/rolling_window_visualization.png" class=""><p>Extract the markers (where rolling result &#x3D;&#x3D; 1) into a new dataframe df_cycle_log for the next step.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_cycle_log = df.loc[df[<span class="string">&quot;finshedOneRound_rolled&quot;</span>] == <span class="number">1</span>]</span><br></pre></td></tr></table></figure><h3 id="2-4-Calculation-and-visualization-for-the-final-result"><a href="#2-4-Calculation-and-visualization-for-the-final-result" class="headerlink" title="2.4 Calculation and visualization for the final result"></a>2.4 Calculation and visualization for the final result</h3><p>I would like to know:</p><ul><li>When did Qiuqiu run?</li><li>How far did she run?</li><li>What was the speed?</li><li>What kind of running pattern she has? (sprint or marathon?)</li></ul><p>Lets do some match and populate the results:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_distance_by_wheel_cycle_count</span>(<span class="params">cycle_count</span>):</span><br><span class="line">    diameter = <span class="number">0.2</span> <span class="comment">#the wheel diameter is 20cm</span></span><br><span class="line">    <span class="keyword">return</span> cycle_count * diameter * math.pi</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_speed_in_KMh</span>(<span class="params">traveled_range_in_m, run_time_in_sec</span>):</span><br><span class="line">    <span class="keyword">return</span> traveled_range_in_m / run_time_in_sec * <span class="number">3.6</span> <span class="comment">#(1m/s = 3.6 km/h)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_speed_by_cycle_count</span>(<span class="params">cycle_count, run_time_in_sec</span>):</span><br><span class="line">    distance = get_distance_by_wheel_cycle_count(cycle_count) </span><br><span class="line">    <span class="keyword">return</span> get_speed_in_KMh(distance, run_time_in_sec)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Aggreate the cycle counts every 30sec, popluate the data</span></span><br><span class="line">run_time_segment = <span class="string">&quot;30s&quot;</span></span><br><span class="line"></span><br><span class="line">df_result = pd.DataFrame()</span><br><span class="line">df_result[<span class="string">&quot;cycle_count&quot;</span>] = df_cycle_log[<span class="string">&quot;finshedOneRound_rolled&quot;</span>].resample(run_time_segment).count()</span><br><span class="line">df_result[<span class="string">&quot;distance&quot;</span>] = df_result[<span class="string">&quot;cycle_count&quot;</span>].apply(get_distance_by_wheel_cycle_count)</span><br><span class="line">df_result[<span class="string">&quot;speed_km&quot;</span>] = df_result[<span class="string">&quot;cycle_count&quot;</span>].apply(<span class="keyword">lambda</span> count: get_speed_by_cycle_count(count, <span class="number">30</span>))</span><br></pre></td></tr></table></figure><p>Then plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"><span class="comment"># Create figure with secondary y-axis</span></span><br><span class="line">fig = make_subplots(specs=[[&#123;<span class="string">&quot;secondary_y&quot;</span>: <span class="literal">True</span>&#125;]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#fig.add_trace(go.Scatter(x=df_result.index, y=df_result[&#x27;cycle_count&#x27;], name=&quot;wheel count&quot;))</span></span><br><span class="line">fig.add_trace(go.Scatter(x=df_result.index, y=df_result[<span class="string">&#x27;speed_km&#x27;</span>], name=<span class="string">&quot;speed(km/h)&quot;</span>), secondary_y=<span class="literal">False</span>)</span><br><span class="line">fig.add_trace(go.Scatter(x=df_result.index, y=df_result[<span class="string">&quot;distance&quot;</span>].cumsum()/<span class="number">1000</span>, name=<span class="string">&quot;distance(km)&quot;</span>), secondary_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">fig.update_xaxes(rangeslider_visible=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/final_chart.png" class=""><p>Conclusion from the result:</p><ul><li><strong>When did Qiuqiu run?</strong><br>She mainly ran for about 4 hours, between 21:30 and 01:30 UTC time (or 23:30 and 03:30 Oslo time).</li><li><strong>How far did she run?</strong><br>During these 4 hours, she ran about 7.74 KM (12315 cycles). </li><li><strong>What was the speed?</strong><br>Average speed was about 3KM&#x2F;h, with a peak 3.7 KM&#x2F;h.</li><li><strong>What kind of running pattern she had? (sprint or marathon?)</strong><br>She typically ran 5 minutes sprints, and took 2 min small breaks between them.</li></ul><p>According to the internet, Qiuqiu is not the fastest runner (<a href="https://firsthamster.com/how-much-how-fast-hamsters-run/">a hamster can run up to 5-9 KM&#x2F;h</a>), and also ran slightly less than <a href="https://en.wikipedia.org/wiki/Hamster_wheel">average range 9 KM</a> in that evening. </p><p>Of course the speed&#x2F;range can vary from hamster to hamster, and this is data for one evening. The next step is to build a fully automated data pipeline with time series database, create some Grafana dashboards with daily&#x2F;weekly baseline for long term tracking. </p><p>Thanks for the reading.</p><img src="/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/qiuqiu_running.gif" class="">]]></content>
    
    
    <summary type="html">&lt;p&gt;We recently welcomed our new family member Qiuqiu (球球) (a girl &lt;a href=&quot;https://en.wikipedia.org/wiki/Golden_hamster&quot;&gt;Syrian&amp;#x2F;Golden hamster)&lt;/a&gt; home. She seems to enjoy the new environment  fairly well, but she is a quiet girl - does not show much activities during the day time.&lt;/p&gt;
&lt;p&gt;Of course we understand hamsters are nocturnal animals, which means they are sleeping in day time and become more active at night. But I started wondering how she was doing during the nights, especially how much she ran on the hamster wheel. &lt;/p&gt;
&lt;p&gt;Let’s do something about it.&lt;/p&gt;
&lt;img src=&quot;/2020/08/05/How-to-measure-your-Hamster-s-running-with-IoT/Qiuqiu.jpg&quot; class=&quot;&quot; title=&quot;This is Qiuqiu with her wheel&quot;&gt;
&lt;p&gt;Picture: Qiuqiu with her wheel&lt;/p&gt;</summary>
    
    
    
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="Data Analytics" scheme="https://feng.lu/tags/Data-Analytics/"/>
    
    <category term="Hamster" scheme="https://feng.lu/tags/Hamster/"/>
    
    <category term="Home Assistant" scheme="https://feng.lu/tags/Home-Assistant/"/>
    
    <category term="Python" scheme="https://feng.lu/tags/Python/"/>
    
    <category term="Jupyter Notebook" scheme="https://feng.lu/tags/Jupyter-Notebook/"/>
    
    <category term="Zigbee" scheme="https://feng.lu/tags/Zigbee/"/>
    
  </entry>
  
  <entry>
    <title>Encoding issue when calling API via powershell</title>
    <link href="https://feng.lu/2020/06/20/Encoding-issue-when-calling-API-via-powershell/"/>
    <id>https://feng.lu/2020/06/20/Encoding-issue-when-calling-API-via-powershell/</id>
    <published>2020-06-20T11:40:00.000Z</published>
    <updated>2025-03-28T09:05:16.570Z</updated>
    
    <content type="html"><![CDATA[<p>Recently we need to fetch a big dataset from an API via powershell, then import to Azure Data Explorer (ADX).</p><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Used Measure-Command for measuring performance</span></span><br><span class="line">Measure-Command &#123;curl <span class="string">&#x27;THE_API_END_POINT&#x27;</span> | <span class="keyword">select</span> -<span class="built_in">expand</span> Content &gt; data.json&#125;</span><br></pre></td></tr></table></figure><p>The data.json file looks perfectly fine, but during import to ADX, it reported error “invalid json format”.</p><h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><ol><li><p>Using online validation tool such as <a href="https://jsonlint.com/">https://jsonlint.com/</a>, copy &amp; paste the content from data.json. The json objects are valid.</p></li><li><p>Using local tool <a href="https://www.npmjs.com/package/jsonlint">jsonlint</a>, reports error. It shows the data.json file has encoding issue.</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\lufeng\Desktop&gt; jsonlint .\data.json</span><br><span class="line">Error: Parse error on line 1:</span><br><span class="line">��[ &#123; &quot; _ i d &quot; : &#123;</span><br><span class="line">^</span><br><span class="line">Expecting &#x27;STRING&#x27;, &#x27;NUMBER&#x27;, &#x27;NULL&#x27;, &#x27;TRUE&#x27;, &#x27;FALSE&#x27;, &#x27;&#123;&#x27;, &#x27;[&#x27;, got &#x27;undefined&#x27;</span><br><span class="line">    at Object.parseError (C:\Users\lufeng\AppData\Roaming\npm\node_modules\jsonlint\lib\jsonlint.js:55:11)  </span><br><span class="line">    at Object.parse (C:\Users\lufeng\AppData\Roaming\npm\node_modules\jsonlint\lib\jsonlint.js:132:22)      </span><br><span class="line">    at parse (C:\Users\lufeng\AppData\Roaming\npm\node_modules\jsonlint\lib\cli.js:82:14)</span><br><span class="line">    at main (C:\Users\lufeng\AppData\Roaming\npm\node_modules\jsonlint\lib\cli.js:135:14)</span><br><span class="line">    at Object.&lt;anonymous&gt; (C:\Users\lufeng\AppData\Roaming\npm\node_modules\jsonlint\lib\cli.js:179:1)      </span><br><span class="line">    at Module._compile (internal/modules/cjs/loader.js:955:30)</span><br><span class="line">    at Object.Module._extensions..js (internal/modules/cjs/loader.js:991:10)</span><br><span class="line">    at Module.load (internal/modules/cjs/loader.js:811:32)</span><br><span class="line">    at Function.Module._load (internal/modules/cjs/loader.js:723:14)</span><br><span class="line">    at Function.Module.runMain (internal/modules/cjs/loader.js:1043:10)</span><br></pre></td></tr></table></figure><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>Switch to a different powershell command solved the problem</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Invoke-WebRequest -Uri &#x27;THE_API_END_POINT&#x27; -OutFile data.json</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>EOF</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently we need to fetch a big dataset from an API via powershell, then import to Azure Data Explorer (ADX).&lt;/p&gt;
&lt;h2 id=&quot;Problem&quot;&gt;&lt;a hre</summary>
      
    
    
    
    
    <category term="Powershell" scheme="https://feng.lu/tags/Powershell/"/>
    
    <category term="Encoding" scheme="https://feng.lu/tags/Encoding/"/>
    
    <category term="Json" scheme="https://feng.lu/tags/Json/"/>
    
  </entry>
  
  <entry>
    <title>How to Decrypt Native App&#39;s HTTPS Traffic (and Debug for In-app Browser)</title>
    <link href="https://feng.lu/2020/04/03/How-to-Decrypt-Native-Apps-HTTPS-Traffic-and-Debug-for-In-app-Browser/"/>
    <id>https://feng.lu/2020/04/03/How-to-Decrypt-Native-Apps-HTTPS-Traffic-and-Debug-for-In-app-Browser/</id>
    <published>2020-04-03T18:10:18.000Z</published>
    <updated>2025-03-28T09:05:16.570Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Problem-with-in-app-browser-of-LinkedIn-and-Facebook-iOS-apps"><a href="#Problem-with-in-app-browser-of-LinkedIn-and-Facebook-iOS-apps" class="headerlink" title="Problem with in-app browser of LinkedIn and Facebook iOS apps"></a>Problem with in-app browser of LinkedIn and Facebook iOS apps</h2><p>Recently our QA reported an interesting issue regarding the native app and our website: When the webpage was shared on Linkedin iOS App and&#x2F;or Facebook iOS App, the built-in browsers cannot show it correctly but a blank page. </p><img src="/2020/04/03/How-to-Decrypt-Native-Apps-HTTPS-Traffic-and-Debug-for-In-app-Browser/problem.gif" class="" title="Problems on Facebook and Linkedin app"><ul><li>This issue only happens on some of the iOS apps (see the list below). </li><li>Other iOS native apps have no problem.</li><li>Safari and Chrome for iOS have no problem.</li><li>All Android-based native apps have no problem.</li><li>All desktop browsers have no problem.</li></ul><span id="more"></span><p>| Native App         | Platform | Result |<br>|——————–|———-|:——:|<br>| <strong>Linkedin</strong>           | iOS      | <strong>Not OK</strong> |<br>| <strong>Facebook</strong>           | iOS      | <strong>Not OK</strong> |<br>| <strong>Facebook messenger</strong> | iOS      | <strong>Not OK</strong> |<br>| Slack               | iOS      |  OK |<br>| Skype for Business  | iOS      |  OK |<br>| Linkedin           | Android  |  OK |<br>| Facebook           | Android  |  OK |<br>| Facebook messenger | Android  |  OK |<br>| Slack               | Android  |  OK |<br>| Skype for Business  | Android  |  OK |<br>| Safari              | iOS       |  OK |<br>| Chrome for iOS      | iOS       |  OK |<br>| Any desktop browser | Win 10    |  OK |</p><p>So the problem is about iOS in-app browser in <strong>some</strong> native apps. But unfortunately these apps (LinkedIn and Facebook) are too important to ignore, so we will have to fix it.</p><h2 id="Possible-ways-for-troubleshooting"><a href="#Possible-ways-for-troubleshooting" class="headerlink" title="Possible ways for troubleshooting"></a>Possible ways for troubleshooting</h2><p>It is challenging to debug this issue, as it only happens in some of the iOS apps. It can not be reproduced in Safari or other browsers. Possible approaches are:</p><ol><li>Reach out to Linkedin or Facebook, ask for what web viewer they’re using in the app.</li><li>Search on the internet and hope there is a solution for it. </li><li>Let’s become a hacker: Perform a <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack">Man-in-the-middle attack</a> between apps and the internet, and to decrypt and manipulate the web traffic of Apps as troubleshooting.</li></ol><p>The #1 and #2 are long shots, then I will continue with approach #3. The following diagram shows the architecture.</p><img src="/2020/04/03/How-to-Decrypt-Native-Apps-HTTPS-Traffic-and-Debug-for-In-app-Browser/dzonemitmdiagram.png" class="" title="Man-in-the-middle (credit:dzone.com)"><h2 id="Let’s-decrypt-the-web-traffic-of-a-native-app-with-Fiddler"><a href="#Let’s-decrypt-the-web-traffic-of-a-native-app-with-Fiddler" class="headerlink" title="Let’s decrypt the web traffic of a native app with Fiddler"></a>Let’s decrypt the web traffic of a native app with Fiddler</h2><p>There some many ways to place a “Man-in-the-middle” between mobile and internet. For example, the famous fiddler can do it. </p><p>Follow the documentation <a href="https://docs.telerik.com/fiddler/Configure-Fiddler/Tasks/ConfigureForiOS">https://docs.telerik.com/fiddler/Configure-Fiddler/Tasks/ConfigureForiOS</a>. The key steps are:</p><ol><li>Follow the instruction to install and configure fiddler on your PC.</li><li>Ensure the phone and PC are in the sane network (e.g. same wifi), so your phone can access the PC. </li><li>Turn off cellphone data on the phone, to sure traffic from the phone always go through the PC.</li><li>From the phone, access <a href="http://fiddlermachineip:8888/">http://FiddlerMachineIP:8888</a> with safari. (Chrome does not support download and install profile)</li><li>If your phone can not reach the url on PC, ensure the firewall is turned off on your PC.</li><li>Download  FiddlerRoot certificate, then install it via Settings -&gt; Profile Downloaded.</li><li>On iOS 10 and later, after installing the FiddlerRoot certificate, go to Settings -&gt; General -&gt; About -&gt; Certificate Trust Settings and manually enable full trust for the FiddlerRoot root certificate. </li><li>Config proxy on your phone as in the fiddler documentation.</li><li>Done, you should be able to see HTTP and HTTPS traffics from the apps now.</li></ol><h2 id="The-blank-page-issue-is-caused-by-incorrect-Content-Security-Policy"><a href="#The-blank-page-issue-is-caused-by-incorrect-Content-Security-Policy" class="headerlink" title="The blank page issue is caused by incorrect Content-Security-Policy"></a>The blank page issue is caused by incorrect Content-Security-Policy</h2><p>Now I have started comparing the HTTPS response for the same URL but from different Apps, and quickly narrowed down the cause to the different values in response header <strong>The Content-Security-Policy (CSP).</strong></p><p>Content-Security-Policy in the App that <strong>have</strong> the problem</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Added line break for better readability</span></span><br><span class="line">Content-Security-Policy: script-src az416426.vo.msecnd.net</span><br><span class="line">veracitycdn.azureedge.net <span class="string">&#x27;unsafe-inline&#x27;</span> https://tagmanager.google.com</span><br><span class="line">https://www.googletagmanager.com www.google-analytics.com</span><br><span class="line">sjs.bizographics.com/insight.min.js https://px.ads.linkedin.com/</span><br><span class="line">https://*.hotjar.com https://*.hotjar.io; connect-src</span><br><span class="line">dc.services.visualstudio.com https://*.hotjar.com:* https://*.hotjar.io;</span><br><span class="line">frame-src https://*.hotjar.com https://*.hotjar.io</span><br><span class="line">https://www.googletagmanager.com/ns.html; img-src www.google-analytics.com</span><br><span class="line">stats.g.doubleclick.net ssl.gstatic.com www.gstatic.com</span><br><span class="line">https://px.ads.linkedin.com/ www.google.no www.google.com px.ads.linkedin.com</span><br><span class="line">www.linkedin.com; font-src data: fonts.gstatic.com; style-src</span><br><span class="line">tagmanager.google.com fonts.googleapis.com</span><br><span class="line"><span class="string">&#x27;sha256-SvLgADqEePEV9RNxBrRQXSBJafFHcVNG7cPzHz6h9eA=&#x27;</span></span><br></pre></td></tr></table></figure><p>Content-Security-Policy in the Apps that <strong>do NOT have</strong> the problem</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Added line break for better readability</span></span><br><span class="line">Content-Security-Policy: default-src <span class="string">&#x27;self&#x27;</span> veracitystatic.azureedge.net</span><br><span class="line">veracitycdn.azureedge.net veracity-cdn.azureedge.net</span><br><span class="line">veracity-static.azureedge.net veracity.azureedge.net; style-src <span class="string">&#x27;self&#x27;</span></span><br><span class="line"><span class="string">&#x27;sha256-UTjtaAWWTyzFjRKbltk24jHijlTbP20C1GUYaWPqg7E=&#x27;</span> tagmanager.google.com</span><br><span class="line">fonts.googleapis.com <span class="string">&#x27;sha256-SvLgADqEePEV9RNxBrRQXSBJafFHcVNG7cPzHz6h9eA=&#x27;</span>;</span><br><span class="line">img-src <span class="string">&#x27;self&#x27;</span> data: veracityprod.blob.core.windows.net</span><br><span class="line">veracitycdn.azureedge.net veracitystatic.azureedge.net</span><br><span class="line">veracity-cdn.azureedge.net veracity-static.azureedge.net</span><br><span class="line">veracitytest.azureedge.net veracity.azureedge.net brandcentral.dnvgl.com</span><br><span class="line">devtestdevprofile.blob.core.windows.net testdevprofile.blob.core.windows.net</span><br><span class="line">stagdevprofile.blob.core.windows.net cdn.sanity.io</span><br><span class="line">devprofile.blob.core.windows.net www.google-analytics.com</span><br><span class="line">stats.g.doubleclick.net ssl.gstatic.com www.gstatic.com</span><br><span class="line">https://px.ads.linkedin.com/ www.google.no www.google.com px.ads.linkedin.com</span><br><span class="line">www.linkedin.com; script-src <span class="string">&#x27;self&#x27;</span> veracitycdn.azureedge.net</span><br><span class="line">veracity.azureedge.net https://localhost:3010 az416426.vo.msecnd.net</span><br><span class="line"><span class="string">&#x27;unsafe-inline&#x27;</span> https://tagmanager.google.com https://www.googletagmanager.com</span><br><span class="line">www.google-analytics.com sjs.bizographics.com/insight.min.js</span><br><span class="line">https://px.ads.linkedin.com/ https://*.hotjar.com https://*.hotjar.io;</span><br><span class="line">media-src <span class="string">&#x27;self&#x27;</span> veracityprod.blob.core.windows.net</span><br><span class="line">veracitystatic.azureedge.net veracitycdn.azureedge.net</span><br><span class="line">veracity-cdn.azureedge.net veracity-static.azureedge.net veracity.azureedge.net</span><br><span class="line">cdn.sanity.io brandcentral.dnvgl.com; connect-src <span class="string">&#x27;self&#x27;</span></span><br><span class="line">veracitystatic.azureedge.net veracitycdn.azureedge.net</span><br><span class="line">veracity-cdn.azureedge.net veracity-static.azureedge.net veracity.azureedge.net</span><br><span class="line">cdn.sanity.io wss://localhost:3011 dc.services.visualstudio.com</span><br><span class="line">https://*.hotjar.com:* https://*.hotjar.io; font-src veracitycdn.azureedge.net</span><br><span class="line">data: fonts.gstatic.com; report-uri</span><br><span class="line">https://veracitycommon.report-uri.com/r/d/csp/enforce; report-to</span><br><span class="line">https://veracitycommon.report-uri.com/a/d/g; frame-src https://*.hotjar.com</span><br><span class="line">https://*.hotjar.io https://www.googletagmanager.com/ns.html</span><br></pre></td></tr></table></figure><p>It is pretty clear that due to the incorrect (much shorter) value of Content-Security-Policy caused the problem.</p><h2 id="Some-User-Agent-caused-incorrect-Content-Security-Policy-CSP"><a href="#Some-User-Agent-caused-incorrect-Content-Security-Policy-CSP" class="headerlink" title="Some User-Agent caused incorrect Content-Security-Policy (CSP)"></a>Some User-Agent caused incorrect Content-Security-Policy (CSP)</h2><p>Now we need to check what caused the different CSP values. By comparing the requests that these apps were sending in Fiddler, I have quickly identified the request header “User-Agent” is the key.</p><p>User-Agent values from Apps that cause <strong>wrong</strong> CSP</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Linkedin</span></span><br><span class="line">Mozilla/5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 [LinkedInApp]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Facebook</span></span><br><span class="line">Mozilla/5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 [FBAN/FBIOS;FBDV/iPhone11,2;FBMD/iPhone;FBSN/iOS;FBSV/13.3.1;FBSS/3;FBID/phone;FBLC/en_US;FBOP/5;FBCR/Telenor]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Facebook Messenger</span></span><br><span class="line">Mozilla/5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 LightSpeed [FBAN/MessengerLiteForiOS;FBAV/256.0.1.26.113;FBBV/203261359;FBDV/iPhone11,2;FBMD/iPhone;FBSN/iOS;FBSV/13.3.1;FBSS/3;FBCR/;FBID/phone;FBLC/en_NO;FBOP/0]</span><br></pre></td></tr></table></figure><p>User-Agent values from Apps that cause <strong>correct</strong> CSP</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Slack</span></span><br><span class="line">Mozilla/5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.5 Mobile/15E148 Safari/604.1</span><br><span class="line"></span><br><span class="line"><span class="comment">#Skype for Business</span></span><br><span class="line">Mozilla/5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.5 Mobile/15E148 Safari/604.1</span><br></pre></td></tr></table></figure><h2 id="Manipulate-web-traffic-of-the-apps-to-simulate-different-behaviors"><a href="#Manipulate-web-traffic-of-the-apps-to-simulate-different-behaviors" class="headerlink" title="Manipulate web traffic of the apps to simulate different behaviors"></a>Manipulate web traffic of the apps to simulate different behaviors</h2><p>Although we cannot change the logic of these apps, we can still easily manipulate the request or response, to simulate the different behaviors. </p><p>Head to Fiddler, go to “Filters” table, then you can </p><ol><li>Setup the filter to target the manipulation to a specific page</li><li>Manipulate requests, such as add&#x2F;update&#x2F;remove request headers and body</li><li>Manipulate responses, such as headers and body</li></ol><img src="/2020/04/03/How-to-Decrypt-Native-Apps-HTTPS-Traffic-and-Debug-for-In-app-Browser/fiddler.png" class="" title="Manipulate request and response in fiddler"><p>Some findings are:</p><ol><li>“[…]” part in the user-agent does NOT cause the problem, even though they are quite long strings</li><li>Missing the “Version&#x2F;13.0.5” part is causing the problem</li></ol><p>| Original LinkedIn User-Agent (with issue) | Updated LinkedIn User-Agent (without issue) |<br>|———————————————————————————————————————————|————————————————————————————————————————————————-|<br>| Mozilla&#x2F;5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit&#x2F;605.1.15 (KHTML, like Gecko) Mobile&#x2F;15E148  [LinkedInApp] | Mozilla&#x2F;5.0 (iPhone; CPU iPhone OS 13_3_1 like Mac OS X) AppleWebKit&#x2F;605.1.15 (KHTML, like Gecko) Mobile&#x2F;15E148 <strong>Version&#x2F;13.0.5</strong> [LinkedInApp] |</p><h2 id="Root-cause-and-solution"><a href="#Root-cause-and-solution" class="headerlink" title="Root cause and solution"></a>Root cause and solution</h2><p>Generally, the web site should return the same CSP for most of the cases. So this is an issue that we should fix on the website. </p><p>The investigation led us to the opensource library <a href="https://github.com/helmetjs">Helmet</a> where we reported a bug <a href="https://github.com/helmetjs/csp/issues/105">https://github.com/helmetjs/csp/issues/105</a>. </p><p>Now we have fixed this issue locally and once Helmet merged the PR, we are ready to go.</p><h2 id="Take-away"><a href="#Take-away" class="headerlink" title="Take away"></a>Take away</h2><ol><li>It is easy to perform a “Man-in-the-middle” like attack, but ONLY IF you have control on the device (e.g. you can install the root certificate). </li><li>Once you have a machine between mobile and internet, you can not only monitor the web traffic, but also manipulate both request and response. So if you are interested in how an app is talking to its backend, you have tools to do that.</li><li>Advice to normal app user: be careful who have access to your device and try to stay away from the public wifi.</li><li>Advice to app developers: always remind yourself that technically it is possible for a hacker to “open your app” and look at which API endpoint your app is talking to, and manipulate the requests. Your app’s private API endpoint will be exposed, take all necessray security measurement on it!</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>   Establish the proxy <a href="https://docs.telerik.com/fiddler/Configure-Fiddler/Tasks/ConfigureForiOS">https://docs.telerik.com/fiddler/Configure-Fiddler/Tasks/ConfigureForiOS</a></li><li>   Manipulate the request header <a href="https://hackernoon.com/manipulating-web-application-http-traffic-with-fiddler-140d789d0a1c">https://hackernoon.com/manipulating-web-application-http-traffic-with-fiddler-140d789d0a1c</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Problem-with-in-app-browser-of-LinkedIn-and-Facebook-iOS-apps&quot;&gt;&lt;a href=&quot;#Problem-with-in-app-browser-of-LinkedIn-and-Facebook-iOS-apps&quot; class=&quot;headerlink&quot; title=&quot;Problem with in-app browser of LinkedIn and Facebook iOS apps&quot;&gt;&lt;/a&gt;Problem with in-app browser of LinkedIn and Facebook iOS apps&lt;/h2&gt;&lt;p&gt;Recently our QA reported an interesting issue regarding the native app and our website: When the webpage was shared on Linkedin iOS App and&amp;#x2F;or Facebook iOS App, the built-in browsers cannot show it correctly but a blank page. &lt;/p&gt;
&lt;img src=&quot;/2020/04/03/How-to-Decrypt-Native-Apps-HTTPS-Traffic-and-Debug-for-In-app-Browser/problem.gif&quot; class=&quot;&quot; title=&quot;Problems on Facebook and Linkedin app&quot;&gt;

&lt;ul&gt;
&lt;li&gt;This issue only happens on some of the iOS apps (see the list below). &lt;/li&gt;
&lt;li&gt;Other iOS native apps have no problem.&lt;/li&gt;
&lt;li&gt;Safari and Chrome for iOS have no problem.&lt;/li&gt;
&lt;li&gt;All Android-based native apps have no problem.&lt;/li&gt;
&lt;li&gt;All desktop browsers have no problem.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="Troubleshooting" scheme="https://feng.lu/tags/Troubleshooting/"/>
    
    <category term="Fiddler" scheme="https://feng.lu/tags/Fiddler/"/>
    
    <category term="Native App" scheme="https://feng.lu/tags/Native-App/"/>
    
    <category term="HTTPS" scheme="https://feng.lu/tags/HTTPS/"/>
    
    <category term="Decryption" scheme="https://feng.lu/tags/Decryption/"/>
    
  </entry>
  
  <entry>
    <title>Jump-start Kubernetes and Istio with Docker Desktop on Windows 10</title>
    <link href="https://feng.lu/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/"/>
    <id>https://feng.lu/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/</id>
    <published>2019-10-05T17:57:31.000Z</published>
    <updated>2025-03-28T09:05:16.831Z</updated>
    
    <content type="html"><![CDATA[<p>Here we will setup a single-node Kubernetes cluster on a windows 10 PC (In my case it is a surface 5 with 16GB RAM). If you are new to docker, feel free to check out <a href="/2017/03/31/Jump-start-ASP-Net-Core-with-Docker/">Jump-start with docker</a>.<br>We are going to setup:</p><ul><li>A single-node Kubernetes cluster</li><li><a href="https://github.com/kubernetes/dashboard">Kubernetes dashboard</a></li><li>Helm</li><li>Isito (service mesh, including Kiali)</li><li>Deployment samples</li></ul><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Title%20picture.png" class=""><span id="more"></span><h1 id="1-Enable-Kubernetes-in-Docker-Desktop"><a href="#1-Enable-Kubernetes-in-Docker-Desktop" class="headerlink" title="1. Enable Kubernetes in Docker Desktop"></a>1. Enable Kubernetes in Docker Desktop</h1><p><a href="https://docs.docker.com/docker-for-windows/">Docker Desktop (or Docker for Windows)</a> is a nice environment for developers on Windows. The community stable version of Docker Desktop is good enough for this jump-start, just make sure the version you installed include Kubernetes 1.14.x or higher. (I am using Docker Desktop Community 2.1.0.3).</p><p>Once installed, you can enable Kubernetes in Setting (see detailed info at <a href="https://docs.docker.com/docker-for-windows/#kubernetes">here</a>)</p><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Enable%20Kubernetes%20in%20setting.png" class="" title="Enable Kubernetes in setting"><p>Then, you can verify it by running “<strong>kubectl version</strong>“ in powershell (or Command window)</p><p>In my case, I got error while connecting to [::1]:8080:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; kubectl version</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Client Version: version.Info&#123;Major:<span class="string">&quot;1&quot;</span>, Minor:<span class="string">&quot;14&quot;</span>, GitVersion:<span class="string">&quot;v1.14.3&quot;</span>, GitCommit:<span class="string">&quot;5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, BuildDate:<span class="string">&quot;2019-06-06T01:44:30Z&quot;</span>, GoVersion:<span class="string">&quot;go1.12.5&quot;</span>, Compiler:<span class="string">&quot;gc&quot;</span>, Platform:<span class="string">&quot;windows/amd64&quot;</span>&#125;</span><br><span class="line">Unable to connect to the server: dial tcp [::1]:8080: connectex: No connection could be made because the target machine actively refused it.</span><br></pre></td></tr></table></figure><p>This is because I am missing an environment variable “<strong>KUBECONFIG</strong>“. Set this variable to your user directory such as “<strong>C:\Users\YOUR__USER_NAME\.kube\config</strong>“. </p><p>After adding this and restart your powershell, it should work.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; Get-Item -Path Env:KUBECONFIG</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Name                           Value</span><br><span class="line">----                           -----</span><br><span class="line">KUBECONFIG                     C:\Users\lufeng\.kube\config</span><br><span class="line"></span><br><span class="line">PS C:\&gt; kubectl version</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Client Version: version.Info&#123;Major:<span class="string">&quot;1&quot;</span>, Minor:<span class="string">&quot;14&quot;</span>, GitVersion:<span class="string">&quot;v1.14.3&quot;</span>, GitCommit:<span class="string">&quot;5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, BuildDate:<span class="string">&quot;2019-06-06T01:44:30Z&quot;</span>, GoVersion:<span class="string">&quot;go1.12.5&quot;</span>, Compiler:<span class="string">&quot;gc&quot;</span>, Platform:<span class="string">&quot;windows/amd64&quot;</span>&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:<span class="string">&quot;1&quot;</span>, Minor:<span class="string">&quot;14&quot;</span>, GitVersion:<span class="string">&quot;v1.14.3&quot;</span>, GitCommit:<span class="string">&quot;5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, BuildDate:<span class="string">&quot;2019-06-06T01:36:19Z&quot;</span>, GoVersion:<span class="string">&quot;go1.12.5&quot;</span>, Compiler:<span class="string">&quot;gc&quot;</span>, Platform:<span class="string">&quot;linux/amd64&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">PS C:\&gt; kubectl get namespaces</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   18h</span><br><span class="line">docker            Active   18h</span><br><span class="line">kube-node-lease   Active   18h</span><br><span class="line">kube-public       Active   18h</span><br><span class="line">kube-system       Active   18h</span><br></pre></td></tr></table></figure><h1 id="2-Installing-Kubernetes-Dashboard"><a href="#2-Installing-Kubernetes-Dashboard" class="headerlink" title="2. Installing Kubernetes Dashboard"></a>2. Installing Kubernetes Dashboard</h1><p>It is always nice to have a GUI for a complicated system such as Kubernetes, so lets install the dashboard <a href="https://github.com/kubernetes/dashboard">https://github.com/kubernetes/dashboard</a>. </p><h2 id="2-1-Dashboard-deployment"><a href="#2-1-Dashboard-deployment" class="headerlink" title="2.1 Dashboard deployment"></a>2.1 Dashboard deployment</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br></pre></td></tr></table></figure><h2 id="2-2-Accessing-the-dashboard"><a href="#2-2-Accessing-the-dashboard" class="headerlink" title="2.2 Accessing the dashboard"></a>2.2 Accessing the dashboard</h2><p>First of all, we need to enable the proxy, so you can access the dashboard from your localhost:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; kubectl proxy</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Starting to serve on 127.0.0.1:8001</span><br></pre></td></tr></table></figure><p>Once the proxy is up and running, visit the dashboard URL: <a href="http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/">http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</a></p><p>Normally you will meet this [login view] (<a href="https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/README.md#login-view">https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/README.md#login-view</a>)</p><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Dashboard%20login.png" class="" title="Dashboard login"><p>You can find more info from the dashboard github about <a href="https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/README.md">Access control</a>, but here we will do it simpler (This is for demo purpose, do not apply the same setup in your production environment).</p><h3 id="2-2-1-Get-token"><a href="#2-2-1-Get-token" class="headerlink" title="2.2.1 Get token"></a>2.2.1 Get token</h3><p>Get the default token name</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; kubectl get secrets</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                  TYPE                                  DATA   AGE</span><br><span class="line">default-token-n92hz   kubernetes.io/service-account-token   3      18h</span><br></pre></td></tr></table></figure><p>Then get the token</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; kubectl describe secrets default-token-n92hz</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Name:         default-token-n92hz</span><br><span class="line">Namespace:    default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: default</span><br><span class="line">              kubernetes.io/service-account.uid: c56ad00e-e5e5-11e9-91a0-00155d3a9005</span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  7 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImt3NlcnZpY2UtYWNjb......CIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjfv4TPDVZoOrLWHZecEw-8XBQ</span><br><span class="line">PS C:\&gt;</span><br></pre></td></tr></table></figure><p>Use the token in the login form, then you are in.</p><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Kubernetes%20Dashboard.png" class="" title="Kubernetes Dashboard Overview"><h1 id="3-Installing-Helm-on-Windows"><a href="#3-Installing-Helm-on-Windows" class="headerlink" title="3. Installing Helm on Windows"></a>3. Installing Helm on Windows</h1><p>Helm is a tool for managing Kubernetes charts. Charts are packages of pre-configured Kubernetes resources. You can read more at <a href="https://helm.sh/">https://helm.sh/</a>.<br>According to the <a href="https://helm.sh/docs/using_helm/#installing-helm">installation guide</a>, we are going to:</p><ol><li>Install <a href="https://scoop.sh/">scoop</a></li><li>Install helm via scoop</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; scoop install helm</span><br></pre></td></tr></table></figure><ol start="3"><li>Ensure configure the environment variable for “<strong>HELM_HOME</strong>“, such as “C:\Users\USERNAME.kube”. It should be an valid directory in your file system.</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; Get-Item -Path Env:HELM_HOME</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Name                           Value</span><br><span class="line">----                           -----</span><br><span class="line">HELM_HOME                      C:\Users\lufeng\.kube</span><br></pre></td></tr></table></figure><ol start="4"><li>Initialize Helm and install Tiller<br>Once you have Helm ready, you can initialize the local CLI and also install Tiller into your Kubernetes cluster in one step:</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Check current kubernetes cluster context</span></span><br><span class="line">PS P:\&gt; kubectl config current-context</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">docker-desktop</span><br><span class="line"></span><br><span class="line"><span class="comment">#Init helm</span></span><br><span class="line">PS C:\&gt; helm init --history-max 200</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line"><span class="variable">$HELM_HOME</span> has been configured at C:\Users\lufeng\.kube.</span><br><span class="line">Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.</span><br><span class="line"></span><br><span class="line"><span class="comment">#Verify the triller is up and running (the last row)</span></span><br><span class="line">PS C:\&gt; kubectl get pods --namespace kube-system</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-fb8b8dccf-b5lq5                  1/1     Running   0          19h</span><br><span class="line">coredns-fb8b8dccf-t5kdf                  1/1     Running   0          19h</span><br><span class="line">etcd-docker-desktop                      1/1     Running   0          19h</span><br><span class="line">kube-apiserver-docker-desktop            1/1     Running   0          19h</span><br><span class="line">kube-controller-manager-docker-desktop   1/1     Running   0          19h</span><br><span class="line">kube-proxy-bj2x4                         1/1     Running   0          19h</span><br><span class="line">kube-scheduler-docker-desktop            1/1     Running   0          19h</span><br><span class="line">kubernetes-dashboard-5f7b999d65-vqdq6    1/1     Running   0          19h</span><br><span class="line">tiller-deploy-5454fb964d-8tp5t           1/1     Running   0          76s</span><br></pre></td></tr></table></figure><h1 id="4-Installing-Istio"><a href="#4-Installing-Istio" class="headerlink" title="4. Installing Istio"></a>4. Installing Istio</h1><p><a href="istio.io">Istio</a> is a microservice-mesh management framework, that provides traffic management, policy enforcement, and telemetry collection.<br>We are going to:</p><ul><li>Install Istio (and addons such as Kiali) via Helm (<a href="https://istio.io/docs/setup/install/helm/">doc</a>)</li><li>Accessing Kiali dashboard (<a href="https://istio.io/docs/tasks/telemetry/kiali/">doc</a>)</li><li>Install bookinfo demo (<a href="https://istio.io/docs/examples/bookinfo/">doc</a>)</li></ul><h2 id="4-1-Install-Istio-via-Helm"><a href="#4-1-Install-Istio-via-Helm" class="headerlink" title="4.1 Install Istio via Helm"></a>4.1 Install Istio via Helm</h2><p>Simply follow the steps in <a href="https://istio.io/docs/setup/install/helm/">https://istio.io/docs/setup/install/helm/</a>, remember to config docker desktop <a href="https://istio.io/docs/setup/platform-setup/docker/">as mentioned</a>. Unzip the downloaded package into “<strong>c:\Istio</strong>“ as we might want to update some files there.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">PS C:\&gt; helm repo add istio.io https://storage.googleapis.com/istio-release/releases/1.3.1/charts/</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line"><span class="string">&quot;istio.io&quot;</span> has been added to your repositories</span><br><span class="line"></span><br><span class="line"><span class="comment">#Use Helm’s Tiller pod to manage Istio release (option 2), as we installed Tiller in previous step.</span></span><br><span class="line">PS C:\&gt; <span class="built_in">cd</span> istio</span><br><span class="line"></span><br><span class="line"><span class="comment">#1. Make sure you have a service account with the cluster-admin role defined for Tiller. If not already defined, create one using following command</span></span><br><span class="line">PS C:\istio&gt; kubectl apply -f install/kubernetes/helm/helm-service-account.yaml</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">serviceaccount/tiller created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/tiller created</span><br><span class="line"></span><br><span class="line"><span class="comment">#2. Config Tiller on your cluster with the service account:</span></span><br><span class="line">PS C:\istio&gt; helm init --upgrade --service-account tiller</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line"><span class="variable">$HELM_HOME</span> has been configured at C:\Users\lufeng\.kube.</span><br><span class="line">Tiller (the Helm server-side component) has been upgraded to the current version.</span><br><span class="line"></span><br><span class="line"><span class="comment">#3. Install the istio-init chart to bootstrap all the Istio’s CRDs:</span></span><br><span class="line">PS C:\istio&gt; helm install install/kubernetes/helm/istio-init --name istio-init --namespace istio-system</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME:   istio-init</span><br><span class="line">LAST DEPLOYED: Fri Oct  4 11:36:15 2019</span><br><span class="line">NAMESPACE: istio-system</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/ClusterRole</span><br><span class="line">NAME                     AGE</span><br><span class="line">istio-init-istio-system  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ClusterRoleBinding</span><br><span class="line">NAME                                        AGE</span><br><span class="line">istio-init-admin-role-binding-istio-system  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME          DATA  AGE</span><br><span class="line">istio-crd-10  1     0s</span><br><span class="line">istio-crd-11  1     0s</span><br><span class="line">istio-crd-12  1     0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Job</span><br><span class="line">NAME                     COMPLETIONS  DURATION  AGE</span><br><span class="line">istio-init-crd-10-1.3.1  0/1          0s</span><br><span class="line">istio-init-crd-11-1.3.1  0/1          0s  0s</span><br><span class="line">istio-init-crd-12-1.3.1  0/1          0s  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                           READY  STATUS             RESTARTS  AGE</span><br><span class="line">istio-init-crd-11-1.3.1-qz4fh  0/1    ContainerCreating  0         0s</span><br><span class="line">istio-init-crd-12-1.3.1-6rk5w  0/1    ContainerCreating  0         0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ServiceAccount</span><br><span class="line">NAME                        SECRETS  AGE</span><br><span class="line">istio-init-service-account  1        0s</span><br></pre></td></tr></table></figure><p>Then select a <a href="https://istio.io/docs/setup/additional-setup/config-profiles/">configuration profile</a>. We go with “<strong>demo</strong>“ as it include some nice addons such as Kiali. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Installation</span></span><br><span class="line">PS C:\istio&gt; helm install install/kubernetes/helm/istio --name istio --namespace istio-system --values install/kubernetes/helm/istio/values-istio-demo.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment">#Verify</span></span><br><span class="line">PS C:\istio&gt;  kubectl get pods -n istio-system</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">grafana-6fc987bd95-zj4kn                  1/1     Running     0          98s</span><br><span class="line">istio-citadel-55646d8965-wvflc            1/1     Running     0          97s</span><br><span class="line">istio-egressgateway-7bdb7bf7b5-ck4k6      1/1     Running     0          98s</span><br><span class="line">istio-galley-56bf6b7497-c9szw             1/1     Running     0          98s</span><br><span class="line">istio-ingressgateway-64dbd4b954-64gj8     1/1     Running     0          98s</span><br><span class="line">istio-init-crd-10-1.3.1-tvnr4             0/1     Completed   0          4h1m</span><br><span class="line">istio-init-crd-11-1.3.1-qz4fh             0/1     Completed   0          4h1m</span><br><span class="line">istio-init-crd-12-1.3.1-6rk5w             0/1     Completed   0          4h1m</span><br><span class="line">istio-pilot-5d4c86d576-crn2k              2/2     Running     0          97s</span><br><span class="line">istio-policy-759d4988df-c7tnb             2/2     Running     1          97s</span><br><span class="line">istio-sidecar-injector-5d6ff6d758-8tlrx   1/1     Running     0          97s</span><br><span class="line">istio-telemetry-7c88764b9c-245mk          2/2     Running     1          97s</span><br><span class="line">istio-tracing-669fd4b9f8-gmlh9            1/1     Running     0          97s</span><br><span class="line">kiali-94f8cbd99-zwz8z                     1/1     Running     0          98s</span><br><span class="line">prometheus-776fdf7479-jwnvh               1/1     Running     0          97s</span><br></pre></td></tr></table></figure><p>You can also verify these pod via dashboard</p><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Istio%20pods.png" class="" title="Istio pods in dashboard"><h2 id="4-2-Accessing-Kiali-dashboard"><a href="#4-2-Accessing-Kiali-dashboard" class="headerlink" title="4.2 Accessing Kiali dashboard"></a>4.2 Accessing Kiali dashboard</h2><p>As we installed the <strong>Demo</strong> configuration profile of Istio, Kiali was also installed. <a href="https://www.kiali.io/">Kiali</a> is an observability console for Istio with service mesh configuration capabilities. (Read more at <a href="https://istio.io/docs/tasks/telemetry/kiali/">https://istio.io/docs/tasks/telemetry/kiali/</a> also)</p><p>To open Kiali UI, pls run</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PS C:\istio&gt; kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=kiali -o jsonpath=<span class="string">&#x27;&#123;.items[0].metadata.name&#125;&#x27;</span>) 20001:20001</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Forwarding from 127.0.0.1:20001 -&gt; 20001</span><br><span class="line">Forwarding from [::1]:20001 -&gt; 20001</span><br></pre></td></tr></table></figure><p>Then go to <a href="http://localhost:20001/">http://localhost:20001</a> for visting Kiali UI.</p><p>Again, it ask for login. As in this case, Kiali was installed as a part of the <strong>Demo</strong> configuration profile, you can use default user name “<strong>admin</strong>“ and password “<strong>admin</strong>“ to login.</p><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Kiali%20login.png" class="" title="Kiali login form"><h2 id="4-3-Install-bookinfo-demo"><a href="#4-3-Install-bookinfo-demo" class="headerlink" title="4.3 Install bookinfo demo"></a>4.3 Install bookinfo demo</h2><p>Now, lets deploy a demo application composed of four separate microservices. The detailed doc can be found at <a href="https://istio.io/docs/examples/bookinfo/">https://istio.io/docs/examples/bookinfo/</a>. </p><ol><li>Start the application services</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. Set automatic sidecar injection</span></span><br><span class="line">PS C:\istio&gt; kubectl label namespace default istio-injection=enabled</span><br><span class="line"></span><br><span class="line"><span class="comment">#2. Deployment</span></span><br><span class="line">PS C:\istio&gt; kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">service/details created</span><br><span class="line">serviceaccount/bookinfo-details created</span><br><span class="line">deployment.apps/details-v1 created</span><br><span class="line">service/ratings created</span><br><span class="line">serviceaccount/bookinfo-ratings created</span><br><span class="line">deployment.apps/ratings-v1 created</span><br><span class="line">service/reviews created</span><br><span class="line">serviceaccount/bookinfo-reviews created</span><br><span class="line">deployment.apps/reviews-v1 created</span><br><span class="line">deployment.apps/reviews-v2 created</span><br><span class="line">deployment.apps/reviews-v3 created</span><br><span class="line">service/productpage created</span><br><span class="line">serviceaccount/bookinfo-productpage created</span><br><span class="line">deployment.apps/productpage-v1 created</span><br><span class="line"></span><br><span class="line"><span class="comment">#3. Verify services and pods</span></span><br><span class="line">PS C:\istio&gt; kubectl get services</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">details       ClusterIP   10.110.165.24   &lt;none&gt;        9080/TCP   33s</span><br><span class="line">kubernetes    ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    6h50m</span><br><span class="line">productpage   ClusterIP   10.97.123.119   &lt;none&gt;        9080/TCP   32s</span><br><span class="line">ratings       ClusterIP   10.111.216.40   &lt;none&gt;        9080/TCP   33s</span><br><span class="line">reviews       ClusterIP   10.109.244.28   &lt;none&gt;        9080/TCP   33s</span><br><span class="line"></span><br><span class="line">PS C:\istio&gt; kubectl get pods</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">details-v1-c5b5f496d-sgr6w       2/2     Running   0          85s</span><br><span class="line">productpage-v1-c7765c886-6cpr9   2/2     Running   0          83s</span><br><span class="line">ratings-v1-f745cf57b-87m7q       2/2     Running   0          85s</span><br><span class="line">reviews-v1-75b979578c-vmzn2      2/2     Running   0          84s</span><br><span class="line">reviews-v2-597bf96c8f-plml7      2/2     Running   0          85s</span><br><span class="line">reviews-v3-54c6c64795-x67ss      2/2     Running   0          84s</span><br><span class="line"></span><br><span class="line"><span class="comment">#4. Verify by calling the application</span></span><br><span class="line">PS C:\istio&gt; kubectl <span class="built_in">exec</span> -it $(kubectl get pod -l app=ratings -o jsonpath=<span class="string">&#x27;&#123;.items[0].metadata.name&#125;&#x27;</span>) -c ratings -- curl productpage:9080/productpage | select-string -pattern <span class="string">&quot;&lt;title&gt;&quot;</span></span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">    &lt;title&gt;Simple Bookstore App&lt;/title&gt;</span><br></pre></td></tr></table></figure><ol start="2"><li>Establish gateway for the bookinfo app</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. Apply gateway</span></span><br><span class="line">PS C:\istio&gt; kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">gateway.networking.istio.io/bookinfo-gateway created</span><br><span class="line">virtualservice.networking.istio.io/bookinfo created</span><br><span class="line"></span><br><span class="line"><span class="comment">#2. Verify the gateway</span></span><br><span class="line">PS C:\istio&gt; kubectl get gateway</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME               AGE</span><br><span class="line">bookinfo-gateway   38s</span><br></pre></td></tr></table></figure><ol start="3"><li>Confirm the app is accessible from outside the cluster<br>Go to <a href="http://localhost/productpage">http://localhost/productpage</a> to verify you can open the page. You can refresh the page several times for generating telemtries.</li></ol><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Bookinfo%20demo.png" class="" title="Bookinfo demo page"><ol start="4"><li>Kiali Visualization<br>Assuming the 20001 port forwarding is still running, then you can visualize the service relationship in Kiali <a href="http://localhost:20001/">http://localhost:20001/</a></li></ol><img src="/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Kiali%20graph.gif" class="" title="Kiali graph"><h1 id="5-Deployment-examples"><a href="#5-Deployment-examples" class="headerlink" title="5. Deployment examples"></a>5. Deployment examples</h1><p>Let’s deploy a single-container-application (Grafana) to the cluster, which is described at <a href="https://grafana.com/docs/installation/docker/">https://grafana.com/docs/installation/docker/</a></p><p><strong>1. Docker version</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:3000 grafana/grafana</span><br></pre></td></tr></table></figure><p><strong>2. Kubernetes kubectl command version</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Deployment</span></span><br><span class="line">PS C:\&gt; kubectl run grafana-test --generator=run-pod/v1 --image=grafana/grafana --port=3000</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">pod/grafana-test created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Check the name of the grafana pod. Note it is sitting in &quot;default&quot; namespace</span></span><br><span class="line">PS C:\&gt; kubectl -n default get pod</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">details-v1-c5b5f496d-sgr6w            2/2     Running   0          29h</span><br><span class="line">grafana-test                          2/2     Running   0          97s</span><br><span class="line">kubernetes-bootcamp-b94cb9bff-vsprh   2/2     Running   0          3h6m</span><br><span class="line">productpage-v1-c7765c886-6cpr9        2/2     Running   0          29h</span><br><span class="line">ratings-v1-f745cf57b-87m7q            2/2     Running   0          29h</span><br><span class="line">reviews-v1-75b979578c-vmzn2           2/2     Running   0          29h</span><br><span class="line">reviews-v2-597bf96c8f-plml7           2/2     Running   0          29h</span><br><span class="line">reviews-v3-54c6c64795-x67ss           2/2     Running   0          29h</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Enable port forwarding.</span></span><br><span class="line"><span class="comment"># In case you wanna use select as the pod name contains random string, </span></span><br><span class="line"><span class="comment"># Use &quot;kubectl -n default port-forward $(kubectl -n default get pod -l run=grafana-test -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) 3000:3000&quot;</span></span><br><span class="line">PS C:\&gt; kubectl -n default port-forward grafana-test 3000:3000</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">Forwarding from 127.0.0.1:3000 -&gt; 3000</span><br><span class="line">Forwarding from [::1]:3000 -&gt; 3000</span><br></pre></td></tr></table></figure><p><strong>3. Kubernetes YAML deployment version</strong><br>It is recommended to use YAML file for defining a deployment. See doc at <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">https://kubernetes.io/docs/concepts/workloads/controllers/deployment/</a><br>Create a deployment grafana-deployment.yaml file as below:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">grafana-yaml-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">grafana-yaml</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">grafana-yaml</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">grafana-yaml</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-yaml</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">grafana/grafana</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure><p>Then apply the yaml file and run</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. Deployment</span></span><br><span class="line">PS C:\&gt; kubectl apply -f .\grafana-deployment.yaml</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">deployment.apps/grafana-yaml-deployment created</span><br><span class="line"></span><br><span class="line"><span class="comment">#2. Verify</span></span><br><span class="line">PS C:\&gt; kubectl get deployments</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                      READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">details-v1                1/1     1            1           29h</span><br><span class="line">grafana-yaml-deployment   1/1     1            1           40s</span><br><span class="line">kubernetes-bootcamp       1/1     1            1           3h27m</span><br><span class="line">productpage-v1            1/1     1            1           29h</span><br><span class="line">ratings-v1                1/1     1            1           29h</span><br><span class="line">reviews-v1                1/1     1            1           29h</span><br><span class="line">reviews-v2                1/1     1            1           29h</span><br><span class="line">reviews-v3                1/1     1            1           29h</span><br><span class="line"></span><br><span class="line"><span class="comment">#3. Enable forward port, by using selector app=grafana-yaml</span></span><br><span class="line">PS C:\&gt; kubectl -n default port-forward $(kubectl -n default get pod -l app=grafana-yaml -o jsonpath=<span class="string">&#x27;&#123;.items[0].metadata.name&#125;&#x27;</span>) 3000:3000</span><br><span class="line"></span><br><span class="line"><span class="comment">#4. Expose the service via nodeport</span></span><br><span class="line">PS C:\&gt; kubectl expose deployment grafana-yaml-deployment --<span class="built_in">type</span>=NodePort --port=3000</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">service/grafana-yaml-deployment exposed</span><br><span class="line"></span><br><span class="line"><span class="comment">#5. Get the external ip and port</span></span><br><span class="line">PS C:\&gt; kubectl get services</span><br><span class="line"><span class="comment">#Output:</span></span><br><span class="line">NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">details                   ClusterIP   10.110.165.24   &lt;none&gt;        9080/TCP         3d8h</span><br><span class="line">grafana-yaml-deployment   NodePort    10.98.52.86     &lt;none&gt;        3000:30857/TCP   9s</span><br><span class="line">kubernetes                ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          3d15h</span><br><span class="line">productpage               ClusterIP   10.97.123.119   &lt;none&gt;        9080/TCP         3d8h</span><br><span class="line">ratings                   ClusterIP   10.111.216.40   &lt;none&gt;        9080/TCP         3d8h</span><br><span class="line">reviews                   ClusterIP   10.109.244.28   &lt;none&gt;        9080/TCP         3d8h</span><br><span class="line"></span><br><span class="line">PS C:\&gt; kubectl describe service grafana-yaml-deployment</span><br><span class="line">Name:                     grafana-yaml-deployment</span><br><span class="line">Namespace:                default</span><br><span class="line">Labels:                   app=grafana-yaml</span><br><span class="line">Annotations:              &lt;none&gt;</span><br><span class="line">Selector:                 app=grafana-yaml</span><br><span class="line">Type:                     NodePort</span><br><span class="line">IP:                       10.98.52.86</span><br><span class="line">LoadBalancer Ingress:     localhost</span><br><span class="line">Port:                     &lt;<span class="built_in">unset</span>&gt;  3000/TCP</span><br><span class="line">TargetPort:               3000/TCP</span><br><span class="line">NodePort:                 &lt;<span class="built_in">unset</span>&gt;  30857/TCP</span><br><span class="line">Endpoints:                10.1.0.208:3000</span><br><span class="line">Session Affinity:         None</span><br><span class="line">External Traffic Policy:  Cluster</span><br><span class="line">Events:                   &lt;none&gt;</span><br></pre></td></tr></table></figure><p>Then you can access grafana pod via <a href="http://localhost:30857/">http://localhost:30857</a></p><h1 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6. Summary"></a>6. Summary</h1><p>Now, you should have a kubernetes environment up and running, together with Istio and Kiali enabled. It can be used as your sandbox, for developing and testing your applications in Kubernetes. With Istio and Kiali, you can also play with service mesh. Everything is running locally in “one box”, so you do not need to worry about any cloud running cost.</p><p>Have fun.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Here we will setup a single-node Kubernetes cluster on a windows 10 PC (In my case it is a surface 5 with 16GB RAM). If you are new to docker, feel free to check out &lt;a href=&quot;/2017/03/31/Jump-start-ASP-Net-Core-with-Docker/&quot;&gt;Jump-start with docker&lt;/a&gt;.&lt;br&gt;We are going to setup:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A single-node Kubernetes cluster&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes/dashboard&quot;&gt;Kubernetes dashboard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Helm&lt;/li&gt;
&lt;li&gt;Isito (service mesh, including Kiali)&lt;/li&gt;
&lt;li&gt;Deployment samples&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&quot;/2019/10/05/Jump-start-Kubernetes-with-Docker-Desktop-on-Windows-10/Title%20picture.png&quot; class=&quot;&quot;&gt;</summary>
    
    
    
    
    <category term="Docker" scheme="https://feng.lu/tags/Docker/"/>
    
    <category term="Kubernetes" scheme="https://feng.lu/tags/Kubernetes/"/>
    
    <category term="Istio" scheme="https://feng.lu/tags/Istio/"/>
    
    <category term="Service mesh" scheme="https://feng.lu/tags/Service-mesh/"/>
    
    <category term="Kiali" scheme="https://feng.lu/tags/Kiali/"/>
    
    <category term="Jump-start" scheme="https://feng.lu/tags/Jump-start/"/>
    
  </entry>
  
  <entry>
    <title>Customize social sharing on Linkedin via API</title>
    <link href="https://feng.lu/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/"/>
    <id>https://feng.lu/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/</id>
    <published>2019-02-06T19:34:51.000Z</published>
    <updated>2025-03-28T09:05:16.529Z</updated>
    
    <content type="html"><![CDATA[<p>(edited 10.06.2020: Updated how to get User ID as LinkedIn upgraded their endpoints)</p><h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h1><p>Nowadays it is pretty common to share articles on social media such as Facebook and Linkedin. Thanks to the widely implemented <a href="http://ogp.me/">Open Graph</a> protocol, sharing is no long just a dry url, but with enrich text and thumbnails.</p><p>However, there are still some web pages that do not have Open Graph implemented, which significantly reduces the readers’ willingness for clicking it. </p><img src="/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/With%20vs%20without%20thumbnails.png" class="" title="With vs without thumbnails"><p>In addition, even you introduced the Open Graph tags as a hotfix, some times you will have wait for approximately 7 days for linkedin crawler to refresh the preview caching, as mentioned in <a href="https://developer.linkedin.com/docs/share-on-linkedin">linkedin documentation</a>: </p><blockquote><p><em>The first time that LinkedIn’s crawlers visit a webpage when asked to share content via a URL, the data it finds (Open Graph values or our own analysis) will be cached for a period of approximately 7 days.</em><br><em>This means that if you subsequently change the article’s description, upload a new image, fix a typo in the title, etc., you will not see the change represented during any subsequent attempts to share the page until the cache has expired and the crawler is forced to revisit the page to retrieve fresh content.</em></p></blockquote><p>Some solutions are <a href="https://support.strikingly.com/hc/en-us/articles/214364928-LinkedIn-or-Facebook-Share-Image-Not-Updating">here</a> and <a href="https://www.linkedin.com/pulse/how-clear-linkedin-link-preview-cache-ananda-kannan-p/">here</a>, but they are more like a workaround. </p><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution:"></a>Solution:</h1><p>We can overcome this issue by using linkedin API, which provide huge flexibility for customizing the sharing experiences. </p><span id="more"></span><h2 id="1-Create-an-application-in-Linkedin"><a href="#1-Create-an-application-in-Linkedin" class="headerlink" title="1. Create an application in Linkedin"></a>1. Create an application in Linkedin</h2><p>Head to <a href="https://www.linkedin.com/developers/">https://www.linkedin.com/developers/</a> and create an application. As showed in the screenshot, I created an application named “Linkedin Poster”. Take notes on <strong>Client ID</strong> and <strong>Client Secret</strong>, set the <strong>Redirect URLs</strong> as <a href="https://www.getpostman.com/oauth2/callback">https://www.getpostman.com/oauth2/callback</a>.</p><img src="/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/Linkedin%20App.png" class="" title="Linkedin App"><h2 id="2-Generate-OAuth-token-in-Postman"><a href="#2-Generate-OAuth-token-in-Postman" class="headerlink" title="2. Generate OAuth token in Postman"></a>2. Generate OAuth token in Postman</h2><p>Use postman application to generate OAuth 2.0 token (Authorization Code Flow). The detailed documentation is <a href="https://docs.microsoft.com/en-us/linkedin/shared/authentication/authorization-code-flow?context=linkedin/consumer/context">here</a>. </p><img src="/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/Postman.png" class="" title="Postman authorization"><ul><li>Auth URL: <a href="https://www.linkedin.com/oauth/v2/authorization">https://www.linkedin.com/oauth/v2/authorization</a></li><li>Access Token URL: <a href="https://www.linkedin.com/oauth/v2/accessToken">https://www.linkedin.com/oauth/v2/accessToken</a> </li><li>Call back: <a href="https://www.getpostman.com/oauth2/callback">https://www.getpostman.com/oauth2/callback</a> (same as in the linkedin app setting)</li><li>Scope: “r_emailaddress r_liteprofile w_member_social” (need “w_member_social” as we need to post)</li></ul><p>Login to generate token<br> <img src="/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/Login.png" class="" title="Login to generate token"></p><h2 id="3-Get-user-id-from-linkedin"><a href="#3-Get-user-id-from-linkedin" class="headerlink" title="3. Get user id from linkedin"></a>3. Get user id from linkedin</h2><p>In order to post articles in LinkedIn via API, we need to provide the user id.<br>Make a GET request to API <a href="https://api.linkedin.com/v2/me">https://api.linkedin.com/v2/me</a> (see <a href="https://docs.microsoft.com/en-us/linkedin/shared/integrations/people/profile-api?context=linkedin/marketing/context">document</a>), make sure the token from step 2 is included. The result is something like below:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;localizedLastName&quot;: &quot;Lu&quot;,</span><br><span class="line">    &quot;profilePicture&quot;: &#123;</span><br><span class="line">        &quot;displayImage&quot;: &quot;urn:li:digitalmediaAsset:BACABCqwPVej-w&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;firstName&quot;: &#123;</span><br><span class="line">        &quot;localized&quot;: &#123;</span><br><span class="line">            &quot;en_US&quot;: &quot;Feng&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;preferredLocale&quot;: &#123;</span><br><span class="line">            &quot;country&quot;: &quot;US&quot;,</span><br><span class="line">            &quot;language&quot;: &quot;en&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;lastName&quot;: &#123;</span><br><span class="line">        &quot;localized&quot;: &#123;</span><br><span class="line">            &quot;en_US&quot;: &quot;Lu&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;preferredLocale&quot;: &#123;</span><br><span class="line">            &quot;country&quot;: &quot;US&quot;,</span><br><span class="line">            &quot;language&quot;: &quot;en&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;id&quot;: &quot;ABC123-ab1&quot;,</span><br><span class="line">    &quot;localizedFirstName&quot;: &quot;Feng&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-Customize-your-article-sharing-via-API"><a href="#4-Customize-your-article-sharing-via-API" class="headerlink" title="4. Customize your article sharing via API"></a>4. Customize your article sharing via API</h2><p>Ref to the <a href="https://docs.microsoft.com/en-us/linkedin/marketing/integrations/community-management/shares/share-api#post-shares">documentation</a> it is pretty straightforward for customizing the shared content. </p><p>In my case, I would like to share <a href="http://feng.lu/archives/">http://feng.lu/archives/</a> (which does not have Open Graph) with  <a href="http://feng.lu/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/archives.jpg">a nice archive picture</a>.</p><p>POST to <a href="https://api.linkedin.com/v2/shares">https://api.linkedin.com/v2/shares</a> with body:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;contentEntities&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;entityLocation&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://feng.lu/archives/&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;thumbnails&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;resolvedUrl&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://feng.lu/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/archives.jpg&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Article archives of feng.lu&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;distribution&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;linkedInDistributionTarget&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;owner&quot;</span><span class="punctuation">:</span> <span class="string">&quot;urn:li:person:MY_LINKEDIN_ID&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Checkout my blog archives! Hopefully you will find it useful. :)&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>Checkout the result:</p><img src="/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/Result.png" class="" title="Result on LinkedIn"><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion:"></a>Conclusion:</h1><p>By using LinkedIn API, we can easily customize the sharing experience with your professional networks. It does not only overcome the challenges such as missing Open Graph implementation, but also can improve the social media campaign experience and better integration with CMS.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;(edited 10.06.2020: Updated how to get User ID as LinkedIn upgraded their endpoints)&lt;/p&gt;
&lt;h1 id=&quot;Problem&quot;&gt;&lt;a href=&quot;#Problem&quot; class=&quot;headerlink&quot; title=&quot;Problem:&quot;&gt;&lt;/a&gt;Problem:&lt;/h1&gt;&lt;p&gt;Nowadays it is pretty common to share articles on social media such as Facebook and Linkedin. Thanks to the widely implemented &lt;a href=&quot;http://ogp.me/&quot;&gt;Open Graph&lt;/a&gt; protocol, sharing is no long just a dry url, but with enrich text and thumbnails.&lt;/p&gt;
&lt;p&gt;However, there are still some web pages that do not have Open Graph implemented, which significantly reduces the readers’ willingness for clicking it. &lt;/p&gt;
&lt;img src=&quot;/2019/02/06/Customize-social-sharing-on-Linkedin-via-API/With%20vs%20without%20thumbnails.png&quot; class=&quot;&quot; title=&quot;With vs without thumbnails&quot;&gt;

&lt;p&gt;In addition, even you introduced the Open Graph tags as a hotfix, some times you will have wait for approximately 7 days for linkedin crawler to refresh the preview caching, as mentioned in &lt;a href=&quot;https://developer.linkedin.com/docs/share-on-linkedin&quot;&gt;linkedin documentation&lt;/a&gt;: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The first time that LinkedIn’s crawlers visit a webpage when asked to share content via a URL, the data it finds (Open Graph values or our own analysis) will be cached for a period of approximately 7 days.&lt;/em&gt;&lt;br&gt;&lt;em&gt;This means that if you subsequently change the article’s description, upload a new image, fix a typo in the title, etc., you will not see the change represented during any subsequent attempts to share the page until the cache has expired and the crawler is forced to revisit the page to retrieve fresh content.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Some solutions are &lt;a href=&quot;https://support.strikingly.com/hc/en-us/articles/214364928-LinkedIn-or-Facebook-Share-Image-Not-Updating&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://www.linkedin.com/pulse/how-clear-linkedin-link-preview-cache-ananda-kannan-p/&quot;&gt;here&lt;/a&gt;, but they are more like a workaround. &lt;/p&gt;
&lt;h1 id=&quot;Solution&quot;&gt;&lt;a href=&quot;#Solution&quot; class=&quot;headerlink&quot; title=&quot;Solution:&quot;&gt;&lt;/a&gt;Solution:&lt;/h1&gt;&lt;p&gt;We can overcome this issue by using linkedin API, which provide huge flexibility for customizing the sharing experiences. &lt;/p&gt;</summary>
    
    
    
    
    <category term="Linkedin" scheme="https://feng.lu/tags/Linkedin/"/>
    
    <category term="Social Sharing" scheme="https://feng.lu/tags/Social-Sharing/"/>
    
    <category term="API" scheme="https://feng.lu/tags/API/"/>
    
    <category term="OAuth" scheme="https://feng.lu/tags/OAuth/"/>
    
    <category term="Postman" scheme="https://feng.lu/tags/Postman/"/>
    
  </entry>
  
  <entry>
    <title>Data Integrity and Lineage by using DLT, Part 3</title>
    <link href="https://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/"/>
    <id>https://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/</id>
    <published>2019-01-03T10:08:30.000Z</published>
    <updated>2025-03-28T10:26:55.649Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Other articles in this series:</strong></p><ul><li><a href="http://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/">Part 1</a></li><li><a href="http://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/">Part 2</a> </li><li>Part 3 (this article)</li></ul><h1 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h1><p>In the second part of this series, we have went though both the detailed technical design that is based on IOTA. Some quick recap are:</p><ol><li>Use MAM protocol for interacting with IOTA Tangle.</li><li>Defined the core data schema (4 mandatory fields: “dataPackageId”, “wayOfProof” , “valueOfProof” and “inputs”).</li></ol><p>Although the core data schema is quite easy to implement, companies and developers might meet some challenges to get started, such as:</p><ol><li>Developers need to build the knowledge of IOTA and MAM protocol.</li><li>Need to build user interface for data lineage visualization.</li><li>Companies most likely need to setup and maintain their dedicated infrastructure (Web server that runs IOTA server code, database, resource to perform Proof-of-Work, connection to neighbor nodes in IOTA network, etc), as public nodes from community are not stable.</li></ol><h1 id="Data-Lineage-Service-an-open-source-application-to-get-you-started"><a href="#Data-Lineage-Service-an-open-source-application-to-get-you-started" class="headerlink" title="Data Lineage Service - an open source application to get you started"></a>Data Lineage Service - an open source application to get you started</h1><p>We want to address above challenges, and help everyone to gain benefits of data integrity and lineage. Therefore, we have built “<strong>Data Lineage Service</strong>“ application. Developers and companies can apply this technology without deep understanding of IOTA and MAM protocol. It can be used either as a standalone application, or a microservice that integrates with existing systems.</p><p>The key functions are:</p><ul><li>Wrapped IOTA MAM protocol to well-known HTTP(s) protocol as standard Restful API, with swagger definition. Developers do not need to worry about MAM protocol and it technical details, but focus on the normal data pipeline.</li><li>Reusable web interface for lineage visualization.</li><li>User-friendly interface for submitting data integrity and lineage information to DLT.</li><li>Built-in functionalities for addressing common issues such as caching and monitoring.</li><li>It is <a href="https://github.com/veracity/data-lineage-service">open-sourced on github</a> with MIT license.</li></ul><span id="more"></span><p>Also, for one who simply wanna try it out in the live environment, we are hosting this service that connects to the live DLT environment (IOTA tangle mainnet). </p><p>As a live environment, it allows anyone to:</p><ul><li>Submit and receive integrity&#x2F;lineage information with the live IOTA tangle mainnet, without maintain his&#x2F;her own infrastructure.</li><li>Outsource Proof-of-work (PoW) from clients to the service. Our host environment is taking care of the PoW on the server side. It helps IoT devices with low computing power (such as Raspberry PI) to submit information to DLT without consuming local resources. This also helps to improve the submission throughput (Number of submission per second). </li><li>All functions can be done via either web browser or restful APIs.</li><li><strong>Zero cost</strong> for testing and building Proof-of-Concept applications with real-world DLT.</li></ul><h2 id="Source-code-of-Data-Lineage-Service"><a href="#Source-code-of-Data-Lineage-Service" class="headerlink" title="Source code of Data-Lineage-Service"></a>Source code of Data-Lineage-Service</h2><p>The source code is hosted in Github: <a href="https://github.com/veracity/data-lineage-service">https://github.com/veracity/data-lineage-service</a></p><h2 id="Live-environment"><a href="#Live-environment" class="headerlink" title="Live environment"></a>Live environment</h2><p>The live demo environment can be found at <a href="https://datalineage-viewer.azurewebsites.net/">https://datalineage-viewer.azurewebsites.net</a><br>This live environment is backed by IOTA public network (public IOTA nodes). Feel free to use it (either GUI or API swagger) to store your integrity and lineage data into IOTA mainnet, as well as visualize the existing data. </p><p>The API Swagger is at <a href="https://datalineage-viewer.azurewebsites.net/swagger/">https://datalineage-viewer.azurewebsites.net/swagger/</a> </p><p>Screenshot:</p><img src="/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/datalineage-screenshot.png" class="" title="Screenshot of data lineage view"><h2 id="Real-World-Demo-Real-time-data-integrity-on-IoT-device"><a href="#Real-World-Demo-Real-time-data-integrity-on-IoT-device" class="headerlink" title="Real World Demo: Real-time data integrity on IoT device"></a>Real World Demo: Real-time data integrity on IoT device</h2><p>By using this service, an IoT device can ensure the integrity of its IoT data stream. As a demo, I have a raspberry pi with <a href="https://www.raspberrypi.org/products/sense-hat/">sense hat</a> that is reporting temperature as well as saving the integrity information to DLT. The integrity information can be read at <a href="https://thetangle.org/mam/UZFQPIFSPRNEXLGYLKQIFUZNZWLSQCUWBFHRWLBJDKIANJLKRMEYAMEPFEFHQBTENPSLPQBKKCVGYLMUN">here</a> from DLT. </p><div class="video-container"><iframe src="https://www.youtube.com/embed/uL5f_d1Np20" frameborder="0" loading="lazy" allowfullscreen></iframe></div><p>Therefore, the data consumer of this temperature sensor can be confident that:</p><ul><li>the temperature report (and the report timestamp) is not tampered  </li><li>it is indeed from <em>this</em> raspberry pi </li><li>this data integrity information can be included into the downstream data lineage</li></ul><p>The source code of this demo is at <a href="https://github.com/linkcd/data-integrity-on-pi">https://github.com/linkcd/data-integrity-on-pi</a></p><h1 id="Performance-testing-and-results"><a href="#Performance-testing-and-results" class="headerlink" title="Performance testing and results"></a>Performance testing and results</h1><p>From day 1, the performance of DLT is a known issue. By expanding this technology into the IoT and real-time data exchanging world, the performance can be a blocking issue. This is also the reason that we started look into IOTA in the beginning, hope its performance can meet the need.</p><p>We have conducted the performance testing in 3 iterations:</p><ol><li>Using a public IOTA node</li><li>Using our own self-hosted IOTA node</li><li>Using self-hosted IOTA node but outsource the PoW to <a href="https://powsrv.io/">https://powsrv.io/</a></li></ol><p>In each iteration, we tested performance both for reading and writing. The testing code is also open-sourced at github <a href="https://github.com/veracity/IOTA-MAM-performance-testing">https://github.com/veracity/IOTA-MAM-performance-testing</a></p><p><strong>Test results (on 20.09.2018)</strong></p><img src="/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/Performace%20testing.png" class="" title="Performance testing"><p><strong>Conclusion</strong>:</p><ul><li>Performance of <strong>reading</strong> is OK (0.5 second per read), as far as you have a stable IOTA node (either self-host or from a provider)</li><li>Outsource the PoW to dedicated service providers such as powsrv.io can significantly improve the performance of <strong>writing</strong>, but the best result allows us to do about 15 transactions per minute.</li></ul><h1 id="Next-step"><a href="#Next-step" class="headerlink" title="Next step"></a>Next step</h1><p>In veracity we are researching and building <strong>Data Integrity and Lineage as a Service (DILAAS)</strong>  to bring down the barriers for both data providers and data consumers. DILAAS offers:</p><ol><li>A cloud service for managing and exchanging data integrity and lineage information between parties.</li><li>Standard HTTP(s) API, without building competence of backend DLT, such as MAM programming. It helps to reduce the development cost and boost the onboard progress.</li><li>Visualization of data integrity and lineage information.</li><li>Managed infrastructure that offers stable IOTA network accessibility. </li><li>Seed&#x2F;Identity management, for properly managing the seeds&#x2F;identifies in the secure environment.</li></ol><p><strong>Other articles in this series:</strong></p><ul><li><a href="http://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/">Part 1</a></li><li><a href="http://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/">Part 2</a> </li><li>Part 3 (this article)</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Other articles in this series:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/&quot;&gt;Part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/&quot;&gt;Part 2&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Part 3 (this article)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Recap&quot;&gt;&lt;a href=&quot;#Recap&quot; class=&quot;headerlink&quot; title=&quot;Recap&quot;&gt;&lt;/a&gt;Recap&lt;/h1&gt;&lt;p&gt;In the second part of this series, we have went though both the detailed technical design that is based on IOTA. Some quick recap are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use MAM protocol for interacting with IOTA Tangle.&lt;/li&gt;
&lt;li&gt;Defined the core data schema (4 mandatory fields: “dataPackageId”, “wayOfProof” , “valueOfProof” and “inputs”).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although the core data schema is quite easy to implement, companies and developers might meet some challenges to get started, such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Developers need to build the knowledge of IOTA and MAM protocol.&lt;/li&gt;
&lt;li&gt;Need to build user interface for data lineage visualization.&lt;/li&gt;
&lt;li&gt;Companies most likely need to setup and maintain their dedicated infrastructure (Web server that runs IOTA server code, database, resource to perform Proof-of-Work, connection to neighbor nodes in IOTA network, etc), as public nodes from community are not stable.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;Data-Lineage-Service-an-open-source-application-to-get-you-started&quot;&gt;&lt;a href=&quot;#Data-Lineage-Service-an-open-source-application-to-get-you-started&quot; class=&quot;headerlink&quot; title=&quot;Data Lineage Service - an open source application to get you started&quot;&gt;&lt;/a&gt;Data Lineage Service - an open source application to get you started&lt;/h1&gt;&lt;p&gt;We want to address above challenges, and help everyone to gain benefits of data integrity and lineage. Therefore, we have built “&lt;strong&gt;Data Lineage Service&lt;/strong&gt;“ application. Developers and companies can apply this technology without deep understanding of IOTA and MAM protocol. It can be used either as a standalone application, or a microservice that integrates with existing systems.&lt;/p&gt;
&lt;p&gt;The key functions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wrapped IOTA MAM protocol to well-known HTTP(s) protocol as standard Restful API, with swagger definition. Developers do not need to worry about MAM protocol and it technical details, but focus on the normal data pipeline.&lt;/li&gt;
&lt;li&gt;Reusable web interface for lineage visualization.&lt;/li&gt;
&lt;li&gt;User-friendly interface for submitting data integrity and lineage information to DLT.&lt;/li&gt;
&lt;li&gt;Built-in functionalities for addressing common issues such as caching and monitoring.&lt;/li&gt;
&lt;li&gt;It is &lt;a href=&quot;https://github.com/veracity/data-lineage-service&quot;&gt;open-sourced on github&lt;/a&gt; with MIT license.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="IOTA" scheme="https://feng.lu/tags/IOTA/"/>
    
    <category term="Data Lineage" scheme="https://feng.lu/tags/Data-Lineage/"/>
    
    <category term="Data Integrity" scheme="https://feng.lu/tags/Data-Integrity/"/>
    
    <category term="DLT" scheme="https://feng.lu/tags/DLT/"/>
    
    <category term="Distributed Ledger Technology" scheme="https://feng.lu/tags/Distributed-Ledger-Technology/"/>
    
    <category term="Tangle" scheme="https://feng.lu/tags/Tangle/"/>
    
  </entry>
  
  <entry>
    <title>Data Integrity and Lineage by using DLT, Part 2</title>
    <link href="https://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/"/>
    <id>https://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/</id>
    <published>2018-10-03T18:14:40.000Z</published>
    <updated>2025-03-28T09:05:16.550Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Other articles in this series:</strong></p><ul><li><a href="http://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/">Part 1</a></li><li>Part 2 (this article)</li><li><a href="http://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/">Part 3</a></li></ul><p>In my previous article, we discussed different approaches for solving the data integrity and lineage challenges, and concluded that the “<strong>Hashing with DLT</strong>“ solution is the direction we will move forward. In this article, we will have deep dive into it. Please not that Veracity’s work on data integrity and data lineage is testing many technologies in parallel. We utilise and test proven centralized technologies as well as new distributed ledger technologies like Tangle and Blockchain. This article series uses the IOTA Tangle as the distributed ledger technology. The use cases described can be solved with other technologies. This article does not necessarily reflect the technologies used in Veracity production environments.</p><h1 id="Which-DLT-to-select"><a href="#Which-DLT-to-select" class="headerlink" title="Which DLT to select?"></a>Which DLT to select?</h1><p>As Veracity is part of an Open Industry Ecosystem we have focused our data integrity and data lineage work using public DLT and open sourced technologies. We believe that to succeed with providing transparency from the user to the origin of data many technology vendors must collaborate around common standards and technologies. The organizational setup and philosophies for some of the public distributed ledgers provides the right environment to learn and develop fast with an adaptive ecosystem. </p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/title.jpg" class=""><span id="more"></span><p>There are many public DLT platforms nowadays, but not all of them (such as Bitcoin and Ethereum) are suitable for Big Data or IoT scenarios, such as:</p><ol><li>We are tracking logical data entities (bits, files or data streams) instead of physical entities (coal, car parts or packages).</li><li>The granularity of data has much more detailed scale in IoT and the Big Data world. One example is, tracking every single piece of coal from a carrier ship sounds crazy, but tracking every data signal from thousands of sensors from the very same ship is quite common. </li><li>We need to use DLT to handle large volume of transactions within a short time period (e.g. send 1000 data points from one device to another device per minute) </li><li>We need to use DLT to store large amount of data (e.g. data integrity information of thousands of sensors)</li><li><ol start="5"><li>   High transaction fees will weaken the business case.</li></ol></li></ol><h2 id="IOTA-the-selected-DTL-for-exploring"><a href="#IOTA-the-selected-DTL-for-exploring" class="headerlink" title="IOTA - the selected DTL for exploring"></a>IOTA - the selected DTL for exploring</h2><p>We have been watching closely at the technology evolution of distributed ledgers and exploring different possibilities. Currently we are exploring <a href="https://www.iota.org/">IOTA</a>, which is a new type of DLT that foundationally different from other blockchain-based technologies.  The high-level comparison can be found at <a href="https://www.iota.org/get-started/faqs">IOTA FAQs</a>, question “How is IOTA different from Blockchain?”<br>We decide to test our solution on top of IOTA, due to the following key features that IOTA offers:</p><ol><li>Promise of higher performance and scalability: Thanks to tangle data structure.</li><li>Zero Transaction Fee: Machine to Machine micropayments. This way machines can pay each other for certain services and resources.</li></ol><p><em>This is not an article of introducing IOTA, but you can learn more from <a href="https://www.iota.org/">https://www.iota.org</a></em></p><h2 id="MAM-protocol-from-IOTA"><a href="#MAM-protocol-from-IOTA" class="headerlink" title="MAM protocol from IOTA"></a>MAM protocol from IOTA</h2><p>In addition, IOTA provides a protocol named <a href="https://blog.iota.org/introducing-masked-authenticated-messaging-e55c1822d50e">Masked Authenticated Messaging (MAM)</a> that easily fit into our solution. MAM provides an abstract data structure layer (channels) on top of regular transactions. In our solution, all read and write data into DLT (tangle) is around MAM channels. Check the article appendix for more resources of MAM.</p><ol><li>One person or application creates a private seed. The seed shall be considered as a private key, and not be shared with others.</li><li>One seed can create one unique MAM channel in IOTA tangle that can store messages.</li><li>Messages contain data such as json object.</li><li>The private seed ensures that only the seed owner is authorized to write messages in the channel. Therefore the origin of the messages is trusted by others.</li><li>Once the message was written into channel, the message is replicated and stored in all nodes in DLT. It means the message is immutable.</li><li>Once you know a MAM address in the channel, you can go through all addresses (and fetch their messages) that follows the known address, such as <em>root address -&gt; address 1 -&gt; address 2 -&gt; address 3 -&gt; address N</em>…</li><li>The message can be fetched from channels by using the MAM address.</li></ol><p>Therefore, Alice can publish the hash values like the following diagram </p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/Hashing%20with%20MAM%20channel.png" class=""><p>In above case, Alice creates one channel with her private seed. Then she sends messages into this channel, one address has one message. </p><h3 id="Sample-code-for-sending-MAM-message-to-channel"><a href="#Sample-code-for-sending-MAM-message-to-channel" class="headerlink" title="Sample code for sending MAM message to channel"></a>Sample code for sending MAM message to channel</h3><p>There is a sample code for sending message into IOTA tangle at <a href="https://github.com/linkcd/IOTAPoC/blob/master/tangleWriter.js">https://github.com/linkcd/IOTAPoC/blob/master/tangleWriter.js</a> from <a href="https://github.com/linkcd/IOTAPoC">my repository</a>.</p><p>This code simply:</p><ol><li>Generates a random seed and create a public MAM channel</li><li>Accepts inputs from keyboard and send it to tangle as json format</li><li>Once the message was sent do tangle, anyone can query the tangle and read it from the public channel. But none can change it since it is immutable. You can read the MAM message by using a good tool <a href="https://thetangle.org/mam">https://thetangle.org/mam</a>.</li></ol><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/MAM%20sample%20code.png" class="" title="Sample code for sending message to IOTA tangle"><h1 id="Design-principles-and-conceptual-entities"><a href="#Design-principles-and-conceptual-entities" class="headerlink" title="Design principles and conceptual entities"></a>Design principles and conceptual entities</h1><p>First, let’s agree some design principles and conceptual entities</p><h2 id="1-Self-service-verification-process"><a href="#1-Self-service-verification-process" class="headerlink" title="1. Self-service verification process"></a>1. Self-service verification process</h2><p>The verification process of both data integrity and data lineage should be self-service. It means that all verification information should be available to public. Data provider should not be bothered by this process.<br><em>(Technically it is possible to have permission control of the verification process, by using <strong>private</strong> or <strong>restricted</strong> MAM channels, it means that data provider has to response to the ad-hoc verification requests)</em></p><h2 id="2-Data-lineage-verification-is-an-add-on-on-the-side-of-the-main-data-flow"><a href="#2-Data-lineage-verification-is-an-add-on-on-the-side-of-the-main-data-flow" class="headerlink" title="2. Data lineage verification is an add-on on the side of the main data-flow"></a>2. Data lineage verification is an add-on on the side of the main data-flow</h2><p>It means that data lineage will not impact the existing data flow, nor become a bottleneck. </p><h2 id="3-Conceptual-entities"><a href="#3-Conceptual-entities" class="headerlink" title="3. Conceptual entities"></a>3. Conceptual entities</h2><h3 id="3-1-Data-Source"><a href="#3-1-Data-Source" class="headerlink" title="3.1 Data Source"></a>3.1 Data Source</h3><ul><li>A sensor, person or application that generates data package(s)</li><li>Has 0 or more inputs (upstream data source)</li><li>Has 1 or more outputs (downstream data source)</li><li>A company can have more than one data sources</li></ul><h3 id="3-2-Data-Package"><a href="#3-2-Data-Package" class="headerlink" title="3.2 Data Package"></a>3.2 Data Package</h3><p>An atomic unit in data flow from one data source to another data source. For example:</p><ul><li>A data point (23 degree at 10:30am), or</li><li>A file (json, xml)</li><li>Files (1.json, 2.json…10.json…)</li><li>Data rows in a database (row #1 to row #10 in table “employee”)</li></ul><h3 id="3-3-Data-Package-Id"><a href="#3-3-Data-Package-Id" class="headerlink" title="3.3 Data Package Id"></a>3.3 Data Package Id</h3><p>The unique ID of a data package in the scope of a data source. A typical data package ID is a number, a GUID or a time-stamp.</p><h3 id="3-4-Data-Stream"><a href="#3-4-Data-Stream" class="headerlink" title="3.4 Data Stream"></a>3.4 Data Stream</h3><p>Data stream is data package series from the same data source. It contains more than one packages and their IDs.</p><h1 id="Deep-dive-1-Data-integrity"><a href="#Deep-dive-1-Data-integrity" class="headerlink" title="Deep dive #1: Data integrity"></a>Deep dive #1: Data integrity</h1><p><strong>Goal: Data consumers can verify the integrity of data packages from a data source.</strong></p><h2 id="Overview-of-data-integrity-workflow"><a href="#Overview-of-data-integrity-workflow" class="headerlink" title="Overview of data integrity workflow"></a>Overview of data integrity workflow</h2><p>The high level overview of data integrity workflow is as following:</p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/Workflow.png" class="" title="Click to enlarge the workflow of data integrity"><h3 id="Step-1-Data-source-announces-its-MAM-channel-root-address-for-publishing-integrity-information"><a href="#Step-1-Data-source-announces-its-MAM-channel-root-address-for-publishing-integrity-information" class="headerlink" title="Step 1. Data source announces its MAM channel root address, for publishing integrity information"></a>Step 1. Data source announces its MAM channel root address, for publishing integrity information</h3><p>Data source creates a MAM public channel by using its private seed, then share the <strong>root address of this channel</strong> with public. It can be done, for instance, via data source’s web site.</p><h4 id="Side-Note-Why-publish-only-root-address-not-all-individual-addresses-per-each-package"><a href="#Side-Note-Why-publish-only-root-address-not-all-individual-addresses-per-each-package" class="headerlink" title="Side Note: Why publish only root address, not all individual addresses per each package"></a>Side Note: Why publish only root address, not all individual addresses per each package</h4><p>The data source can, of course, publish all individual addresses for all messages, but it will be too many. As long as consumers have the channel root address, they can go through all addresses from the root, to find the specific address&#x2F;message to verify. See step 5.</p><h3 id="Step-2-Decide-your-integrity-information-content"><a href="#Step-2-Decide-your-integrity-information-content" class="headerlink" title="Step 2. Decide your integrity information content"></a>Step 2. Decide your integrity information content</h3><p>In order to allow the consumer to verify the integrity, data source need to provide enough information to make it possible. Therefore, you need to decide what information should be stored in the tangle as json object.</p><h4 id="Mandatory-fields"><a href="#Mandatory-fields" class="headerlink" title="Mandatory fields"></a>Mandatory fields</h4><p>All object must have the following core fields. All of them are <strong>mandatory</strong>.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">datapackageId<span class="punctuation">:</span> string<span class="punctuation">,</span></span><br><span class="line">wayofProof<span class="punctuation">:</span>string<span class="punctuation">,</span></span><br><span class="line">valueOfProof<span class="punctuation">:</span>string</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Field</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td><strong>datapackageId</strong></td><td>The package ID is used for querying the data lineage info from the channel. Data source decides the ID format, such as integer or GUID. Different channels can have the same package ID.</td><td>“123456”</td></tr><tr><td><strong>wayofProof</strong></td><td>Information about how to verify the integrity based on valueOfProof. For example, it explains the used hash algorithms (SHA1 or SHA2 or others), or it simply copied the data package content into field valueOfProof.</td><td>“SHA256(packageId, data-content)”</td></tr><tr><td><strong>valueOfProof</strong></td><td>The value of the proof, such as hash value, or the copy of the data content in clear text.</td><td>(hash value or data itself)</td></tr></tbody></table><p><strong>Example</strong><br>An application (aka data source) generates big csv files and pass to the downstream (aka data consumer). All csv files have a unique file name. The application decides to hash the file content together with the file name. The hash function can be one of the <a href="https://en.wikipedia.org/wiki/Secure_Hash_Algorithms">Secure Hash Algorithms</a>, such as SHA-512&#x2F;256.</p><p>Therefore, for file “file201.csv”, the application computed the hash based on <strong>SHA512(“201”, filecontent.string())</strong>, which is “7EC8E…AAFAA”</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">datapackageId<span class="punctuation">:</span> <span class="string">&quot;201&quot;</span><span class="punctuation">,</span></span><br><span class="line">wayofProof<span class="punctuation">:</span><span class="string">&quot;SHA512(201, filecontent.string())&quot;</span><span class="punctuation">,</span></span><br><span class="line">valueOfProof<span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="number">7</span>EC8E...AAFAA<span class="string">&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>Use hash for reducing calls to tangle</strong><br>The hash is also useful if you want to reduce the data sent to tangle. For example, a data source is generating a small file per second. However, pushing data to tangle in every second can be a performance bottleneck. If the data source pack all files of every 10 minutes into one, assign an ID and compute the hash value of this data trunk, it can still publish integrity data into tangle but with much lower frequency. </p><h4 id="Extend-it-with-optional-fields"><a href="#Extend-it-with-optional-fields" class="headerlink" title="Extend it with optional fields"></a>Extend it with optional fields</h4><p>In addition to the above mandatory fields, you can extend the json object by adding more additional fields for fitting your logic. </p><p>For example, you can add a field “location” for storing the application name, and “sensorType” of application owner type.  These fields will be tightly coupled with these core fields, and stored in the tangle.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">datapackageId<span class="punctuation">:</span> <span class="string">&quot;201&quot;</span><span class="punctuation">,</span></span><br><span class="line">wayofProof<span class="punctuation">:</span><span class="string">&quot;SHA512(201, filecontent.string())&quot;</span><span class="punctuation">,</span></span><br><span class="line">valueOfProof<span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="number">7</span>EC8E...AAFAA<span class="string">&quot;</span></span><br><span class="line"><span class="string">applicationName:&quot;</span>temperature reporter v2<span class="number">.1</span><span class="string">&quot;,</span></span><br><span class="line"><span class="string">applicationOwner:&quot;</span>feng.lu@veracity.com<span class="string">&quot;,</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">additionalField:...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>Note</strong><br>“timestamp” is not a mandatory field, as all transactions in Tangle already has a system timestamp that shows when the data was submitted to the tangle. You can add a “package-received-timestamp” field that shows when the original data package was collected.</p><h3 id="Step-3-Data-source-send-data-integrity-information-to-the-channel"><a href="#Step-3-Data-source-send-data-integrity-information-to-the-channel" class="headerlink" title="Step 3. Data source send data integrity information to the channel"></a>Step 3. Data source send data integrity information to the channel</h3><p>Data source sends above json object to the MAM channel (IOTA tangle). The json object will be stored in a MAM address inside of the channel. This can be done by using the demo code shown above.</p><p><strong>— At this point, data source completes all needed tasks—-</strong></p><h3 id="Step-4-Data-consumer-obtains-the-root-address-of-the-MAM-channel-from-the-data-source"><a href="#Step-4-Data-consumer-obtains-the-root-address-of-the-MAM-channel-from-the-data-source" class="headerlink" title="Step 4. Data consumer obtains the root address of the MAM channel from the data source"></a>Step 4. Data consumer obtains the root address of the MAM channel from the data source</h3><p>Data consumer goes to the website from step 1 to get the root address of the MAM channel that belongs to the data source.</p><h3 id="Step-5-Data-consumer-obtains-the-wayOfProof-and-valueOfProof-for-a-specific-package"><a href="#Step-5-Data-consumer-obtains-the-wayOfProof-and-valueOfProof-for-a-specific-package" class="headerlink" title="Step 5. Data consumer obtains the wayOfProof and valueOfProof for a specific package"></a>Step 5. Data consumer obtains the <strong>wayOfProof</strong> and <strong>valueOfProof</strong> for a specific package</h3><p>Data consumer goes through the MAM channel, address by address, to find the json object for the specific package, by using packageID. Then it obtains the <strong>wayOfProof</strong> and <strong>valueOfProof</strong> for that package.</p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/Go%20through%20MAM%20channel.png" class="" title="Go through MAM channel"><p>The pseudo-code is</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// get root address of the channel, from data source website</span></span><br><span class="line">currentAddress = channel-root-address-got-from-data-source-website</span><br><span class="line"></span><br><span class="line"><span class="comment">// to find message for package #201 </span></span><br><span class="line">targetPackageId = <span class="number">201</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// start from the root address, go through all messages in this channel, to find the target message</span></span><br><span class="line"><span class="keyword">while</span>(currentAddress != <span class="literal">null</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">var</span> <span class="variable">currentInfo</span> <span class="operator">=</span> MAM.GetInfoFromAddress(currentAddress)</span><br><span class="line">  <span class="keyword">if</span>(currentInfo.PackageId == targetPackageId)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// found the verification info for the target package, return</span></span><br><span class="line">    <span class="keyword">return</span> currentInfo</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">//the current address is not for the target package, go to next address</span></span><br><span class="line">    currentAddress = currentAddress.nextAddress</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//check currentInfo.wayOfProof and currentInfo.valueOfProof</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure><h3 id="Step-6-Data-consumer-prepare-for-verification"><a href="#Step-6-Data-consumer-prepare-for-verification" class="headerlink" title="Step 6. Data consumer prepare for verification"></a>Step 6. Data consumer prepare for verification</h3><p>Data consumer read the <strong>“wayOfProof”</strong> to understand how to check the <strong>“valueOfProof”</strong> field. For example, compute the hash by using the same hash function <strong>“SHA512(201, filecontent.string())”</strong> for package 201.</p><h3 id="Step-7-Data-consumer-to-verify-the-integrity"><a href="#Step-7-Data-consumer-to-verify-the-integrity" class="headerlink" title="Step 7. Data consumer to verify the integrity"></a>Step 7. Data consumer to verify the integrity</h3><p>Data consumer compares the hash values from the MAM channel and the local compute process. </p><ul><li>If hash value matches, then integrity is OK, accept the package.</li><li>If hash value does NOT match, then integrity is NOT OK, reject the package.</li></ul><h1 id="Deep-dive-2-Data-Lineage"><a href="#Deep-dive-2-Data-Lineage" class="headerlink" title="Deep dive #2: Data Lineage"></a>Deep dive #2: Data Lineage</h1><h2 id="A-case-study"><a href="#A-case-study" class="headerlink" title="A case study"></a>A case study</h2><p>Let’s look at a real life case: </p><p>You as an American tourist was having an vacation in Norway. You were driving a car and had a great experience of the fjords. Unfortunately you had a small accident outside of a gas station, and the car windshield was damaged (but lucky, no one has been injured). The local police station was informed and issued a form (in Norwegian!) about this accident. </p><p>Now you would like to report this to your insurance company. </p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/Report%20an%20accident.png" class="" title="Report an accident"><p>Most likely the insurance company would like to know if they can trust the damage report. You can of course explain that the data flow is:</p><ol><li>The police station in Norway issued a statement in Norwegian <strong>“2018 20. februar 13:00: En liten bilulykke utenfor Esso bensinstasjon på Billingstadsletta 9, 1396 Billingstad. Bilskade: 5000 NOK.”</strong> </li><li>Since the US based insurance company only accept documents in English, a translation provider helped to translate this statement from Norwegian to English: <strong>“2018 Feb 20th, 13:00PM: A small car accident outside of Esso gas station at Billingstadsletta 9, 1396 Billingstad.Car damage: 5000 NOK. “</strong></li><li>The next step is to convert the currency <strong>5000 NOK</strong> to US Dollar, according to the currency rate of 2018 Feb 20th, as well as provide a map for describing the location of the accident. Therefore a currency converter and a geolocation service provider were involved for providing data.</li></ol><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/How%20the%20report%20was%20created.png" class="" title="How the report was created"><p>If we can store and verify this flow (data lineage of the report), it will:</p><ol><li>Provide full traceability of the end-to-end process</li><li>Save huge cost from insurance company by reducing the time-consuming manual verification process</li><li>Immutable histories of all inputs of the report. It also helps to identify responsibility of any false input.</li></ol><h2 id="Solution-Design"><a href="#Solution-Design" class="headerlink" title="Solution Design"></a>Solution Design</h2><p>On the top of the data integrity layer that we discussed above, it is easy to extend the format to build the data lineage layer. </p><p>Now we extend the format to include an optional field “<strong>inputs</strong>“, which is an array of MAM addresses. These addresses represent the data integrity information of all inputs of the current data package.  A MAM address is a global unique identifier in Tangle, regardless of which channel it belongs to.</p><h4 id="Extent-the-format-to-include-inputs"><a href="#Extent-the-format-to-include-inputs" class="headerlink" title="Extent the format to include inputs"></a>Extent the format to include inputs</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">datapackageId<span class="punctuation">:</span> string<span class="punctuation">,</span></span><br><span class="line">wayofProof<span class="punctuation">:</span>string<span class="punctuation">,</span></span><br><span class="line">valueOfProof<span class="punctuation">:</span>string<span class="punctuation">,</span></span><br><span class="line">inputs<span class="punctuation">:</span> <span class="punctuation">[</span>array-of-input-addresses<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">...</span><br><span class="line">additionalField<span class="punctuation">:</span>...</span><br><span class="line">...</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>Depends on if you have any input, “<strong>inputs</strong>“ field is optional. You can ignore this field, or have this field, but the value is null.</p><p>The illustration is as below:</p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/Data%20lineage%20MAM%20implementation.png" class="" title="Data lineage MAM implementation"><p>Then, for above insurance report case, by using the additional <strong>inputs</strong> field, it is easy to establish the follow data lineage flow:</p><img src="/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/Data%20lineage%20flow.png" class="" title="Click to enlarge the data lineage flow"><p>It means that</p><ol><li>The insurance company can verify that the report#33 is indeed from the report generator and it was not tampered.</li><li>By following the inputs fields, the insurance company can also find all upstream data and data origin in report#33, and verify the integrity of them as well.  </li><li>It also helps, for example, if there is a mistake of the currency convert from NOK to USD, it is the currency converter, not the report generator (customer), that holds the responsibility.</li></ol><h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><p><strong>Q1</strong>: Can I use IOTA and MAM protocol without IOTA token?<br><strong>A1</strong>: Yes. Technically all MAM messages are 0(zero) value transactions. You can create unlimited MAM messages without any IOTA token. </p><p><strong>Q2</strong>: Can I use IOTA and MAM protocol without hosting an IOTA node?<br><strong>A1</strong>: Yes. You can use public hosted nodes on mainnet. For example, check <a href="https://thetangle.org/nodes">https://thetangle.org/nodes</a> or google “iota public nodes”. However, for production-ready solutions, having a managed node is recommended, which can offer you, for example, capacity of permanode, see Q3. </p><p><strong>Q3</strong>: What are Public nodes and Permanode? Which one should I use?<br><strong>A3</strong>: Some explanation can be found <a href="https://iota.stackexchange.com/questions/782/full-node-vs-permanode/783">at here</a>, for example. The short answer is, if you need to keep the historical MAM messages away from IOTA snapshots, go with permanode. Veracity is planning to host permanode(s) for the platform and its partners&#x2F;customers. </p><p><strong>Q4</strong>: Is it free to create a private seed and send messages to MAM channels?<br><strong>A4</strong>: Yes, you can simply create a seed (a string) locally and store data into MAM channel. Feel free to generate seeds for your sensors&#x2F;applications.</p><p><strong>Q5</strong>: I do not want to use public MAM channels that anyone can take a look at, even if I know the messages only contain hash values. How can I protect the channels?<br><strong>A5</strong>: MAM channel supports 3 access levels: public, private and restricted. In our solution, in order to make the verification as a self-service, we decided to use public channels. But it is possible to switch to private or restricted channels, and grant access to the selected data consumers to the channel.</p><p><strong>Q6</strong>: I have an application that is sending out data to consumers. Do I need to do anything if a new consumer starts using my data and build the lineage on top of it?<br><strong>A6</strong>: No. As a data source sitting in the upstream, you do not need to do anything for downstream consumers.</p><p><strong>Q7</strong>: I am a data consumer. What information do I need to create the whole data lineage covering all inputs in different levels? For example, if the data flow is Alice-&gt;Bob-&gt;Carol-&gt;myself, do I need to know the MAM root address of Alice, Bob and Carol?<br><strong>A7</strong>: No, you only need MAM root of Carol. As far as you follow the input fields recursively，you can check integrity and lineage of Bob (Carol’s upstream) and Alice (Bob’s upstream). In above insurance case, the insurance company can also follow the inputs fields to check, for example, the translator’s message and the Norwegian police station’s message.</p><p><strong>Q8</strong>: This solution sounds great, but it can take some efforts to build it, such as build the UX for data lineage visualization, API for read&#x2F;write MAM messages, manage seeds properly, etc. Is there anything we can reuse?<br><strong>A8</strong>: I am glad that you asked. In veracity we are building <strong>Data Integrity and Lineage as a Service (DILAAS)</strong>  to bring down the barriers for both data providers and data consumers. DILAAS offers:</p><ol><li>A cloud service for managing and exchanging data integrity and lineage information between parties.</li><li>Standard HTTP API, without building competence of backend DLT, such as MAM programming. It helps to reduce the development cost and boost the onboard progress.</li><li>Seed&#x2F;Identity management, for properly managing the seeds&#x2F;identifies in the secure environment.</li><li>Visualization of data integrity and lineage information.</li></ol><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>In this article, we discussed the detailed design of verification data schema, such as these crucial fields: <strong>“datapackageId”</strong>, <strong>“wayofProof”</strong> , <strong>“valueOfProof”</strong> and <strong>“inputs”</strong>. We also implemented the solution on  the selected DLT: IOTA and its MAM protocol. In next article of this series, we will put this solution into actions, and have closer look at some components of the DILAAS. </p><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><p>Masked Authenticated Messaging (MAM) was introduced by IOTA in Nov 2017. The high level description can be found  <a href="https://blog.iota.org/introducing-masked-authenticated-messaging-e55c1822d50e">here</a>. In addition, some deep dive information of Tangle transaction and MAM can be found at:</p><ul><li><a href="https://medium.com/@abmushi/iota-mam-eloquently-explained-d7505863b413">IOTA: MAM Eloquently Explained</a></li><li>Javascript lib of MAM: <a href="https://github.com/iotaledger/mam.client.js">https://github.com/iotaledger/mam.client.js</a> </li><li><a href="https://www.youtube.com/watch?v=Nnwn_o_ZBFU">MAM deep dive (youtube)</a></li></ul><p><strong>Other articles in this series:</strong></p><ul><li><a href="http://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/">Part 1</a></li><li>Part 2 (this article)</li><li><a href="http://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/">Part 3</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Other articles in this series:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/&quot;&gt;Part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Part 2 (this article)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/&quot;&gt;Part 3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my previous article, we discussed different approaches for solving the data integrity and lineage challenges, and concluded that the “&lt;strong&gt;Hashing with DLT&lt;/strong&gt;“ solution is the direction we will move forward. In this article, we will have deep dive into it. Please not that Veracity’s work on data integrity and data lineage is testing many technologies in parallel. We utilise and test proven centralized technologies as well as new distributed ledger technologies like Tangle and Blockchain. This article series uses the IOTA Tangle as the distributed ledger technology. The use cases described can be solved with other technologies. This article does not necessarily reflect the technologies used in Veracity production environments.&lt;/p&gt;
&lt;h1 id=&quot;Which-DLT-to-select&quot;&gt;&lt;a href=&quot;#Which-DLT-to-select&quot; class=&quot;headerlink&quot; title=&quot;Which DLT to select?&quot;&gt;&lt;/a&gt;Which DLT to select?&lt;/h1&gt;&lt;p&gt;As Veracity is part of an Open Industry Ecosystem we have focused our data integrity and data lineage work using public DLT and open sourced technologies. We believe that to succeed with providing transparency from the user to the origin of data many technology vendors must collaborate around common standards and technologies. The organizational setup and philosophies for some of the public distributed ledgers provides the right environment to learn and develop fast with an adaptive ecosystem. &lt;/p&gt;
&lt;img src=&quot;/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/title.jpg&quot; class=&quot;&quot;&gt;</summary>
    
    
    
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="IOTA" scheme="https://feng.lu/tags/IOTA/"/>
    
    <category term="Data Lineage" scheme="https://feng.lu/tags/Data-Lineage/"/>
    
    <category term="Data Integrity" scheme="https://feng.lu/tags/Data-Integrity/"/>
    
    <category term="DLT" scheme="https://feng.lu/tags/DLT/"/>
    
    <category term="Distributed Ledger Technology" scheme="https://feng.lu/tags/Distributed-Ledger-Technology/"/>
    
    <category term="Tangle" scheme="https://feng.lu/tags/Tangle/"/>
    
  </entry>
  
  <entry>
    <title>Data Integrity and Lineage by using DLT, Part 1</title>
    <link href="https://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/"/>
    <id>https://feng.lu/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/</id>
    <published>2018-09-25T18:33:49.000Z</published>
    <updated>2025-03-28T09:05:16.540Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Other articles in this series:</strong></p><ul><li>Part 1 (this article)</li><li><a href="http://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/">Part 2</a> </li><li><a href="http://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/">Part 3</a></li></ul><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>With the proliferation of data – collecting and storing it, sharing it, mining it for gains – a basic question goes unanswered: is this data even good? The quality of data is of utmost concern because you can’t do meaningful analysis on data which you can’t trust. Here in Veracity, we are trying to address this is very concern. This is a 3 part series, going all the way from concept to a working implementation using DLT (Distributed Ledger Technology).</p><p>Side note, Veracity is designed to help companies unlock, qualify, combine and prepare data for analytics and benchmarking. It helps data providers to easily onboard data to the platform, and enable data consumers to access and mine value. The data can be from various sources, such as sensors and edge devices, production systems, historical databases and human inputs. Data is generated, transferred, processed and stored, from one system to another system, one company to another company. </p><p>Veracity is by DNV GL, and DNV GL has held a strong brand for more than 150 years as being a trusted 3rd party, yet it is still pretty common to hear questions from data consumers such as:<br>1.Can I trust the data I got from Veracity?<br>2.How was the data collected and processed?</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Blackbox%20in%20data%20platform.png" class=""><span id="more"></span><p>In order to answer these questions and bring more transparency to the data process lifecycle, we must address both <a href="https://en.wikipedia.org/wiki/Data_integrity">data integrity</a> and <a href="https://en.wikipedia.org/wiki/Data_lineage">data lineage</a>. Both Data integrity and data lineage are the foundation of trust.</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Data%20integrity%20lineage%20and%20trust.png" class="" title="Data lineage is built on top of data integrity"><p>In this series of articles, we are going to look at different challenges of data integrity and lineage, and evolve the solution. (Note that integrity is one of the 3 parts of <a href="https://whatis.techtarget.com/definition/Confidentiality-integrity-and-availability-CIA">CIA triad</a>: confidentiality, integrity and availability, but we will not cover confidentiality and availability in this series.)</p><h1 id="Data-Integrity"><a href="#Data-Integrity" class="headerlink" title="Data Integrity"></a>Data Integrity</h1><p>Let’s start with a basic example:<br>Alice sends messages (ie. files) to Bob. The messages were sent via an insecure channel, such as http-based data transfer, ftp, file share or even an USB stick.</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Alice%20sends%20msg%20to%20Bob.png" class="" title="Alice sends msg to Bob"><h2 id="Basic-requirements"><a href="#Basic-requirements" class="headerlink" title="Basic requirements:"></a>Basic requirements:</h2><p>There are 2 basic requirements for any data communication:</p><ol><li>The messages were not tampered by man-in-the-middle.</li><li>The messages that Bob received, are indeed from Alice.</li></ol><p>There are mainly 2 ways to ensure this: encryption and&#x2F;or hashing. (A nice articles for comparing hashing and encryption can be found at <a href="https://www.ssl2buy.com/wiki/difference-between-hashing-and-encryption">here</a>.)</p><h2 id="Iteration-1"><a href="#Iteration-1" class="headerlink" title="Iteration #1"></a>Iteration #1</h2><p>In iteration 1 we focus on solving requirement #1: <strong>The messages were not tampered by man-in-the-middle</strong>. We either use encryption or hashing.</p><h4 id="1-1-Using-Encryption-with-symmetric-or-asymmetric-key"><a href="#1-1-Using-Encryption-with-symmetric-or-asymmetric-key" class="headerlink" title="1.1 Using Encryption (with symmetric or asymmetric key)"></a>1.1 Using Encryption (with symmetric or asymmetric key)</h4><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Sending%20msg%20with%20encryption.png" class="" title="Sending msg with encryption"><ul><li><strong>Pro</strong>: Encryption is pretty straight forward: Either use symmetric or asymmetric key, Alice and Bob can encrypt and decrypt messages without worrying data tampering. </li><li><strong>Con</strong>: However, this requires key management, both for Alice and Bob.</li></ul><h4 id="1-2-Using-Hashing"><a href="#1-2-Using-Hashing" class="headerlink" title="1.2 Using Hashing"></a>1.2 Using Hashing</h4><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Sending%20msg%20with%20hash.png" class="" title="Sending msg with hashing"><ul><li><strong>Pro</strong>: Does not require key management for both Alice and Bob.</li><li><strong>Con</strong>: With hashing, it requires an additional data flow for passing hash values from Alice to Bob. It actually requires the same security mechanism as the normal data flow.</li></ul><p>We can address the Con by introducing a trusted area for Alice. For example, Alice also publishes the hash values of the messages on <a href="https://alice.com/">https://alice.com</a>. Bob can verify the message by compare the hash values. It is also OK to make the trusted area public, as hash value is irreversible - nobody can obtain the data by using the hash value, they can only check the message integrity. </p><p>This solution is sort of adding a secured “safeguard” track on the side, to help verifying the data flowing in the insecure channel. </p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Sending%20msg%20with%20hash%20with%20trust%20area.png" class="" title="Sending msg with hash with trust area"><ul><li><strong>Pro</strong>: Does not require key management for both Alice and Bob. Solved the problem for protecting hash value data flow.</li></ul><h2 id="Iteration-2"><a href="#Iteration-2" class="headerlink" title="Iteration #2"></a>Iteration #2</h2><p>In iteration #2, in additional to requirement #1, we also need to also fulfill requirement #2:  <strong>The messages that Bob received, are indeed from Alice.</strong></p><h4 id="2-1-Using-Encryption-with-Asymmetric-key"><a href="#2-1-Using-Encryption-with-Asymmetric-key" class="headerlink" title="2.1 Using Encryption (with Asymmetric key)"></a>2.1 Using Encryption (with Asymmetric key)</h4><p>This normally requires asymmetric encryption: Alice encrypts the message with her private key, and Bob decrypts it with Alice’s public key. Therefore, Bob is confident that Alice is the message author.</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Sending%20msg%20with%20asymmetric%20encryption.png" class="" title="Sending msg with asymmetric encryption"><h4 id="2-2-Using-Hashing-with-a-trusted-area-same-as-iteration-1"><a href="#2-2-Using-Hashing-with-a-trusted-area-same-as-iteration-1" class="headerlink" title="2.2 Using Hashing (with a trusted area), same as iteration #1"></a>2.2 Using Hashing (with a trusted area), same as iteration #1</h4><p>Hashing solution with a trusted area can also meet this requirement, simply counting on ONLY Alice can write into the trusted area.</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Can%20trust%20message%20with%20hash.png" class=""><h2 id="Conclusion-of-iteration-1-and-2"><a href="#Conclusion-of-iteration-1-and-2" class="headerlink" title="Conclusion of iteration #1 and #2"></a>Conclusion of iteration #1 and #2</h2><p>For ensuring the basic requirements, both solutions work:</p><ul><li>Using Encryption (with asymmetric key), and</li><li>Using Hashing (with trusted area)</li></ul><h2 id="Challenge-of-accountability-and-non-repudiation"><a href="#Challenge-of-accountability-and-non-repudiation" class="headerlink" title="Challenge of accountability and non-repudiation"></a>Challenge of accountability and non-repudiation</h2><p>Now, an interesting real challenge: <strong>Once Alice sends out a message, she can neither deny the message was sent, the message’s origin nor the original content</strong>.  In another word, the challenge is about accountability and <a href="https://en.wikipedia.org/wiki/Non-repudiation">non-repudiation</a>. </p><p>It can be explained by the following example:</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Bobs%20problem.png" class="" title="Bobs problem"> <p>(click to enlarge the picture)</p><p>At this point, these above solutions that we have so far cannot help Bob. For example, Alice can replace both the message and the hash value in <a href="#">https://alice.com</a>.  </p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Alice%20replaces%20both%20message%20and%20its%20hash.png" class="" title="Alice replaces both message and its hash"><p>With encryption solution, although Bob can prove the buggy version of message #2 is from Alice, but he cannot prove that Alice sent out the buggy version on Monday.</p><p>**In general, Bob (and we) need an immutable history that provides immutable traceability of data, such as when and what data was sent and processed. ** </p><p>It definitely helps provides data consumers like Bob, but there are benefits for well-behaved data providers as well: By offering the immutable history, it increases the data’s acceptance from that providers, as well as increases value and trust of the provider.</p><h2 id="Iteration-3-introduce-DLT-as-immutable-history"><a href="#Iteration-3-introduce-DLT-as-immutable-history" class="headerlink" title="Iteration #3 - introduce DLT as immutable history"></a>Iteration #3 - introduce DLT as immutable history</h2><p><a href="https://en.wikipedia.org/wiki/Distributed_ledger">Distributed Ledger Technology</a> (DLT) shows its potential capacity to become a natural place for storing data integrity and data lineage information, as it has the following key features:</p><ul><li>Data Immutability<br>As the data is replicated in all nodes in the DLT network, it means that the data is immutable, even the author cannot modify his&#x2F;her records once it is confirmed in ledgers.</li><li>Decentralized<br>The ledger network is decentralized, means all participators have the same copy of the data, including Alice and Bob. There is not a central authority can control the whole network and the records in it.  </li><li>Built-in authentication<br>In order to send data to the ledger, the author must use his&#x2F;her private key. It provides the built-in authentication for identifying who is the author of the data&#x2F;transaction.</li></ul><h4 id="3-1-Encrypted-message-within-DLT"><a href="#3-1-Encrypted-message-within-DLT" class="headerlink" title="3.1 Encrypted message within DLT"></a>3.1 Encrypted message within DLT</h4><p>As DLT does support built-authentication, there is no need to use asymmetric(public&#x2F;private) key for identity purpose. You can still use symmetric key for protecting the message from unauthorized access.<br>However, there are some limitations for using DLT as the secured channel. The biggest one is the size limitation of the message. For example, bitcoin size limitation is 1 MB and ethereum is of similar size. For lots of the cases, this limitation is show-stopper.</p><p>Therefore, the hashing solution with DLT is more realizable. See below.</p><h4 id="3-2-Hashing-with-DLT"><a href="#3-2-Hashing-with-DLT" class="headerlink" title="3.2 Hashing with DLT"></a>3.2 Hashing with DLT</h4><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Hashing%20solution%20with%20dlt.png" class="" title="Hashing solution with dlt"> <p>By only putting hash value of the messages into DLT, we can solve the size limitation issue.<br>It means:</p><ol><li>Alice continues to send messages via the insecure channels.</li><li>Meanwhile, Alice sends the hash values of the message into DLT.<ol><li>All hash values that Alice sent to DLT, is signed by Alice’s private key. So everyone knows it was author (Alice), the original message’s digest and when the data was sent (timestamp).</li></ol></li><li>Once Bob received the message via insecure channel, he can <ol><li>Find the transaction that contains the hash value for that message from DLT</li><li>By check the transaction’s metadata, Bob can check the author and timestamp.</li><li>By check the hash value from that transaction, Bob can verify the message content is not tampered.</li></ol></li><li>Also, it is impossible for Alice want to replace an old hash value. So Bob is protected from an immutable history.</li></ol><h1 id="Data-Lineage"><a href="#Data-Lineage" class="headerlink" title="Data Lineage"></a>Data Lineage</h1><p>The goal of <a href="https://en.wikipedia.org/wiki/Data_lineage">data lineage</a> is to track data over its entire lifecycle, to gain a better understanding of what happens to data as it moves through the course of its life. It increases trust and acceptance of result of data process. It also helps to trace errors back to the root cause, and comply with laws and regulations. You can easily compare this with the traditional supply chain of raw materials in manufacturing industry and&#x2F;or logistic industry. </p><p>For example, Bob is running a data process. This process takes inputs from Alice, then produces results. The results are sent to Carol.</p><ul><li>Bob produces result #X, based on inputs from Alice #1 and #2.</li><li>Bob produces result #Y, based on input from Alice #3.</li></ul><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Question%20of%20data%20lineage.png" class="" title="Question of data lineage"> <p>For Carol, some typical questions are:</p><ol><li>What inputs Bob used for producing the results #X and #Y?</li><li>Do these inputs also have another input? If yes, what are they?</li><li>Is there a way to have to full picture of the whole data process lifecycle, without asking Bob (and every upstream) in the supply chain?</li></ol><h4 id="Data-Lineage-with-DLT"><a href="#Data-Lineage-with-DLT" class="headerlink" title="Data Lineage with DLT"></a>Data Lineage with DLT</h4><p>Now we continue building on top of the Hashing solution with DLT. Whenever a data provider (for example, Bob) sends out data, he writes into DLT that contains:</p><ol><li>Hash value, which will be used for data integrity verification (same as before), and</li><li>If the data has inputs, the reference to the input are also stored into DLT</li></ol><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Data%20lineage%20by%20using%20DLT.png" class=""><p>It means that the DLT contains the end-to-end data lifecycle information. Carol (and anyone else) only need to query the public information from DLT to build the lineage diagram.</p><p>With this solution, Carol can:</p><ol><li>Gain the knowledge that that Bob is using data from Alice as inputs, without asking Bob. </li><li>Verify the data integrity for both Alice and Bob, even Carol does not directly consume the data from Alice.</li><li>Data integrity and data lineage information is immutable.</li></ol><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Extract%20lineage%20from%20DLT.png" class=""><h4 id="Extra-protection-for-data-processor"><a href="#Extra-protection-for-data-processor" class="headerlink" title="Extra protection for data processor"></a>Extra protection for data processor</h4><p>In above process, Bob is a data processor that accepts inputs from Alice (upstream), process it and send results to Carol (downstream). </p><p>This solution also provides an extra protection for Bob. For example, if Bob sent a data to Carol based on an incorrect input from Alice, Bob can simply explain that the root cause of the error is not on him but Alice, and Alice cannot deny that.</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Track%20down%20the%20root%20cause.png" class=""><p>This also means this solution can greatly simplifying the ability to trace errors back to the root cause, even the whole process includes different parties&#x2F;organizations. </p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Now we have went through different requirements and evolved solutions accordingly. At the end we believe the hashing solution with DLT can solve both data integrity and data lineage challenges. If the eco-system (data source, data processors and platform) can follows the same design, it will significantly increase the trust of data consumers as well as build more value into the data.</p><img src="/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/No%20longer%20a%20blackbox%20on%20veracity.png" class=""><p>In the next article, we will look at this solution in action, by using IOTA as the selected DLT.</p><p><strong>Other articles in this series:</strong></p><ul><li>Part 1 (this article)</li><li><a href="http://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/">Part 2</a> </li><li><a href="http://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/">Part 3</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Other articles in this series:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part 1 (this article)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://feng.lu/2018/10/03/Data-Integrity-and-Lineage-by-using-DLT-Part-2/&quot;&gt;Part 2&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://feng.lu/2019/01/03/Data-Integrity-and-Lineage-by-using-DLT-Part-3/&quot;&gt;Part 3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;With the proliferation of data – collecting and storing it, sharing it, mining it for gains – a basic question goes unanswered: is this data even good? The quality of data is of utmost concern because you can’t do meaningful analysis on data which you can’t trust. Here in Veracity, we are trying to address this is very concern. This is a 3 part series, going all the way from concept to a working implementation using DLT (Distributed Ledger Technology).&lt;/p&gt;
&lt;p&gt;Side note, Veracity is designed to help companies unlock, qualify, combine and prepare data for analytics and benchmarking. It helps data providers to easily onboard data to the platform, and enable data consumers to access and mine value. The data can be from various sources, such as sensors and edge devices, production systems, historical databases and human inputs. Data is generated, transferred, processed and stored, from one system to another system, one company to another company. &lt;/p&gt;
&lt;p&gt;Veracity is by DNV GL, and DNV GL has held a strong brand for more than 150 years as being a trusted 3rd party, yet it is still pretty common to hear questions from data consumers such as:&lt;br&gt;1.	Can I trust the data I got from Veracity?&lt;br&gt;2.	How was the data collected and processed?&lt;/p&gt;
&lt;img src=&quot;/2018/09/25/Data-Integrity-and-Lineage-by-using-DLT-Part-1/Blackbox%20in%20data%20platform.png&quot; class=&quot;&quot;&gt;</summary>
    
    
    
    
    <category term="IoT" scheme="https://feng.lu/tags/IoT/"/>
    
    <category term="IOTA" scheme="https://feng.lu/tags/IOTA/"/>
    
    <category term="Data Lineage" scheme="https://feng.lu/tags/Data-Lineage/"/>
    
    <category term="Data Integrity" scheme="https://feng.lu/tags/Data-Integrity/"/>
    
    <category term="DLT" scheme="https://feng.lu/tags/DLT/"/>
    
    <category term="Distributed Ledger Technology" scheme="https://feng.lu/tags/Distributed-Ledger-Technology/"/>
    
    <category term="Tangle" scheme="https://feng.lu/tags/Tangle/"/>
    
  </entry>
  
  <entry>
    <title>Using new domain feng.lu</title>
    <link href="https://feng.lu/2018/08/27/Using-new-domain-feng-lu/"/>
    <id>https://feng.lu/2018/08/27/Using-new-domain-feng-lu/</id>
    <published>2018-08-27T19:13:52.000Z</published>
    <updated>2025-03-28T09:05:16.902Z</updated>
    
    <content type="html"><![CDATA[<p>Shortly after I have renewed my blog domain <strong>fenglu.me</strong>, it just crossed my mind that “hey, is it possible to register a top-level domain with my family name <strong>.lu</strong>? So I can literally have my name for my site: <strong>feng.lu</strong>! That will be cool!”</p><img src="/2018/08/27/Using-new-domain-feng-lu/Header.jpeg" class="" title="picture credit: www.dreamhost.com"><p>(picture copyright: <a href="http://www.dreamhost.com/">www.dreamhost.com</a>)</p><p>And, (after googling), yes! It is possible! <strong>.lu</strong> is the Internet country code top-level domain for Luxembourg. OK… (continue googling) “Can I register a .lu domain without been a Luxembourgers?” “No problem!” Great!</p><p>Long story short, after some quick research on vendors and paid 24 Euro, I got the brand new feng.lu domain! :)</p><p>The remaining is pretty straightforward:</p><ul><li>In feng.lu domain provider, set up an apex domain and www subdomain for my real blog host Github page, according to <a href="https://help.github.com/articles/using-a-custom-domain-with-github-pages/">their document</a>.</li><li>In github page settings, update the custom domain (equals to update the CNAME file).</li><li>Update blog source code (hexo) with the new domain </li><li><strong>Important!</strong>: Since I would like to keep all existing links from the old domain <a href="http://fenglu.me/">fenglu.me</a> continue working, I also setup the domain forwarding. <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/10043/2237/url-redirect-with-parameters">Document</a>. Remember to use “Redirect to a specific page&#x2F;folder&#x2F;subfolder”.</li><li>Update Google Analytics, GTM, etc</li><li>Done!</li></ul><p>Happy blogging!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Shortly after I have renewed my blog domain &lt;strong&gt;fenglu.me&lt;/strong&gt;, it just crossed my mind that “hey, is it possible to register a t</summary>
      
    
    
    
    
    <category term="Blog" scheme="https://feng.lu/tags/Blog/"/>
    
    <category term="Domain" scheme="https://feng.lu/tags/Domain/"/>
    
    <category term="DNS" scheme="https://feng.lu/tags/DNS/"/>
    
  </entry>
  
</feed>
